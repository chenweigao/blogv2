---
title: JAVA 虚拟机 ART 研究（杂谈）
date: 2022-10-17
tag:
 - jvm
 - java
category:
 - JAVA
author: weigao
# 此页面会出现在首页的文章板块中
star: true
---





这篇文章是一个关于 JAVA Art/Davlik 虚拟机的一个杂谈，整理了一些问题和感悟。

- 栈式虚拟机 vs 寄存器虚拟机
- IR

<!-- more -->

## 栈 vs 寄存器虚拟机

### 对比

常见的虚拟机可以分为两种，一种是基于堆栈（表达式栈）的虚拟机，一种是基于寄存器的虚拟机，Davlik 就是基于寄存器的虚拟机。关于这两个方面的优劣，在这进行一个简单的研究。

> 所谓“表达式栈”就是用来存放表达式临时值的地方。“基于虚拟寄存器”的做法是给每个临时值都赋予一个“临时变量”的名字；而“基于表达式栈”则不赋予“临时变量”的名，总是通过栈来隐式操作临时值。

> 对于解释器来说，解释器开销主要来自解释器循环（fetch-decode/dispatch-execute 循环）中的 fetch 与 decode/dispatch，反而真正用于执行程序逻辑的 execute 部分并不是大头。每条指令都要经历一轮 FDX 循环。因而减少指令条数可以导致 F与 D 的开销减少，于是就提升了解释器速度[^1]。

上述文字说了一个问题，就是解释器的开销的前端 bound 较大，所以说减少指令数量可以一定程度上提高性能。

有几个对比：

1. 源代码的生成难度：差别不大，栈更简单一些
2. 同样逻辑的代码大小：基于栈 < 基于寄存器
3. 同样逻辑的指令条数：基于栈 > 基于寄存器
4. 简易实现中数据移动次数：基于栈 > 基于寄存器；这里面说的就是堆栈的上下文切换之类的；栈顶缓存技术(top-of-stack caching) 可以大幅度降低基于栈的解释器的数据移动操作
5. 同等优化下的解释器速度：基于栈 < 基于寄存器
6. 交由同等优化程度的 JIT 编译器编译后生成的代码速度：基于栈 == 基于寄存器；只要经过合理的编译，得到的结果是一模一样的

基于以上的说明，我们如果要选择基于寄存器的虚拟机的时候，我们一般是对**解释器的执行速度**有所要求；如果要选择基于栈的虚拟机的时候，其优点是实现简单、传输代码的大小较小；

而对于带有 JIT 编译器的执行引擎的速度而言，如果 JIT 实现的较好的话，其经过 parse 之后速度是差不多的。

### JVM

早期 JVM 是基于栈的，但是实际上，基于栈的虚拟机并没有减少 Java 代码的传输大小，这是因为 JAVA 是使用 Class 文件为单位来进行传输与存储的，每一个 Class 文件都是独立存储，这是为了 Java 设计之初支持分离编译和按需动态类加载；独立存储的情况下，每一个 Class 文件都必须携带自己的常量池以及用于符号链接的符号引用信息。

分析 Java 字节码是可以看出来，其只占 Class 文件的小部分，大部分都被常量池占了 -- 这些常量池一般都是存在重叠的，这些都是冗余信息。所以说 Dex 文件的优势就在这显现出来了。

但是有一个问题是，Dex 文件较小，和虚拟机是基于寄存器的有关吗？其实没有特别大的关联，在字节码部分，Dalvik 的字节码其实比 JVM 的字节码更大。再多说一句，我个人的理解就是 Dex 文件较小是取决于其中的共享常量池等技术，pack200.

不管如何，基于寄存器的设计还是一个较为新的潮流。

在这关于 Class 文件的一些槽点，引用[^1]作者的一些描述，看能否再后续的工作上对这些提出优化的思路：

> Class文件方面：
>
> - 各种人为的大小限制都跟不上时代了，例如每个方法的字节码最多65535字节；
> - 要生成StackMapTable太闹心；
> - 常量池的组织方式不便于直接从文件映射到内存然后高效执行；可以有更高效的组织方式。
>
> JAR文件方面：
>
> - 如前文提的，多个Class文件之间的常量池冗余；
> - 缺少带有强语义的描述模块的信息；
> - 等等…

#### class 文件就是字节码么？

@todo 博客更新后，转移到 jvm.md 中，并且可以根据 class 文件找到所对应的信息部分。

不是。除了字节码以外，class 文件还记录了很多信息：

- 结构信息
  - Class 文件格式版本号
  - 各部分的数量与大小
- 元数据
  - 类、继承的超类、实现的接口声明信息
  - 常量池
  - ...
- 方法信息
  - 字节码
  - 异常处理器表
  - ...

字节码只代表程序逻辑，只是 class 文件众多组成部分其中之一。

### 栈顶缓存

在最原始的 “基于表达式栈” 的基础上有两个变种，都是利用 “栈顶缓存” 的思路：

1. 单状态栈顶缓存，1-TOSCA
2. 多状态栈顶缓存，2-TOSCA

单状态栈顶缓存：总是把表达式栈的栈顶值放在一个实际寄存器（这个缓存寄存器也叫累加器）里；如果表达式栈有多于一个值，则其余部分分配在栈帧上。

关于 HotSpot VM 和 Dalvik VM 的解释器，前者是使用 1-TOSCA，后者是用全部映射到栈帧上的方式实现基于虚拟寄存器的指令集（Dalvik 字节码）。

多状态栈顶缓存有几种不同的做法；本质上其就是一种非常简单使用的、适用于后序遍历表达树的寄存器分配思路[^2]。

:::tip stack slot

暂时可以理解为栈的一部分。Second chance binpacking 算法（全局寄存器分配的算法之一，一种或线性扫描的算法）中会使用到这个概念。

:::

## IR

> 如果有个项目急需为某个语言实现一个优化的 JIT 编译器，怎样能在有限的时间内快速做出优化程度足够好的实现呢？
>
> 一个思路：如果有现成的静态编译器后端的话，针对输入的语言写个编译器前端，让它生成现成的后端能接受的[IR](https://link.zhihu.com/?target=http%3A//en.wikipedia.org/wiki/Intermediate_language%23Intermediate_representation)，直接插到现成的后端上。
>
> “有现成的静态编译器后端”门槛挺高，直到[LLVM](https://link.zhihu.com/?target=http%3A//llvm.org/)普及之前；不过土豪大厂们早已跨过这门槛，自然会想走这条路。

这个是引用知乎上的一个回答中的问题，从中我们可以管中窥豹，看一下 IR 在整个编译器中所处的位置。目前的理解是：IR 是后端的输入，前端的输出。





[^1]:[栈式虚拟机和寄存器式虚拟机？](https://www.zhihu.com/question/35777031/answer/64575683)
[^2]: [寄存器分配问题？ - RednaxelaFX的回答 - 知乎 ](https://www.zhihu.com/question/29355187/answer/51935409)