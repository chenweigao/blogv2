const n=JSON.parse(`{"key":"v-ec768da6","path":"/blogs/Research/mnist.html","title":"MNIST 手写数字识别","lang":"zh-CN","frontmatter":{"title":"MNIST 手写数字识别","date":"2017-03-10T00:00:00.000Z","tag":["paper","deeplearning"],"category":["Research"],"description":"#mnist_inference.py import tensorflow as tf INPUT_NODE = 784 OUTPUT_NODE = 10 LAYER1_NODE = 500 def get_weight_variable(shape, regularizer): weights = tf.get_variable(\\"weights\\", shape, initializer=tf.truncated_normal_initializer(stddev=0.1)) if regularizer != None: tf.add_to_collection('losses', regularizer(weights)) return weights def inference(input_tensor, regularizer): with tf.variable_scope('layer1'): weights = get_weight_variable([INPUT_NODE, LAYER1_NODE], regularizer) biases = tf.get_variable(\\"biases\\", [LAYER1_NODE], initializer=tf.constant_initializer(0.0)) layer1 = tf.nn.relu(tf.matmul(input_tensor, weights) + biases) with tf.variable_scope('layer2'): weights = get_weight_variable([LAYER1_NODE, OUTPUT_NODE], regularizer) biases = tf.get_variable(\\"biases\\", [OUTPUT_NODE], initializer=tf.constant_initializer(0.0)) layer2 = tf.matmul(layer1, weights) + biases return layer2","head":[["meta",{"property":"og:url","content":"https://vueblog.weigao.cc/blogs/Research/mnist.html"}],["meta",{"property":"og:site_name","content":"WW"}],["meta",{"property":"og:title","content":"MNIST 手写数字识别"}],["meta",{"property":"og:description","content":"#mnist_inference.py import tensorflow as tf INPUT_NODE = 784 OUTPUT_NODE = 10 LAYER1_NODE = 500 def get_weight_variable(shape, regularizer): weights = tf.get_variable(\\"weights\\", shape, initializer=tf.truncated_normal_initializer(stddev=0.1)) if regularizer != None: tf.add_to_collection('losses', regularizer(weights)) return weights def inference(input_tensor, regularizer): with tf.variable_scope('layer1'): weights = get_weight_variable([INPUT_NODE, LAYER1_NODE], regularizer) biases = tf.get_variable(\\"biases\\", [LAYER1_NODE], initializer=tf.constant_initializer(0.0)) layer1 = tf.nn.relu(tf.matmul(input_tensor, weights) + biases) with tf.variable_scope('layer2'): weights = get_weight_variable([LAYER1_NODE, OUTPUT_NODE], regularizer) biases = tf.get_variable(\\"biases\\", [OUTPUT_NODE], initializer=tf.constant_initializer(0.0)) layer2 = tf.matmul(layer1, weights) + biases return layer2"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"Someone"}],["meta",{"property":"article:tag","content":"paper"}],["meta",{"property":"article:tag","content":"deeplearning"}],["meta",{"property":"article:published_time","content":"2017-03-10T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"MNIST 手写数字识别\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2017-03-10T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Someone\\",\\"url\\":\\"https://www.weigao.cc\\"}]}"]]},"headers":[{"level":3,"title":"LeNet实现mnist","slug":"lenet实现mnist","link":"#lenet实现mnist","children":[]}],"git":{},"readingTime":{"minutes":3.42,"words":1027},"filePathRelative":"blogs/Research/mnist.md","localizedDate":"2017年3月10日","excerpt":"<div class=\\"language-python line-numbers-mode\\" data-ext=\\"py\\"><pre class=\\"language-python\\"><code><span class=\\"token comment\\">#mnist_inference.py</span>\\n<span class=\\"token keyword\\">import</span> tensorflow <span class=\\"token keyword\\">as</span> tf\\n\\nINPUT_NODE <span class=\\"token operator\\">=</span> <span class=\\"token number\\">784</span>\\nOUTPUT_NODE <span class=\\"token operator\\">=</span> <span class=\\"token number\\">10</span>\\nLAYER1_NODE <span class=\\"token operator\\">=</span> <span class=\\"token number\\">500</span>\\n\\n<span class=\\"token keyword\\">def</span> <span class=\\"token function\\">get_weight_variable</span><span class=\\"token punctuation\\">(</span>shape<span class=\\"token punctuation\\">,</span> regularizer<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n    weights <span class=\\"token operator\\">=</span> tf<span class=\\"token punctuation\\">.</span>get_variable<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">\\"weights\\"</span><span class=\\"token punctuation\\">,</span> shape<span class=\\"token punctuation\\">,</span> initializer<span class=\\"token operator\\">=</span>tf<span class=\\"token punctuation\\">.</span>truncated_normal_initializer<span class=\\"token punctuation\\">(</span>stddev<span class=\\"token operator\\">=</span><span class=\\"token number\\">0.1</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>\\n    <span class=\\"token keyword\\">if</span> regularizer <span class=\\"token operator\\">!=</span> <span class=\\"token boolean\\">None</span><span class=\\"token punctuation\\">:</span> tf<span class=\\"token punctuation\\">.</span>add_to_collection<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'losses'</span><span class=\\"token punctuation\\">,</span> regularizer<span class=\\"token punctuation\\">(</span>weights<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>\\n    <span class=\\"token keyword\\">return</span> weights\\n\\n\\n<span class=\\"token keyword\\">def</span> <span class=\\"token function\\">inference</span><span class=\\"token punctuation\\">(</span>input_tensor<span class=\\"token punctuation\\">,</span> regularizer<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n    <span class=\\"token keyword\\">with</span> tf<span class=\\"token punctuation\\">.</span>variable_scope<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'layer1'</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n\\n        weights <span class=\\"token operator\\">=</span> get_weight_variable<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">[</span>INPUT_NODE<span class=\\"token punctuation\\">,</span> LAYER1_NODE<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">,</span> regularizer<span class=\\"token punctuation\\">)</span>\\n        biases <span class=\\"token operator\\">=</span> tf<span class=\\"token punctuation\\">.</span>get_variable<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">\\"biases\\"</span><span class=\\"token punctuation\\">,</span> <span class=\\"token punctuation\\">[</span>LAYER1_NODE<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">,</span> initializer<span class=\\"token operator\\">=</span>tf<span class=\\"token punctuation\\">.</span>constant_initializer<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">0.0</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>\\n        layer1 <span class=\\"token operator\\">=</span> tf<span class=\\"token punctuation\\">.</span>nn<span class=\\"token punctuation\\">.</span>relu<span class=\\"token punctuation\\">(</span>tf<span class=\\"token punctuation\\">.</span>matmul<span class=\\"token punctuation\\">(</span>input_tensor<span class=\\"token punctuation\\">,</span> weights<span class=\\"token punctuation\\">)</span> <span class=\\"token operator\\">+</span> biases<span class=\\"token punctuation\\">)</span>\\n\\n    <span class=\\"token keyword\\">with</span> tf<span class=\\"token punctuation\\">.</span>variable_scope<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'layer2'</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n        weights <span class=\\"token operator\\">=</span> get_weight_variable<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">[</span>LAYER1_NODE<span class=\\"token punctuation\\">,</span> OUTPUT_NODE<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">,</span> regularizer<span class=\\"token punctuation\\">)</span>\\n        biases <span class=\\"token operator\\">=</span> tf<span class=\\"token punctuation\\">.</span>get_variable<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">\\"biases\\"</span><span class=\\"token punctuation\\">,</span> <span class=\\"token punctuation\\">[</span>OUTPUT_NODE<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">,</span> initializer<span class=\\"token operator\\">=</span>tf<span class=\\"token punctuation\\">.</span>constant_initializer<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">0.0</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>\\n        layer2 <span class=\\"token operator\\">=</span> tf<span class=\\"token punctuation\\">.</span>matmul<span class=\\"token punctuation\\">(</span>layer1<span class=\\"token punctuation\\">,</span> weights<span class=\\"token punctuation\\">)</span> <span class=\\"token operator\\">+</span> biases\\n\\n    <span class=\\"token keyword\\">return</span> layer2\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div>","autoDesc":true}`);export{n as data};
