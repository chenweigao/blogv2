import{_ as d}from"./plugin-vue_export-helper-c27b6911.js";import{r as n,o as l,c as s,a as e,b as t,d as a,f as i}from"./app-22cda79c.js";const c={},h=i('<h1 id="vp-value-prediction-abstract" tabindex="-1"><a class="header-anchor" href="#vp-value-prediction-abstract" aria-hidden="true">#</a> VP - Value Prediction Abstract</h1><h2 id="value-prediction-in-a-nutshell" tabindex="-1"><a class="header-anchor" href="#value-prediction-in-a-nutshell" aria-hidden="true">#</a> Value Prediction in a Nutshell</h2><blockquote><p>Value Prediction (VP) is a microarchitectural technique that speculatively breaks true data dependency to increase instruction level parallelism in out-of-order processor cores.<sup class="footnote-ref"><a href="#footnote1">[1]</a><a class="footnote-anchor" id="footnote-ref1"></a></sup></p></blockquote><ul><li>branch prediction but for values</li></ul>',4),p=e("sup",{class:"footnote-ref"},[e("a",{href:"#footnote2"},"[2]"),e("a",{class:"footnote-anchor",id:"footnote-ref2"})],-1),u={href:"http://dl.acm.org/citation.cfm?id=243889",target:"_blank",rel:"noopener noreferrer"},f=e("sup",{class:"footnote-ref"},[e("a",{href:"#footnote3"},"[3]"),e("a",{class:"footnote-anchor",id:"footnote-ref3"})],-1),b=i('<h2 id="micro-29" tabindex="-1"><a class="header-anchor" href="#micro-29" aria-hidden="true">#</a> MICRO 29</h2><h3 id="abstract" tabindex="-1"><a class="header-anchor" href="#abstract" aria-hidden="true">#</a> Abstract</h3><p>本章节主要研究 <em>Exceeding the dataflow limit via value prediction</em> 这篇文章，这篇文章作为经典的 VP 的顶尖著作之一，具有很高的研究价值。</p><h3 id="taxonomy-of-speculative-execution" tabindex="-1"><a class="header-anchor" href="#taxonomy-of-speculative-execution" aria-hidden="true">#</a> Taxonomy of Speculative Execution</h3><p>投机执行的分类：</p>',5),m=i('<ul><li><p>对于 Data Speculation 而言，我们分类：预测是否与数据的<strong>位置</strong>或者<strong>值</strong>有关。</p></li><li><p>对于 binary vs multi-valued 而言，binary 表示的是预测的两种结果，0-1 或者 token vs not-token(branch 中表示 branch 的方向)，mutil-valued 表示的是 brach 的目标，这个目标可能是存在于程序地址的任何空间中的。</p></li></ul><h3 id="data-speculation" tabindex="-1"><a class="header-anchor" href="#data-speculation" aria-hidden="true">#</a> Data Speculation</h3><p>可以分为两类：</p><ol><li>those that speculate on the storage location of the data: 存储位置</li><li>those that speculate on the actual value of the data: 实际的值</li></ol><p>对于推测存储位置存在两种 flavor:</p><ol><li>those that speculate on a specific attribute of the storage location：根据存储位置的特定属性进行推测</li><li>those that speculate on the address of the storage location：根据存储位置的地址进行推测</li></ol><h3 id="value-locality" tabindex="-1"><a class="header-anchor" href="#value-locality" aria-hidden="true">#</a> Value Locality</h3><blockquote><p>previously-seen value recurring repeatedly within a storage location.</p></blockquote><p>以前看到的值在存储位置中重复出现。</p><blockquote><p>Although the concept is general and can be applied to any storage location within a computer system, we have limited our current study to examine only the value locality of general-purpose or floating point registers immediately following instructions that write to those registers.</p></blockquote><p>目前限制了这个 Value Locality 的范围在通用寄存器或者浮点寄存器的值局部性，这些寄存器紧跟在写入指令之后。</p><p>不过哪怕是寄存器，以 32-bit 举例，也可能会存在超过 2^32 的值，我们要怎么才能做到预测下一个可能出现的值呢？</p><blockquote><p>As it turns out, if we narrow the scope of our prediction mechanism by considering each <strong>static instruction</strong> individually, the task becomes much easier and we are able to accurately predict a significant fraction of register values being written by machine instructions.</p></blockquote><p>这篇文章使用了 20 个 benchmark 总结出来了寄存器的 value locality, 特别是 signal cycle 的指定操作寄存器的 value locality 更加明显。</p><h3 id="exploiting-value-locality" tabindex="-1"><a class="header-anchor" href="#exploiting-value-locality" aria-hidden="true">#</a> Exploiting Value Locality</h3>',15),g=e("h3",{id:"value-prediction-unit",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#value-prediction-unit","aria-hidden":"true"},"#"),t(" Value Prediction Unit")],-1),v=e("p",null,"文章提出了 VP 单元的两级预测结构：",-1),y=i('<p>我们对这张图片进行分析：</p><blockquote><p>the Classification Table (CT) and the Value Prediction Table (VPT), both of which are direct-mapped and indexed by the instruction address (PC) of the instruction being predicted.</p></blockquote><blockquote><p>The PC of the instruction being predicted is used to index into the VPT to find a value to predict.</p></blockquote><p>PC 中的指令用于 index 进去 VPT, 找到需要预测的值。与此同时，CT 也被 Index 用于用于决定是否进行预测。当指令完成的时候，<em>pred histstory</em> 和 <em>value history</em> 两个字段都被更新了。</p><h4 id="ct" tabindex="-1"><a class="header-anchor" href="#ct" aria-hidden="true">#</a> CT</h4><ul><li>valid</li></ul><blockquote><p>The valid field, which consists of either a single bit that indicates a valid entry or a partial or complete tag field that is matched against the upper bits of the PC to indicate a valid field.</p></blockquote><p>这句话主要的意思是：由单个 bit 位组成，表示一个有效的 entry 或者一部分或完整的 tag 字段，与 PC 的高比特位匹配，表示有效的 field.</p><ul><li>prediction history</li></ul><p>​ 1 bit 或者更多位的 saturating counter(饱和计数器)， 某个预测正确或者错误的时候，这一位的字段增加或者减少。</p><p>​ 除此之外，还可以将指定分类为可预测和不可预测；这种预测用于决定是否预测特定指令的结果。换言之，CT 将指令分为了两类：通过 VPT 预测和指令和不通过 VPT 预测的指令。</p><blockquote><p>Increasing the number of bits in the saturating counter adds hysteresis to the classification process and <em>can help avoid erroneous classifications by ignoring anomalous values and/or destructive interference.</em></p></blockquote><p>​ 需要注意，增加饱和计数器的 bit 位可能会增加分类过程中的 hystersis(迟滞)；这个迟滞可能的意思是说，增加 bit 位导致的预测结果集后移，这种迟滞，如以前 2-bit, 2 and 3 是预测，3-bit 而言 可能需要 4 以后才可以预测，这就是迟滞。</p><p>对于 CT 和 VPT 的相互关系：</p><blockquote><p>The VPT replacement policy is also governed by the CT prediction history to introduce hysteresis and avoid replacing useful values with less useful ones.</p></blockquote><p>VPT 的替换策略受到 CT 预测历史的影响，这是为了避免引入不必要的错误值。</p><p>总结：</p><ol><li>用于在预测正确或者错误的时候饱和计数器自增或者自减</li><li>用于对某个指令分类，该指令是否可预测</li></ol><h4 id="vpt" tabindex="-1"><a class="header-anchor" href="#vpt" aria-hidden="true">#</a> VPT</h4><p>VPT 的这两个字段的含义说明如下：</p><ul><li><p>tag</p><p>同 CT，由单个 bit 有效位或者完整或者部分标记。</p></li><li><p>value history</p><p>包括 32-bit 或者 64 bit 的值，这些值由 LRU 策略维护（that are maintained with an LRU policy）；当第一次产生指令结果或者预测不正确的时候，这个字段被替换掉。</p><p>需要注意的是，VPT 的替换策略受到 CT 预测历史的影响，以免用了不那么有用的值替换掉有用的值。</p></li></ul><h3 id="verifying-predictions" tabindex="-1"><a class="header-anchor" href="#verifying-predictions" aria-hidden="true">#</a> Verifying Predictions</h3><p>由于值预测本来就是投机性的，所以需要一种机制来验证预测的正确性，并且从错误预测中恢复过来。</p><h2 id="hpca-19" tabindex="-1"><a class="header-anchor" href="#hpca-19" aria-hidden="true">#</a> HPCA 19</h2><h3 id="abstract-1" tabindex="-1"><a class="header-anchor" href="#abstract-1" aria-hidden="true">#</a> Abstract</h3><p>本章主要研究 HPCA 19 的 <em>Efficient Load Value Prediction using Multiple Predictors and Filters<sup class="footnote-ref"><a href="#footnote4">[4]</a><a class="footnote-anchor" id="footnote-ref4"></a></sup></em>.</p><p>首先阐述 VP 的重大意义：</p><blockquote><p>Value prediction has the potential to break through the performance limitations imposed by true data dependencies.</p></blockquote><p>然后提出了仅预测 load value 是最高效的方式，特别是在硬件预算不高的情况下（虽然说预测所有指令类型的值是可以做到的）。</p><p>📌📌📌 todo，需要研究一下原文的 3 和 4 引用，搞清楚 load value 具体的意义。</p><p>目前自己理解的 load value 的含义为：load 指令取值，这个值来自于内存中。</p><p>在此先引用一下一篇论文中的解释<sup class="footnote-ref"><a href="#footnote5">[5]</a><a class="footnote-anchor" id="footnote-ref5"></a></sup>，但是不一定是准确的：</p><blockquote><p>The LVPT is used to predict the value being loaded from memory by associating the load instruction with the value previously loaded by that instruction.</p></blockquote><p>🤔🤔🤔 这句话阐述了一个观点：load value 指的是指令从内存中加载出来的值，load 指令中有访存的操作，这时候就是从内存中取出来要使用的值。</p><blockquote><p>While predicting values of all instruction types is possible, prior work has shown that predicting just load values is most effective with a modest hardware budget.</p></blockquote><p>然后概述使用了比较多的篇幅来说明提升 VP 的预测精度需要硬件帮助，因此本文提出了一种：</p><blockquote><p>In this paper, we <strong>analyzed four state-of-the-art load value predictors</strong>, and found that they complement each other.</p></blockquote><p>基于上述的 load value, 作者提出了一个新的复合预测器。</p><blockquote><p>Based on that finding, we evaluated a <strong>new composite predictor</strong> that combines all four component predictors.</p></blockquote><h3 id="summary" tabindex="-1"><a class="header-anchor" href="#summary" aria-hidden="true">#</a> Summary</h3><p>这块做一个简单的总结，从总体上对这篇文章有一个了解。</p><ol><li>本文使用了 4 个先进的预测器，并且提出了一种 Smart Training 的方法对这四种预测器进行有机的结合（后文 Smart Training 中进行详细的研究）</li><li>增加 AM(Accuracy Monitor) 技术，这个技术通过屏蔽 produce mis-prediction 的预测器，来减少错误预测带来的损失。AM 可以分为两种：M-AM 和 PC-AM</li><li>使用 Heterogeneous Predictor Tables 技术，也可以称作动态融合预测器表，将资源从性能不佳的预测器重新分配到性能更好的预测器</li><li>深入分析比较了这种融合的方式对于预测准确度的提升，并和最先进的模型进行了对比</li></ol><h3 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction" aria-hidden="true">#</a> Introduction</h3><p>more ILP, true data limit.</p><p>ILP 指的是 Instruction Level Parallelism, 指令级并行。</p><blockquote><p>In the case of load instructions, it is also possible to predict a load memory address, followed by a data cache access, to generate a speculative value that does not necessarily exhibit value locality.</p></blockquote><p>这个技术可以再研究一下。</p><h3 id="_4-predictors" tabindex="-1"><a class="header-anchor" href="#_4-predictors" aria-hidden="true">#</a> 4 Predictors</h3><p>本文使用了 4 个先进的预测器，并对他们进行了融合，融合过后的组合预测器性能得到了很大的提升，这 4 个预测器如下表所示：</p><table><thead><tr><th></th><th>Predicts</th><th>Predicts</th></tr></thead><tbody><tr><td></td><td>Load values</td><td>Load addresses</td></tr><tr><td>Context agnostic</td><td>Last Value Prediction (LVP)</td><td>Stride Address Prediction (SAP)</td></tr><tr><td>Context aware</td><td>Context Value Prediction (CVP)</td><td>Context Address Prediction (CAP)</td></tr></tbody></table><p>从表中我们可以看出，本文一共使用的四个预测器，并且可以分类为基于地址的、基于 value 的、上下文是否感知的，本文对这些预测器进行了一个排序（使用顺序，在预测的时候先使用哪个，后使用哪个），我们根据这个排序对这 4 个预测器进行简单的介绍：</p><ol><li>LVP<sup class="footnote-ref"><a href="#footnote6">[6]</a><a class="footnote-anchor" id="footnote-ref6"></a></sup></li><li>CVP</li><li>SAP</li><li>CAP</li></ol><blockquote><p>All four components train inparallel.</p></blockquote><p>注意到其并行性。</p><h4 id="lvp" tabindex="-1"><a class="header-anchor" href="#lvp" aria-hidden="true">#</a> LVP</h4><p>LVP<sup class="footnote-ref"><a href="#footnote6">[6:1]</a><a class="footnote-anchor" id="footnote-ref6:1"></a></sup>这个预测器的原理在于：<em>that consecutive dynamic instances of a static load will often produce the same value</em>, 翻译过来就是说静态 load 的连续动态实例通常会产生相同的值。</p><p>这个预测器是对上下文不感知的。</p><p>这边举了两个例子，还需要再深入理解一下，或者去阅读一下原文。</p><p>第一个例子（接上面的英文原文）：</p><blockquote><p>This commonly occurs, for example, with PC-based loads that read large constants.</p></blockquote><p>第二个例子：</p><blockquote><p>The pattern can also occur when dynamic instances of a static load produce different addresses, such as when sequencing through an array just initialized with memset.</p></blockquote><p>上述两个例子都是举例说明了 LVP 的一些场景。</p><p>LVP uses a PC-indexed, tagged prediction table. 其结构如下：</p><table><thead><tr><th>14-bit</th><th>64-bit</th><th>3-bit</th><th></th><th>81 bits(total)</th></tr></thead><tbody><tr><td>tag</td><td>value</td><td>saturating confidence counter</td><td></td><td>a entry</td></tr></tbody></table><blockquote><p>LVP is trained when a load executes by hashing the PC bits of a load to access an entry and then updating the entry’s tag and value.</p></blockquote><p>❌❌❌ load PC 的关系不明确，导致这段话不能理解。</p><p>目前可以看出来的是，PC 中的一些比特位通过 hash 的方式索引到 LVP 表中的 entry, 一般而言，是对比 tag, 然后看其对应的置信值是否大于阈值。</p><p>这个预测器如果遇到了 tag/value 匹配的话，我们就增加置信值，否则不匹配的话，置信值归零。</p><h4 id="cvp" tabindex="-1"><a class="header-anchor" href="#cvp" aria-hidden="true">#</a> CVP</h4><p><strong>77bits: tag(14-bit) + virtual address(49-bit) + saturating confidence counter(2-bit)</strong><br> saturating confidence counter: 饱和置信计数器。</p><h4 id="cvp-1" tabindex="-1"><a class="header-anchor" href="#cvp-1" aria-hidden="true">#</a> CVP</h4><p><strong>81bits: tag(14-bit) + value(64 bit) + counter(3-bit)</strong></p><blockquote><p>CVP is inspired by branch prediction, which has long observed that branch behavior is correlated with the path history leading to the branch.</p></blockquote><p>其灵感来源于分支预测，分支的行为往往与导致分支行为的路径历史有关，对于 VP, 这个结论也同样适用。</p><p>当 load 执行的时候，CVP 适用表中最长历史、最高置信的字段。</p><h4 id="cap" tabindex="-1"><a class="header-anchor" href="#cap" aria-hidden="true">#</a> CAP</h4><p><strong>67bits:tag(14-bit) + virtual address(49-bit) + confidence(2-bit) + load size(2-bit)</strong></p><p>CAP 预测器在 4 个预测器中拥有最小的置信阈值。</p><p>CAP 预测器的工作方式如下：</p><ol><li>load 完成的时候，更新 table</li><li>新的 tag, value 和 size 和已知的 entry 匹配，则增加置信值</li><li>其他情况，置信值置 0</li></ol><h3 id="value-prediction" tabindex="-1"><a class="header-anchor" href="#value-prediction" aria-hidden="true">#</a> Value Prediction</h3><h4 id="fpc-strategies" tabindex="-1"><a class="header-anchor" href="#fpc-strategies" aria-hidden="true">#</a> FPC Strategies</h4><p>使用一个 forward probabilistic counter(FPC) 可以减少数字的比特，这个在其他论文中提到了。</p><p>目前的理解：使用标量构建置信度，然后再计算出对应的 FPC 矢量。</p><h3 id="smart-training" tabindex="-1"><a class="header-anchor" href="#smart-training" aria-hidden="true">#</a> Smart Training</h3><p>使用 Smart Training 的时候，我们在训练和预测时候使用的预测器的数量是减少的，figure 7 阐述了这个结论。</p><p>Smart Training 目的在于合理地对 4 中预测器进行组合，其工作方式如下：</p><ol><li>如果没有预测发生，所有的预测器都用做最小化获得置信预测的最小时间；</li><li>如果一个或者多个预测发生了，那么我们只训练以下的预测器： <ol><li>mispredicted</li><li>参考 heuristic 中拥有最小代价的，简而言之，就是按照顺序对预测器进行训练。</li></ol></li></ol><p>📌📌📌 todo：深入研究这个策略，其前置条件是什么，策略是什么，什么条件下对应使用什么策略。</p><h3 id="accuracy-monitor-am" tabindex="-1"><a class="header-anchor" href="#accuracy-monitor-am" aria-hidden="true">#</a> Accuracy Monitor(AM)</h3><h4 id="am" tabindex="-1"><a class="header-anchor" href="#am" aria-hidden="true">#</a> AM</h4><p>可以分为两种：</p><ol><li>M-AM</li><li>PC-AM</li></ol><p>AM 的概念介绍如下：</p><blockquote><p>In a composite predictor, we can also throttle an entire component predictor when it is producing a high misprediction rate overall. We studied two different throttling mechanisms, which we call Accuracy Monitors (AM).</p></blockquote><p>AM 是一种机制，其保证了当整个组合预测器产生了较高的总体误预测率时，我们可以对其进行限制。可以翻译为一种“节流机制”。</p><h4 id="am-q-a" tabindex="-1"><a class="header-anchor" href="#am-q-a" aria-hidden="true">#</a> AM Q&amp;A</h4><p>Q：AM 使能的时间节点是哪个？</p><p>A：在 fetch 阶段，原文是 At prediction time (Fetch)，在这个阶段 AM 与预测器同时查找。</p><p>Q: AM 通过什么样的方式使能的？</p><p>A：AM 会产生一个预测值，并且 AM 是与预测器关联的，AM 可以指示该预测器的预测不可靠，依据这个我们可以对预测器的预测结果进行压缩(squash).</p><p>Q: M-AM 和 PC-AM 有何不同？</p><p>A: 先说相同点，两者都是衡量的可信指标；M-AM 是 epoch 维度，而 PC-AM 是指令维度。</p><h4 id="m-am" tabindex="-1"><a class="header-anchor" href="#m-am" aria-hidden="true">#</a> M-AM</h4><p>M-AM 跟踪每个组件执行期间的错误预测率，这个预测错误率有一个计算的方法，以每一个 epoch 为单位，大概 100W 个指令。</p><h4 id="pc-am" tabindex="-1"><a class="header-anchor" href="#pc-am" aria-hidden="true">#</a> PC-AM</h4><p>不同于 M-AM，PC-AM 跟踪每一个 PC 的预测错误率，精度更高。</p><p>PC-AM 包括几个字段：tag + counters.</p><p>PC-AM 中的 narrow counter 的增加策略是，每一次触发了流水线的 flush, PC-AM 的 counter 就增加。</p><p>PC-AM 追踪每一个 PC 以便于实施更有针对性的沉默。</p><h4 id="heterogeneous-predictor-tables" tabindex="-1"><a class="header-anchor" href="#heterogeneous-predictor-tables" aria-hidden="true">#</a> Heterogeneous Predictor Tables</h4><h3 id="discuss" tabindex="-1"><a class="header-anchor" href="#discuss" aria-hidden="true">#</a> Discuss</h3><p>Q：这个机制最终还是没有保证 commit 步骤，前面的准确率是如何保证的？</p><p>A：📌📌</p><p>Q：值预测器的原理是什么，简要说明。</p><p>A：</p><h2 id="asplos-96-lvp" tabindex="-1"><a class="header-anchor" href="#asplos-96-lvp" aria-hidden="true">#</a> ASPLOS 96(LVP)</h2><h3 id="abstract-2" tabindex="-1"><a class="header-anchor" href="#abstract-2" aria-hidden="true">#</a> Abstract</h3><p>本部分主要研究文章 <em>Value locality and load value prediction</em><sup class="footnote-ref"><a href="#footnote5">[5:1]</a><a class="footnote-anchor" id="footnote-ref5:1"></a></sup> , 主要是涉及到这篇文章中的 LVP 预测器。</p><blockquote><p>Our work extends this to predict entire 32- and 64-bit register values based on previously-seen values. We find that, just as condition bits are fairly predictable on a per-static-branch basis, <strong>full register values being loaded from memory are frequently predictable as well.</strong></p></blockquote><p>这篇文章的主要工作就是预测 32 或者 64 位寄存器的值。</p><blockquote><p>In this paper, we introduce value locality, a concept related to redundant computation, and demonstrate a technique--Load Value Prediction, or LVP--for predicting the results of load instructions at dispatch by exploiting the affinity between load instruction addresses and the values the loads produce.</p></blockquote><p>上述介绍了 LVP， 通过 load 指令地址和 load 产生的值之间的亲和性来预测 load 指令的结果。</p><p>作者阐述了 LVP 具有两个优点：</p><ol><li><p>indexed by instruction address. 这个优点导致的结果是，我们可以在流水线很早期的时候，对值进行查找(value lookups can occur very early in the pipeline)</p></li><li><p>具有投机性质，依赖 verification 的机制来保证正确性。</p><p>❌❌ 并没有看懂这个是何种优点？作者对比了其他人的研究结果， 那些人的研究是在 pipline 的后段才使用 table indece, 并且要求这个预测是正确的。</p><p>总体来看这篇文章，作者确实使用了预测+验证的机制，并且是将值进行了分类。load 执行完成以后，我们对预测的值进行验证，验证过后更新 LVPT 和 LCT, 并且在需要的时候 reissue 指令。</p></li></ol><h3 id="value-locality-1" tabindex="-1"><a class="header-anchor" href="#value-locality-1" aria-hidden="true">#</a> Value Locality</h3><p>这篇文章也阐述了值局部性的原理，为了加深理解，我们对此也进行研究。</p><blockquote><p>In this paper, we introduce the concept of value locality, which we define as the likelihood of a previously-seen value recurring repeatedly within a storage location.</p></blockquote><p>作者将值局部性定义为了以前在某个存储位置出现过的值还有可能再次重复出现。</p><blockquote><p>we have limited our current study to examine only the value locality of general-purpose or floating-point registers <strong>immediately following memory loads that target those registers.</strong></p></blockquote><p>作者对预测的范围也进行了一个限制：仅仅预测通用的或浮点数寄存器。</p><p>📌📌 深入思考，为什么要做这个限制？</p><blockquote><p>As it turns out, if we narrow the scope of our prediction mechanism by considering each static load individually, the task becomes much easier, and we are able to accurately predict a significant fraction of register values being loaded from memory.</p></blockquote><p>为什么值局部性可以被我们所利用？作者缩小了预测的范围。</p><p>接下来，作者从几个方面来论证，值局部性存在的一些原因：</p><ol><li>data redundancy, 值冗余。体现在一些例子比如稀疏矩阵、带空白的文本文件和电子表格中的空白单元；</li><li>Error-checking, 错误检查，检查不长发生的条件经常会编译到 load 的常量；Checks for infrequently-occurring conditions often compile into loads of what are effectively run-time constants.</li><li>Program constants, 这个比较好理解， 但是我理解不了。❌❌❌</li><li>Computed branches,</li><li>Virtual function calls,</li><li>Glue code,</li><li>Addressability</li><li>Call-subgraph identities</li><li>Memory alias resolution</li><li>Register spill code</li></ol><h3 id="lvpt" tabindex="-1"><a class="header-anchor" href="#lvpt" aria-hidden="true">#</a> LVPT</h3><p>作者通过对 loads value 进行分类达到减少预测错误率的目的，总共可以分为三类：</p><ol><li>LVPT 无法预测</li><li>LVPT 可以预测</li><li>LVPT 几乎可以预测（执行度高的话就进行预测）</li></ol><p>根据以上三类，将 loads 指令分为了三类：unpredictable, predictable, and constant loads.</p><p>对应的可能的 2-bit 计数器可以这么分类：<em>no prediction, incorrect prediction, correct prediction, or constant load.</em></p><blockquote><p>The LVPT is indexed by the load instruction address and is not tagged, so both constructive and destructive interference can occur between loads that map to the same entry (the LVPT is direct-mapped).</p></blockquote><p>上面这段话说明了，LVPT 是直接映射的，并且没有 tag, 所以导致的结果是 both constructive and destructive interference 都可能映射到同一个 entry.</p><p>我们接下来研究一下，预测之中的一些细节：</p><p>首先是 LVPT, LCT, CVU 之间的使用，文章中使用 CVU(constant verification unit) 来存储 constant.</p><h3 id="lct-cvu" tabindex="-1"><a class="header-anchor" href="#lct-cvu" aria-hidden="true">#</a> LCT &amp; CVU</h3><p>尽管说 LVPT 将 loads 分为了三类，但是还是缺少一个验证的机制，所以说在 LCT 阶段，我们还是需要根据分类进行不同的决策：</p><ol><li><p>predictable: 将预测的值和从内存中检索出来的值进行比较。</p></li><li><p>highly-predictable or constant loads: 使用 CVU 单元，CVU 单元可以避免访存操作，具体的做法是强制将 LVPT 中的 entry 与主存保持一致性来实现。</p><blockquote><p>we use the constant verification unit, or CVU, which allows us to avoid accessing the conventional memory system completely by forcing the LVPT entries that correspond to constant loads to remain coherent with main memory.</p></blockquote><p>对于被 LCT 归类于 constants 的 entry 来说，数据的地址和 LVPT 的索引被放在 CVU 内部，但是这两个字段是分开的（独立的）、存于全相联的 table 中。这个 table 与主存保持一致性，策略是：</p><blockquote><p>This table is kept coherent with main memory by invalidating any entries where the data address matches a subsequent store instruction.</p></blockquote></li></ol><p>​ 上述话说明了保持一致的策略，目前我的理解是，table 使其中的某个字段非法化，也就是说，store 指令（💛💛 特别注意这个细节，是 store 指令）的执行可以使 CVU 中的字段非法化，因为访存会改变这个地址对应数据的值。但是如果没有怼这个地址发生过 load 指令的话，这个地址字段就是一直有效的，我们在预测的时候(constant load) 直接从这个 CVU 中取值，这里面的值是和主存中的值保持一致的。</p><p>这个 CVU 里面的值是什么时候写进去的呢，我们在提到上文的 CVU 的组成时说到了，其字段的一部分是与 LVPT 想关联的，所以当 load 执行完成，验证到某个条目的预测是正确的时候，我们就把这个条目刷新到 CVU 中。</p><p>这种措施的好处就是可以降低内存带宽的需求。</p><h3 id="the-load-value-prediction-unit" tabindex="-1"><a class="header-anchor" href="#the-load-value-prediction-unit" aria-hidden="true">#</a> The Load Value Prediction Unit</h3><p>LVPT, LCT, CVU 之间是怎么合作的呢？</p><p>load 指令 fetch 的时候，LVPT, LCT 表被同时索引了，一个负责分类，一个负责具体的预测；一旦预测的地址有了，EX1, cache 的访问和 CVU 的访问同时进行。当真实的 value 从 L1 cache 中返回的时候，将其与预测的值进行比较，此时，相关的推测指令（speculative instructions）有两个选择：</p><ul><li>write back – 成功</li><li>reissue – 失败</li></ul><p>由于无法及时在 CVU 上面执行搜索以避免内存访问，因此 CVU 唯一可以阻止内存访问的时候是在 cache miss 或者 bank conflict 的时候。</p><h3 id="conclusion" tabindex="-1"><a class="header-anchor" href="#conclusion" aria-hidden="true">#</a> Conclusion</h3><blockquote><p>we demonstrate that load instructions, when examined on a per-instruction-address basis, exhibit significant amounts of value locality.</p></blockquote><p>❌❌❌ 如何理解 per-instruction-address basis?</p><blockquote><p>we describe load value prediction, a microarchitectural technique for capturing and exploiting load value locality to reduce effective memory latency as well as bandwidth requirements.</p></blockquote><p>上面这段话讲述了 <strong>load value prediction</strong> 的重要意义，特别是在学术上的定义。</p><h2 id="words" tabindex="-1"><a class="header-anchor" href="#words" aria-hidden="true">#</a> Words</h2><table><thead><tr><th>Words</th><th>含义</th><th></th><th>Words</th><th>含义</th></tr></thead><tbody><tr><td>impose</td><td>强制实行、强制推行</td><td></td><td>Speculation</td><td>推测、猜测</td></tr><tr><td>narrow</td><td>有限的、小的</td><td></td><td>saturating</td><td>饱和</td></tr><tr><td>hysteresis</td><td>回差、滞后</td><td></td><td>speculative</td><td>投机性的</td></tr><tr><td>saturating counter</td><td>饱和计数器</td><td></td><td>govern</td><td>统治、管理</td></tr><tr><td>composite</td><td>组合、复合</td><td></td><td>probed</td><td>探测</td></tr><tr><td>mitigate</td><td>使缓和、使减轻</td><td></td><td>redundancy</td><td>冗余</td></tr><tr><td>heterogeneous</td><td>异构</td><td></td><td>contemporary</td><td>当代的、同时期的</td></tr><tr><td>seamlessly</td><td>完美无缺</td><td></td><td>complementary</td><td>互补的</td></tr></tbody></table><p>饱和计数器理解：对于 2-bit 计数器来说，0 or 3 就是到了饱和的状态，此时自增或者自减都是不会改变值的，所以就饱和了。</p><h2 id="reference" tabindex="-1"><a class="header-anchor" href="#reference" aria-hidden="true">#</a> Reference</h2><hr class="footnotes-sep">',167),P={class:"footnotes"},k={class:"footnotes-list"},V={id:"footnote1",class:"footnote-item"},C={href:"https://www.microarch.org/cvp1/index.html",target:"_blank",rel:"noopener noreferrer"},w=e("a",{href:"#footnote-ref1",class:"footnote-backref"},"↩︎",-1),x={id:"footnote2",class:"footnote-item"},A={href:"https://www.microarch.org/tot/index.html#winners",target:"_blank",rel:"noopener noreferrer"},q=e("a",{href:"#footnote-ref2",class:"footnote-backref"},"↩︎",-1),_=e("li",{id:"footnote3",class:"footnote-item"},[e("p",null,[t('M. H. Lipasti and J. P. Shen, "Exceeding the dataflow limit via value prediction," Proceedings of the 29th Annual IEEE/ACM International Symposium on Microarchitecture. MICRO 29, 1996, pp. 226-237, doi: 10.1109/MICRO.1996.566464. '),e("a",{href:"#footnote-ref3",class:"footnote-backref"},"↩︎")])],-1),T=e("li",{id:"footnote4",class:"footnote-item"},[e("p",null,[t('R. Sheikh and D. Hower, "Efficient Load Value Prediction Using Multiple Predictors and Filters," 2019 IEEE International Symposium on High Performance Computer Architecture (HPCA), 2019, pp. 454-465, doi: 10.1109/HPCA.2019.00057. '),e("a",{href:"#footnote-ref4",class:"footnote-backref"},"↩︎")])],-1),L={id:"footnote5",class:"footnote-item"},M={href:"https://course.ece.cmu.edu/~ece740/f10/lib/exe/fetch.php?media=valuelocalityandloadvalueprediction.pdf",target:"_blank",rel:"noopener noreferrer"},U={href:"https://doi.org/10.1145/248209.237173",target:"_blank",rel:"noopener noreferrer"},I=e("a",{href:"#footnote-ref5",class:"footnote-backref"},"↩︎",-1),S=e("a",{href:"#footnote-ref5:1",class:"footnote-backref"},"↩︎",-1),E={id:"footnote6",class:"footnote-item"},O={href:"https://doi.org/10.1145/237090.237173",target:"_blank",rel:"noopener noreferrer"},Q=e("a",{href:"#footnote-ref6",class:"footnote-backref"},"↩︎",-1),N=e("a",{href:"#footnote-ref6:1",class:"footnote-backref"},"↩︎",-1);function R(B,F){const o=n("ExternalLinkIcon"),r=n("Mermaid");return l(),s("div",null,[h,e("p",null,[t("MICRO Test of Time Award"),p,t(" 是一个十分具有分量的奖项，收录了微体系结构中经典的具有影响力的论文，关于 VP 的论文 <"),e("a",u,[t(" Exceeding the Dataflow Limit Via Value Prediction"),a(o)]),t(">"),f,t(" 就是 2017 年被该奖项收录。")]),b,a(r,{id:"mermaid-36",code:"eJxtzrEOgjAQBuBZn+ImUwcI9A1Q3NwkTi5nqdKktqYU1Lf3DpFEw9Zc//vuv1j/UA2GCFW5XGTicNeqsxhNr2H3pHc03q2Xi1xsvYvBW5gSw1yKEiP+DTNIkgRyWIGkzTQXm4BONVCaoBVn4OTgbByGF9Op/AYqDFcd+fdGh23So+10zZmPmLJJebpL6nB579XUhaBhduS1GUUOCq1ys1Ehp7AGW13/lOIfKYq6Drpt5yhCRmzkuNYbrktfBQ=="}),m,a(r,{id:"mermaid-115",code:"eJxLy8kvT85ILCpR8Ani4jTQcK0oyMnPLMnMS1cIS8wpTVXwyU9OzMksqdTk4jTUgAgFFKWmZCaXZObnKYTmZZYAZYw0wlKLMtMqQdoQssVAGQMFXV1dBUMFNQUjLgC7kiIL"}),g,v,a(r,{id:"mermaid-122",code:"eJxl0DHPwiAQBuAZfsVNX3AoX1p1damjQ2OqCzpgoZaEtA1Qjf/eoyHaxI3ce+S5u9YOz6aTLkC9p6QqWVXC0MLotOJgeh8cX8U6ZNkOyhr+4FzVlKzFpcIW0wSt4CztpP+vlPjpdndy7GKjKK303rSmkcEMPdTyZjVggn3KON3M1cORkpzn7CGtUQjlvGDRhs74MLjXXMoh4xlgRInu1YLBUUDMOqRpvhJmP1KxkAqU8I1fvxTmM4VZonCRuPiakmilJyUbJhbgUfvJhusq3YiSLROnUcnPbVIUL/cGcgJplA=="}),y,e("section",P,[e("ol",k,[e("li",V,[e("p",null,[e("a",C,[t("Championship Value Prediction (CVP)"),a(o)]),t(),w])]),e("li",x,[e("p",null,[e("a",A,[t("MICRO Test of Time Award"),a(o)]),t(),q])]),_,T,e("li",L,[e("p",null,[e("a",M,[t("Value Locality and Load Value Prediction"),a(o)]),t(", "),e("em",null,[t("Mikko H. Lipasti, Christopher B. Wilkerson, and John Paul Shen. 1996. Value locality and load value prediction. SIGPLAN Not. 31, 9 (Sept. 1996), 138–147. "),e("a",U,[t("https://doi.org/10.1145/248209.237173"),a(o)])]),t(),I,t(),S])]),e("li",E,[e("p",null,[t("Mikko H. Lipasti, Christopher B. Wilkerson, and John Paul Shen. 1996. Value locality and load value prediction. In Proceedings of the seventh international conference on Architectural support for programming languages and operating systems (ASPLOS VII). Association for Computing Machinery, New York, NY, USA, 138–147. "),e("a",O,[t("https://doi.org/10.1145/237090.237173"),a(o)]),t(),Q,t(),N])])])])])}const z=d(c,[["render",R],["__file","vp_value_prediction.html.vue"]]);export{z as default};
