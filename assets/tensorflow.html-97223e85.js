import{_ as n}from"./plugin-vue_export-helper-c27b6911.js";import{o as s,c as a,f as p}from"./app-22cda79c.js";const t={},o=p(`<p>Tensorflow中一些简单但是容易忘记的：</p><div class="language-python" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
a <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span> <span class="token comment">#用来表示矩阵的乘法操作</span>

weight <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 

bias <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#偏置项</span>
</code></pre></div><p>tf.Variable为初始化变量的操作，tf.random_normal指定了一个2*3的矩阵，元素均值为0，标准差为2，并且，符合正态分布，其他的可以参考tensorflow随机数生成函数</p><p>接下来这段代码实现神经网络的<strong>前向传播</strong>过程</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
w2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev <span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span><span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

a <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>w2<span class="token punctuation">)</span>

sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>

sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">.</span>initializer<span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w2<span class="token punctuation">.</span>initializer<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>关于placeholder</strong><br> 一般而言，我们需要使用常量：</p><p><code>x = tf.constant([[0.7,0.9]])</code></p><p>但是这样明显加大了tensorflow的计算量，所以引入了placeholder，这时候我们只需要将数据传入计算图，下面是一个例子：</p><p><code>x = tf.placeholder(tf.float32,shape = (1,2), name = &quot;input&quot;)</code></p><p>其中的shape属性可以不指定，因为数据的维度信息可以根据提供的数据推导得出，但是确定的维度的给出可以降低出错的概论。下面的代码为placeholder实现前向传播算法：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
w2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name <span class="token operator">=</span> <span class="token string">&quot;input&quot;</span><span class="token punctuation">)</span>
a <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>w2<span class="token punctuation">)</span>

sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>
init_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_op<span class="token punctuation">)</span>

<span class="token comment"># print(sess.run(y))</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>y<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span><span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>需要注意的是被注释的那行代码<code># print(sess.run(y))</code>，如果运行的话，解释器会报告一个错误，这是因为我们需要提供一个feed_dict来指定x的取值。<br> 如果我们需要多个样例的传播结果，只需要：</p><p><code>x = tf.placeholder(tf.float32,shape=(3,2),name=&quot;input&quot;)</code> #3个</p><p>然后给出三组数据即可：</p><p><code>sess.run(y,feed_dict={x:[[0.7,0.9],[0.1,0.4],[0.5,0.8]]})</code></p><p>而后我们定义loss函数来刻画预测值和真实值之间的差距，然后通过反向传播算法来调整神经网络的取值从而缩小差距</p><div class="language-python" data-ext="py"><pre class="language-python"><code>cross_entropy <span class="token operator">=</span> <span class="token operator">-</span>tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>y_ <span class="token operator">*</span> tf<span class="token punctuation">.</span>log<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>clip_by_value<span class="token punctuation">(</span>y<span class="token punctuation">,</span><span class="token number">1e-10</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">)</span>
</code></pre></div><p>cross_entropy定义了真实值和预测值之间的<em>交叉熵</em>。<br> 具体而言，交叉熵刚开始的意义是刻画了两个概论分布之间的距离，是分类问题中使用比较广的一种损失函数。在代码中的含义就是y\`表示正确结果，y代表预测结果,并且将张量中的数值限制在1E-10~1.0之间，以避免一些运算错误<br> 如果与softmax一起使用的话，tensorflow对这两个功能进行了统一封装，调用</p><p><code>cross_entropy=tf.nn.softmax_cross_entropy_with_logits(y,y_)</code></p><p>下面是训练过程开始的代码：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    init_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_op<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w2<span class="token punctuation">)</span><span class="token punctuation">)</span>

    STEPS <span class="token operator">=</span> <span class="token number">5000</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>STEPS<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start <span class="token operator">=</span> <span class="token punctuation">(</span>i <span class="token operator">*</span> batch_size<span class="token punctuation">)</span> <span class="token operator">%</span> dataset_size
        end <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>start <span class="token operator">+</span> batch_size<span class="token punctuation">,</span> dataset_size<span class="token punctuation">)</span>

        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span> X<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">,</span> y_<span class="token punctuation">:</span> Y<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            total_cross_entropy <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span>X<span class="token punctuation">,</span>y_<span class="token punctuation">:</span>Y<span class="token punctuation">}</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;After %d training steps,cross entropy is %g&quot;</span><span class="token operator">%</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>total_cross_entropy<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w2<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>训练循环了5000次，可以观察到交叉熵的值是越来越小的，这表明预测的结果和真实值的差距越来越小<br> 最后的两行输出表示训练之后神经网络的值</p><p>**总结一下，训练神经网络的过程可以分为以下三个步骤：</p><ul><li>定义网络的结构和前向传播的输出</li><li>定义损失函数和选择反向传播优化的算法</li><li>生成会话并且在训练数据上反复运行反向传播优化算法**</li></ul><p>有的时候需要自定义损失函数：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf 
<span class="token keyword">from</span> numpy<span class="token punctuation">.</span>random <span class="token keyword">import</span> RandomState

batch_size <span class="token operator">=</span> <span class="token number">8</span>

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name <span class="token operator">=</span> <span class="token string">&#39;x-input&#39;</span><span class="token punctuation">)</span>
y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name <span class="token operator">=</span> <span class="token string">&#39;y-input&#39;</span><span class="token punctuation">)</span>

w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span>seed <span class="token operator">=</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span>

loss_less <span class="token operator">=</span> <span class="token number">10</span>
loss_more <span class="token operator">=</span> <span class="token number">1</span>
loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>where<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>greater<span class="token punctuation">(</span>y<span class="token punctuation">,</span>y_<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>y<span class="token operator">-</span>y_<span class="token punctuation">)</span><span class="token operator">*</span>loss_more<span class="token punctuation">,</span><span class="token punctuation">(</span>y_<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token operator">*</span>loss_less<span class="token punctuation">)</span><span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

rdm <span class="token operator">=</span> RandomState<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
dataset_size <span class="token operator">=</span> <span class="token number">128</span>
X <span class="token operator">=</span> rdm<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>dataset_size<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>x1<span class="token operator">+</span>x2<span class="token operator">+</span>rdm<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">10.0</span><span class="token operator">-</span><span class="token number">0.05</span><span class="token punctuation">]</span> <span class="token keyword">for</span> <span class="token punctuation">(</span>x1<span class="token punctuation">,</span>x2<span class="token punctuation">)</span> <span class="token keyword">in</span> X<span class="token punctuation">]</span>

<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    init_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_op<span class="token punctuation">)</span>
    Steps <span class="token operator">=</span> <span class="token number">5000</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>Steps<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start <span class="token operator">=</span> <span class="token punctuation">(</span>i<span class="token operator">*</span>batch_size<span class="token punctuation">)</span> <span class="token operator">%</span> dataset_size
        end <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>start<span class="token operator">+</span>batch_size<span class="token punctuation">,</span>dataset_size<span class="token punctuation">)</span>
        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span>X<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span> <span class="token punctuation">,</span> y_<span class="token punctuation">:</span>Y<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>以上自定义了一个损失函数，实际值和预测值之间存在的差值分配不用的系数，我们也可以使用均方误差(MSE)：</p><p><code>loss = tf.reduce_mean(tf.square(y_-y))</code></p><p>通过比较输出的结果可以看出，不同的损失函数会对模型产生重要影响。</p><p>在优化参数的时候，梯度下降法是最常用的神经网络优化算法，具体而言，对于一个优化算法而言，第一步随机产生一个参数的初始值，然后通过梯度和学习率来更新参数的取值。<br> 梯度下降算法的两个缺陷：第一是可能得到局部最优的结果，第二是计算时间太长，因为要计算所有训练数据的损失函数是非常耗时间的，所以就可以使用随机梯度下降算法，具体而言，就是在每一轮的迭代中，随机优化某一条训练数据上的损失函数，但是随机梯度下降法有的时候甚至无法达到局部最优，所以一般采用<strong>每次计算一小部分训练数据的损失函数</strong>的方法，这一小部分数据称为一个batch。</p><p>对于learning_rate，常用的是指数衰减法</p><div class="language-python" data-ext="py"><pre class="language-python"><code>global_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
learning_rate <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>exponential_decay<span class="token punctuation">(</span><span class="token number">0.001</span><span class="token punctuation">,</span>global_step<span class="token punctuation">,</span> <span class="token number">100</span> <span class="token punctuation">,</span> <span class="token number">0.96</span> <span class="token punctuation">,</span>staircase<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
</code></pre></div><p>dacay_steps代表了完整的使用一遍训练数据所需要的迭代轮数（总训练样本数除以每一个batch的训练样本数），staircase的值为True时，global_step/decay_steps会被转化成整数。上面各个参数的含义是每训练100轮后学习率乘以0.96。经验有助于设置好学习率、衰减系数和衰减速度。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>batch_size <span class="token operator">=</span> n

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>dtype<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span>
y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>dtype<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span>

loss <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

<span class="token keyword">with</span> <span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">:</span>
	<span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>STEPS<span class="token punctuation">)</span><span class="token punctuation">:</span>
		current_X<span class="token punctuation">,</span>surrent_Y <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
		sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step<span class="token punctuation">,</span>feed_sict <span class="token operator">=</span> <span class="token punctuation">{</span>x<span class="token punctuation">:</span>current_X<span class="token punctuation">,</span>y_<span class="token punctuation">:</span>current_Y<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>以上代码概括了一般神经网络的训练大致遵循的过程。</p>`,35),e=[o];function c(u,l){return s(),a("div",null,e)}const r=n(t,[["render",c],["__file","tensorflow.html.vue"]]);export{r as default};
