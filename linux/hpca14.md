# HPCA 14

æœ¬ç« èŠ‚ç ”ç©¶æ–‡ç«  *Practical Data Value Speculation for Future High-end Processors*[^7], ç®€ç§° HPCA 14, è¿™ç¯‡æ–‡ç« ä¸»è¦æ˜¯ç ”ç©¶ CVP, ä¸€ç§ä¸Šä¸‹æ–‡æœ‰å…³çš„ã€Load value çš„é¢„æµ‹å™¨ã€‚



## Abstract

> In this paper, we reconsider the concept of Value Prediction in the contemporary context and show its potential as a direction to improve current single thread performance.

ä½œè€…åœ¨å½“ä»£è¯­å¢ƒ(contemporary context) ä¸‹é‡æ–°æ€è€ƒäº† VP çš„æ¦‚å¿µï¼Œå¹¶ä¸”å‘è§‰å…¶ä½œä¸ºæé«˜å•çº¿ç¨‹æ€§èƒ½æ–¹å‘çš„ä¸€ä¸ªæ½œåŠ›ã€‚



> Said penalty can be as high as the cost of a branch misprediction, yet the benefit of an individual correct prediction is often very limited.

é”™è¯¯æƒ©ç½šå¯èƒ½å’Œåˆ†æ”¯é¢„æµ‹çš„é”™è¯¯æƒ©ç½šä¸€æ ·é«˜ï¼Œä½†æ˜¯æ”¶ç›Šå´ååˆ†æœ‰é™ã€‚

> As a consequence, high coverage is mostly irrelevant in the presence of low accuracy.

åœ¨ç²¾åº¦æä½çš„æƒ…å†µä¸‹ï¼Œé«˜è¦†ç›–ç‡åè€Œæ˜¯æ²¡æœ‰å¿…è¦çš„ã€‚

åŸºäºä»¥ä¸Šä¸¤æ®µè¯ï¼Œé¢„æµ‹çš„è®¾è®¡æ€è·¯åœ¨äºï¼šæé«˜é¢„æµ‹çš„å‡†ç¡®ç‡ï¼Œå¯ä»¥æ¥å—é€‚å½“é™ä½è¦†ç›–ç‡ï¼›æ•…æ­¤ä½œè€…æå‡º FPC, å…¶å®šä¹‰å¦‚ä¸‹ï¼š

> The Forward Probabilistic Counters (FPC) scheme yields value misprediction rates well under 1%, at the cost of reasonably decreasing predictor coverage.

FPC çš„é”™è¯¯é¢„æµ‹ç‡è¿œä½äº 1%ï¼ŒåŒæ—¶ç‰ºç‰²äº†é¢„æµ‹è¦†ç›–ç‡ã€‚

ä½¿ç”¨ FPC çš„å¥½å¤„å¦‚ä¸‹ï¼š

> Our experiments show that when FPC is used, no complex repair mechanism such as selective reissue is needed at execution time.

ä½¿ç”¨ FPC çš„è¯å¯ä»¥é¿å…ä½¿ç”¨å¦‚ selective reissue è¿™ç§å¤æ‚æœºåˆ¶ã€‚



:::tip éšæƒ³

FPC æ˜¯ä¸€ç§ç½®ä¿¡åº¦çš„è¡¡é‡æœºåˆ¶ã€‚FPC çš„ä½œç”¨åœ¨äºé™ä½ misprediction rate.

:::



ä¸‹é¢è¿™æ®µè¯æ¯”è¾ƒéš¾ä»¥ç†è§£ï¼š

> Prediction validation can even be delayed until commit time and be done in-order: Complex and power hungry logic needed for execution time validation is not required anymore.

é¢„æµ‹çš„éªŒè¯å¯ä»¥åœ¨ commit é˜¶æ®µå®Œæˆï¼Ÿæ‰€ä»¥è¯´ç®€åŒ–äº†éªŒè¯çš„æ­¥éª¤ã€‚

:::warning

âŒâŒâŒ ä½†æ˜¯è¿™æ ·çš„è¯ï¼Œæˆ‘ä»¬å¦‚ä½•ä¿è¯é¢„æµ‹çš„æ­£ç¡®æ€§å‘¢ï¼Ÿ

:::

ç»“åˆä¸‹é¢è¿™æ®µè¯ï¼Œçœ‹èƒ½å¦å°è¯•ç†è§£ï¼š

> As a result, prediction is performed in the in-order pipeline front-end, validation is performed in the in-order pipeline back-end while the out-of-order execution engine is only marginally modified.



---

ç¬¬äºŒä¸ªæ¯”è¾ƒå¤§çš„è´¡çŒ®æ˜¯ä½œè€…æå‡ºæ¥äº† Value TAGE predictor (VTAGE). è¿™ä¸ª VTAGE çš„çµæ„Ÿæ¥è‡ªäºåˆ†æ”¯é¢„æµ‹çš„æŠ€æœ¯ ITTAGE.

> VTAGE is the first hardware value predictor to leverage a long **global branch history** and the **path history**.

:::tip éšæƒ³

ä¸Šè¿°è¿™æ®µè¯å®šä¹‰äº† VTAG, å…¶åŸºæœ¬å±æ€§æ˜¯å€¼é¢„æµ‹å™¨ï¼Œä½†æ˜¯åˆ©ç”¨äº†ï¼š

- global branch history
- path history

:::

å¾—ç›Šäº FPC, VTAG å…·æœ‰å¾ˆé«˜çš„é¢„æµ‹ç²¾åº¦ã€‚



## Related Work on VP

æˆ‘ä»¬æœ‰å¿…è¦ç ”ç©¶ä¸€ä¸‹ç›¸å…³çš„å·¥ä½œï¼Œçœ‹èƒ½å¦ä»ä¸­è·å¾—ä¸€äº›å¿ƒå¾—ä½“ä¼šã€‚

> Sazeides et al. refine the taxonomy of Value Prediction by categorizing predictors.

ä¸Šè¿°ä½œè€…å°† predictors åˆ†æˆäº†ä¸¤ç±»ï¼š

1. Computational
2. Context-based

è¿™ä¸¤ç§æ–¹å¼æ˜¯äº’è¡¥çš„å› ä¸ºå®ƒä»¬æ“…é•¿é¢„æµ‹ä¸åŒçš„æŒ‡ä»¤ï¼ˆå‰æ–‡ç ”ç©¶çš„ HPCA19 çš„æ–‡ç« ä¹Ÿæ˜¯ä½¿ç”¨äº† 4 ä¸ªé¢„æµ‹å™¨ï¼ŒæŒ–æ˜å‡ºæ¥äº†äº’è¡¥çš„å…³ç³»ï¼‰ã€‚

å¯¹äº Computational é¢„æµ‹å™¨è€Œè¨€ï¼ŒğŸŸ¢ğŸŸ¢ğŸŸ¢ å…¸å‹çš„å¦‚ 2-Delta Stride predictor è¿™ç§éœ€è¦è¿›è¡Œç ”ç©¶ã€‚å¯¹äº Computational é¢„æµ‹å™¨è€Œè¨€ï¼Œå…¶é€šè¿‡åº”ç”¨ä¸€ä¸ª fucntion å»é¢„æµ‹ values.

å¯¹äº Context-based çš„é¢„æµ‹å™¨è€Œè¨€ï¼Œå°±æ˜¯æ ¹æ®é¢„æµ‹çš„å†å²æ¥å®ç°å€¼çš„é¢„æµ‹ï¼Œå…¸å‹çš„å¦‚ $n^th$ order *Finite Context Method(FCM)*  é¢„æµ‹å™¨ï¼Œè¿™äº›é¢„æµ‹å™¨ä¸€èˆ¬ä½¿ç”¨ two-level çš„é¢„æµ‹ç»“æ„ï¼š

1. ç¬¬ä¸€å±‚ç»“æ„æ˜¯ VHT(Value History Table) 
2. ç¬¬äºŒå±‚ç»“æ„æ˜¯ VPT(Value Prediction Table)

VHT hash åˆ° VPT ä¸Šï¼ŒVPT ä¸ŠåŒ…å«äº†å®é™…çš„é¢„æµ‹ã€‚éœ€è¦æ³¨æ„ï¼Œé€šå¸¸è€Œè¨€ï¼ŒVHT å’Œ VPT éƒ½å«æœ‰ä¸€ä¸ªé¥±å’Œè®¡æ•°å™¨ï¼Œä»¥ä¾¿äºè¡¡é‡ç½®ä¿¡åº¦ã€‚

Goeman å®ç°äº† diff-FCM, é€šè¿‡è¿½è¸ª local history ä¸­çš„ diff, è€Œä¸æ˜¯ value æœ¬èº«ï¼Œè¿™æ ·è¾¾åˆ°äº†æ›´åŠ èŠ‚çœç©ºé—´çš„ç›®çš„ã€‚

Zhou å®ç°äº† gDiff é¢„æµ‹å™¨ï¼ŒgDiff è®¡ç®—äº†ä¸€ä¸ªæŒ‡ä»¤çš„ç»“æœå’Œæœ€å n ä¸ªåŠ¨æ€æŒ‡ä»¤ç»“æœä¹‹é—´çš„ diff, å¦‚æœå‘ç°äº†ä¸€ä¸ª stable difference, ä¹Ÿå¯ä»¥ç§°ä¹‹ä¸º stride, åˆ™è¯¥æŒ‡ä»¤çš„ç»“æœå¯ä»¥é€šè¿‡å…ˆå‰é¢æŒ‡ä»¤è¿›è¡Œé¢„æµ‹ã€‚ç„¶è€Œï¼ŒgDiff çš„ç¼ºé™·åœ¨äºï¼Œå…¶ä¾èµ–äºå¦ä¸€ä¸ªé¢„æµ‹å™¨åœ¨é¢„æµ‹é˜¶æ®µå»é¢„æµ‹å…¨å±€çš„æŠ•æœºå€¼ã€‚ä½†æ˜¯æ­£å› ä¸ºå¦‚æ­¤ï¼ŒgDiff é¢„æµ‹å™¨å¯ä»¥è¢«æ·»åŠ åœ¨ä»»ä½• top of any predictor.

æœ¬æ–‡æå‡ºæ¥çš„ VTAGE é¢„æµ‹å™¨å¯ä»¥ç†è§£ä¸ºä¸€ä¸ª context-based çš„é¢„æµ‹å™¨ï¼Œå…¶ä¸­çš„ context åŒ…æ‹¬ global branch history å’Œ path history.

## Motivation

æœ‰ä¸¤ä¸ªå› ç´ å¯èƒ½ä½¿å¾—é¢„æµ‹å™¨å¤æ‚åŒ–ï¼š

1. Misprediction Recovery
2. Back-to-back prediction

### Misprediction Recovery

è¡¡é‡ misprediction çš„ recovery çš„æ¶ˆè€—å¯ä»¥åˆ†ä¸ºä¸¤ä¸ªå› ç´ ï¼š

1. average misprediction penalty(å¤„ç½š) $P_{value}$
2. absolute number of misprediction $N_{misp}$

äºæ˜¯æœ‰æ€»çš„é”™è¯¯é¢„æµ‹æƒ©ç½šè®¡ç®—å¦‚ä¸‹ï¼š
$$
T_{recov} = P_{value} * N_{misp}
$$
å¤„ç†å™¨ä¸­ç›®å‰å·²æœ‰ä¸¤ç§æœºåˆ¶å»ç®¡ç† value misprediciton recovery:

1. pipline squashing
2. selective reissue

ğŸ’šğŸ’š ä»€ä¹ˆæ˜¯ pipline squashing?

æš‚æ—¶å¯ä»¥ç†è§£ä¸º pipline flushing, clearing or squashing.

ğŸ’šğŸ’š pipline squashing åšäº†ä»€ä¹ˆäº‹æƒ…ï¼Ÿ

ç›®å‰çŒœæµ‹çš„ï¼Œéœ€è¦ç»§ç»­ç ”ç©¶ã€‚

pipline squashing å¯ä»¥è¢«ç”¨äºåˆ†æ”¯é¢„æµ‹å¤±è´¥çš„ recovery ä¸­ï¼Œä¹Ÿå¯ä»¥ç”¨ä¸ VP å¤±è´¥çš„ recovery ä¸­ï¼Œä¸¤è€…çš„ä»£ä»·æ˜¯ä¸€è‡´çš„ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒVP çš„ squash å¯ä»¥è¢«é¿å…çš„ï¼Œåªè¦é¢„æµ‹çš„ç»“æœè¿˜æ²¡æœ‰è¢«åº”ç”¨ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ²¡æœ‰ dependent instruction è¢« issued.

âŒâŒ selective reissue ä¸æ˜¯å¾ˆå¥½ç†è§£ï¼Œéœ€è¦å†ç†è§£ä¸€ä¸‹ã€‚



#### Validation at Execution vs Validation at Commit Time

ä¸‹é¢æ˜¯å¯¹äºä¸¤ç§æœºåˆ¶çš„å¯¹æ¯”ï¼š

1. åœ¨å®ç°çš„èŠ‚ç‚¹ä¸Šï¼ŒSR å¿…é¡»æ˜¯åœ¨ execution çš„æ—¶å€™å°±å®ç°äº†ï¼Œå…¶ç›®çš„æ˜¯ä¸ºäº†é™åˆ¶é”™è¯¯é¢„æµ‹çš„ä»£ä»·ï¼›è€Œ PS åˆ™å¯ä»¥åœ¨ execution æˆ–è€… commit çš„æ—¶å€™å®ç°ã€‚
2. PS åœ¨ execution æ—¶é—´å» validate é¢„æµ‹å¿…é¡»é‡æ–°è®¾è®¡ out-of-order engine, é™¤æ­¤ä¹‹å¤–ï¼Œé¢„æµ‹çš„ value è¿˜å¿…é¡»åœ¨æ¯ä¸ªä¹±åºçš„é˜¶æ®µä¼ æ’­ï¼Œç­‰ç­‰ã€‚ç»¼åˆæ¥çœ‹ï¼Œåœ¨ exec é˜¶æ®µå»éªŒè¯æ¯”è¾ƒå¤æ‚ã€‚
3. åä¹‹ï¼Œåœ¨ commit åè¿›è¡Œ PS å¯èƒ½ä¼šå¯¼è‡´é¢„æµ‹é”™è¯¯åä»£ä»·è¾ƒé«˜ï¼Œä½†æ˜¯å…¶å®ç°æœºåˆ¶è¾ƒä¸ºç®€å•ï¼Œç‰¹åˆ«æ˜¯å¯¹äº out-of-order æ¥è¯´ï¼Œä¸éœ€è¦å¢åŠ é¢å¤–çš„å¤æ‚æœºåˆ¶ã€‚



**Balancing Accuracy and Coverage**

> The total misprediction penalty Trecov is roughly proportional to the number of mispredictions. Thus, if one drastically improves the accuracy at the cost of some coverage then, as long as the coverage of the predictor remains quite high, there might be a performance benefit brought by Value Prediction, even though the average value misprediction penalty is very high.

$T_{recov}$ ä¸é”™è¯¯é¢„æµ‹çš„æ•°é‡å¤§è‡´æˆæ­£æ¯”ï¼Œæ‰€ä»¥å¦‚æœå¯ä»¥åœ¨ç‰ºç‰²ä¸€äº›è¦†ç›–ç‡çš„æƒ…å†µä¸‹æå‡ç²¾åº¦ï¼Œé‚£ä¹ˆæ€»çš„ VP æ€§èƒ½æ˜¯å¯ä»¥å¾—åˆ°æå‡çš„ã€‚



### Back-to-back prediction

> However, for most predictors, the outcomes of a few previous occurrences of the instruction are needed to perform a prediction for the current instance.

å¯¹äºå¤§å¤šæ•°çš„é¢„æµ‹å™¨è€Œè¨€ï¼Œå…¶é¢„æµ‹æ˜¯ä¾èµ–äºä¸€äº›å…ˆå‰å‡ºç°æŒ‡ä»¤çš„ç»“æœçš„ã€‚

> Consequently, for those predictors, either the critical operation must be made short enough to allow for the prediction of close (possibly back-to-back) occurrences (e.g. by using small tables) or the prediction of tight loops must be given up.

æ‰€ä»¥ï¼Œå¯¹è¿™äº›é¢„æµ‹å™¨è€Œè¨€ï¼Œå°±è¦æ±‚å…³é”®è·¯å¾„å°½å¯èƒ½çš„çŸ­ã€‚æˆ–è€…è¯´ tight loop å¿…é¡»å°½å¯èƒ½å¾—æ”¾å¼ƒã€‚

> Unfortunately, tight loops with candidates for VP are quite abundant in existing programs.

ä¸å¹¸çš„æ˜¯ï¼Œtight loop è¿™ç§æƒ…å†µåœ¨ç¨‹åºä¸­å¾ˆå¤šã€‚



ğŸ’šğŸ’š 

æœ¬ç« èŠ‚ä¸»è¦æ˜¯å¯¹æ¯” LVP, stride å’Œ FCM, åˆ†åˆ«é˜è¿°è¿™å‡ ä¸ªé¢„æµ‹å™¨çš„ä¼˜ç¼ºç‚¹ã€‚

ğŸ’šğŸ’š 



#### LVP

> Despite its name, LVP does not require the previous prediction to predict the current instance as long as the table is trained. Consequently, LVP uses only the program counter to generate a prediction.

LVP ä¸éœ€è¦ä¾èµ–å…ˆå‰çš„é¢„æµ‹ç»“æœï¼Œä½†æ˜¯å…¶ä¾èµ–äºç¨‹åºè®¡æ•°å™¨ PC çš„ç»“æœã€‚

> Thus, successive table lookups are independent and can last until Dispatch, meaning that large tables can be implemented.

âŒâŒ LVP å¯ä»¥ä½¿ç”¨å¤§è¡¨ã€‚

#### Stride

@todo

#### FCM

å…¨ç§°æ˜¯ Finite Context Method, å…¶ç»“æ„æ˜¯ two-level:

> The first-level consists of a value history table accessed using the instruction address. This history is then hashed and used to index the second level table.

è¿™ä¸ªä¸¤çº§ç»“æ„çš„å›¾å¯ä»¥å‚è€ƒ Figure 1.



#### Summary

ä¸Šé¢é˜è¿°äº†ä¸‰ä¸ªé¢„æµ‹å™¨çš„å®ç°ç»†èŠ‚å’Œç¼ºç‚¹ã€‚

> Table lookup time is not an issue as long as the prediction arrives before Dispatch for LVP and Stride. Therefore, large predictor tables can be considered for implementation. For stride-based value predictor, the main difficulty is that one has to track the last (possibly speculative) occurrence of each instruction.

ä¸Šè¿°æ–‡å­—è¯´æ˜äº† LVP å’Œ stride çš„ç¼ºç‚¹ã€‚

> For local value based predictors the same difficulty arises with the addition of tracking the n last occurrences. Moreover the critical operations (hash and the 2nd level table read) lead to either using small tables or not being able to timely predict back-to-back occurrences of the same instruction. Implementations of such predictors can only be justified if they bring significant performance benefit over alternative predictors.

åŸºäº local value çš„é¢„æµ‹å™¨ä¹Ÿä¼šå—åˆ°å…³é”®æ“ä½œï¼ˆhash å’Œç¬¬ 2 çº§è¡¨çš„è¯»å–ï¼‰çš„å½±å“ã€‚

> The VTAGE predictor we introduce in this paper is able to seamlessly predict back-to-back occurrences of the same instruction, thus its access can span over several cycles. VTAGE does not require any complex tracking of the last occurrences of the instruction. 
>
> Section 8 shows that VTAGE (resp. hybrid predictor using VTAGE) outperforms a local value based FCM predictor (resp. hybrid predictor using a local value based FCM predictor).

æœ¬æ–‡æå‡ºçš„ VTAGE é¢„æµ‹å™¨å¯ä»¥å®Œç¾é¢„æµ‹ back-to-back åœºæ™¯ï¼Œå› æ­¤å®ƒçš„è®¿é—®å¯ä»¥è·¨è¶Šå‡ ä¸ªå¾ªç¯ã€‚

### Commit Time Validation and Hardware Implications on the Out-of-Order Engine

> In the previous section, we have pointed out that the hardware modifications induced by *pipeline squashing* at *commit time on* the Out-of-Order engine are limited. 
>
> In practice, the only major modification compared with a processor without Value Prediction is that the predicted values must be written in the physical registers before Dispatch.

å‰é¢çš„ç« èŠ‚æåˆ°äº†ï¼Œpipline squashing + commit time validation å¯¹ out-of-order çš„å½±å“æ˜¯æœ‰é™çš„ã€‚

äº‹å®ä¸Šï¼Œåœ¨ä¸æ²¡æœ‰ VP çš„å¤„ç†å™¨ç›¸æ¯”ï¼Œå”¯ä¸€çš„ä¸»è¦ä¿®æ”¹æ—¶ï¼šé¢„æµ‹å€¼å¿…é¡»åœ¨ dispatch ä¹‹å‰å†™å…¥ç‰©ç†å¯„å­˜å™¨ã€‚

> At first glance, if every destination register has to be predicted for each fetch group, one would conclude that the number of write ports should double. 
>
> In that case the overhead on the register file would be quite high. The area cost of a register file is approximately proportional to $(R + W) *  (R + 2W)$, $R$ and $W$ respectively being the number of read ports and the number of write ports.
>
> Assuming $R = 2W$, the area cost without VP would be proportional to $12W^2$ and the one with VP would be proportional to $24W^2$, i.e. the double. Energy consumed in the register file would also be increased by around 50% (using very simple Cacti 5.3 approximation).

ä¹ä¸€çœ‹ï¼Œå¦‚æœæ¯ä¸€ä¸ª fetch group çš„ç›®æ ‡å¯„å­˜å™¨éƒ½å¿…é¡»è¢«é¢„æµ‹çš„è¯ï¼Œåˆ™ä¼šå¾—å‡ºç»“è®ºï¼Œwrite ports åº”è¯¥ç¿»ä¸€ç•ªã€‚

æ¥ä¸‹æ¥æ˜¯å¯¹å¯„å­˜å™¨æ¶ˆè€—çš„è®¡ç®—ï¼Œå…¶ä¸­ $R$ è¡¨ç¤ºè¯»å¯„å­˜å™¨ï¼Œ$W$ è¡¨ç¤ºå†™å¯„å­˜å™¨ã€‚

ç»è¿‡ä¸€ç³»åˆ—çš„è®¡ç®—ï¼Œæœ€åå‘ç°å¯„å­˜å™¨çš„é¢ç§¯è¦å¢åŠ  50%!

> For practical implementations, there exist several opportunities to limit this overhead. 
>
> *For instance one can limit the number of extra ports needed to write predictions.* Each cycle, only a few predictions are used and the predictions can be known several cycles before Dispatch: One could limit the number of writes on each cycle to a certain limit, and buffer the extra writes, if there are any. 
>
> Assuming only $W/2$ write ports for writing predicted values leads to a register file area of $35W^2 /2$ , saving half of the overhead of the naive solution. The same saving on energy is observed (Cacti 5.3 estimations).
>
> Another opportunity is to *allocate physical registers for consecutive instructions in different register file banks, limiting the number of write ports on the individual banks.* One can also prioritize the predictions according to the criticality of the instruction and only use the most critical one, leveraging the work on criticality estimation of Fields et.

ä½†æ˜¯äº‹å®ä¸Šï¼Œæœ‰ä¸€äº› opportunities å»é™åˆ¶è¿™ä¸€å¼€é”€ã€‚

1. ä¾‹å¦‚å¯ä»¥é™åˆ¶å†™å…¥é¢„æµ‹éœ€è¦çš„é¢å¤–å¯„å­˜å™¨æ•°é‡ï¼Œä¸‹é¢æ˜¯ä¸€äº›ä¸¾ä¾‹å’Œè®¡ç®—ã€‚
2. ä¸ºè¿ç»­æŒ‡ä»¤åˆ†é…ç‰©ç†å¯„å­˜å™¨ï¼Œé™åˆ¶å•ä¸ª bank çš„å†™å…¥ç«¯å£æ•°ã€‚ç”šè‡³ä¹Ÿå¯ä»¥æ ¹æ®ä¼˜å…ˆçº§é€‰æ‹©ä½¿ç”¨æœ€å…³é”®çš„æŒ‡ä»¤ã€‚

> Exploring the complete optimization to reduce the overhead on the register file design is out of the scope of this paper. It would depend on the precise micro-architecture of the processor, but we have clearly shown that this overhead in terms of energy and silicon area can be reduced to less than 25% and 50% respectively. Moreover, this overhead is restricted to the register file and does not impact the other components of the out-of-order engine. Similarly, thanks to commit time validation, the power overhead introduced by Value Prediction will essentially reside in the predictor table.

ä½œè€…è¯´æ˜äº†å‡å°‘å¯„å­˜å™¨çš„æ•°é‡ä¸åœ¨æœ¬æ–‡çš„ç ”ç©¶èŒƒå›´ä¹‹å†…ã€‚

âŒâŒâŒ è¿™å¥è¯éš¾ç†è§£ï¼šSimilarly, thanks to commit time validation, the power overhead introduced by Value Prediction will essentially reside in the predictor table.

### Maximizing Value Predictor Accuracy Through Confidence

> As we already pointed out, the total misprediction recovery cost can be minimized through two vehicles: Minimizing the *individual misprediction penalty* and/or minimizing the *total number of mispredictions.*

é”™è¯¯é¢„æµ‹çš„æ¢å¤æŸè€—ä»ä¸¤ä¸ªæ–¹é¢è¡¡é‡ã€‚

> When using the prediction is not mandatory (i.e. contrarily to branch predictions), an efficient way to minimize the number of mispredictions is to use saturating counter to estimate confidence and use the prediction only when the associated confidence is very high. 
>
> For instance, for the value predictors considered in this study, a 3-bit confidence counter per entry that is reset on each misprediction leads to an accuracy in the 95-99% range if the prediction is used only when the counter is saturated. However this level of accuracy is still not sufficient to avoid performance loss in several cases unless idealistic selective reissue is used. 
>
> To increase accuracy, Burtscher et al. proposed the SAg confidence  stimation scheme to assign confidence to a history of outcomes rather than to a particular instruction. However, this entails a second lookup in the counter table using the outcome history retrieved in the predictor table with the PC of the instruction. A way to maximize accuracy without increasing complexity and latency would be preferable.

å½“é¢„æµ‹ä¸æ˜¯å¼ºåˆ¶çš„æ—¶å€™ï¼Œä½¿ç”¨é¥±å’Œè®¡æ•°å™¨ï¼Œæœ€å°åŒ–é”™è¯¯é¢„æµ‹çš„æ•°é‡ï¼Œè®¡ç®—ç½®ä¿¡å€¼å¹¶ä¸”åªä½¿ç”¨ç½®ä¿¡åº¦å¾ˆé«˜çš„é¢„æµ‹ã€‚ä¸¾ä¾‹äº† 3-bit é¥±å’Œè®¡æ•°å™¨çš„åˆç†ä½¿ç”¨å¯ä»¥è¾¾åˆ° 95% - 99% çš„å‡†ç¡®ç‡ï¼Œä½†æ˜¯è¿™ä¸ªå‡†ç¡®ç‡è¿˜æ˜¯ä¸å¤Ÿï¼Œæœ‰äº›ä¸“å®¶æå‡ºäº† SAg ç½®ä¿¡åº¦ä¼°è®¡æ–¹æ¡ˆï¼Œä½†æ˜¯ä¼šå¢åŠ å¤æ‚æ€§ç°åœ¨éœ€è¦ä¸€ä¸ªå‡†ç¡®åº¦é«˜çš„ï¼Œä½†æ˜¯ä¸å¢åŠ å¤æ‚æ€§å’Œæ—¶å»¶çš„æ–¹æ³•ã€‚

> We actually found that simply using **wider counters** (e.g. 6 or 7 bits) leads to much more accurate predictors while the prediction coverage is only reduced by a fraction. 
>
> Prediction is only used on saturated confidence counters and counters are reset on each misprediction. Interestingly, probabilistic 3-bit counters such as defined by Riley et al.  augmented with reset on misprediction achieve the same accuracy for substantially less storage and a marginal increase in complexity.

ä½œè€…å‘ç°ä½¿ç”¨ wider counters å¯ä»¥æå‡å¾ˆå¤šçš„é¢„æµ‹å‡†ç¡®åº¦ï¼Œéšä¹‹çš„ä»£ä»·æ˜¯å¾ˆå°çš„ç²¾åº¦æŸå¤±ã€‚

è¿™ä¸ªä¼˜ç‚¹å¾ˆå¤šï¼Œå…·ä½“æ€ä¹ˆä½¿ç”¨ï¼Œè¦åœ¨åæ–‡ç ”ç©¶ã€‚

> We refer to these probabilistic counters as Forward Probabilistic Counters (FPC). In particular, each forward transition is only triggered with a certain probability. 
>
> In this paper, we will consider 3-bit confidence counters using a probability vector $v = \{1, 1/16, 1/16, 1/16, 1/16, 1/32, 1/32\}$ for pipeline squashing at commit and $v = \{1, 1/8, 1/8, 1/8, 1/8, 1/16, 1/16\}$ for selective reissue, respectively mimicking 7-bit and 6-bit counters.
>
> This generally prevents all the considered VP schemes to slow down execution while minimizing the loss of coverage (as opposed to using lower probabilities). The used pseudo-random generator is a simple Linear Feedback Shift Register.

ä½¿ç”¨äº† FPC è®¡æ•°å™¨ï¼Œå¹¶ä¸”æå‡ºäº† 3-bit è®¡æ•°å™¨ï¼Œæ¯ä¸€ä½å­˜åœ¨ä¸€ä¸ªæŒ‡å®šçš„æ¦‚ç‡å€¼ï¼ŒâŒâŒ  æŒ‡å®šäº† 7 ä½æ¦‚ç‡è€Œä¸æ˜¯ 8 ä½ï¼Œç»†èŠ‚æœ‰å¾…ç ”ç©¶ã€‚

åœ¨ HPCA 19 çš„æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†è¿™ä¸ª FPC.

> Using FPC counters instead of full counters limits the overhead of confidence estimation. It also opens the opportunity to adapt the probabilities at run-time as suggested in and/or to individualize these probabilities depending on the criticality of the instructions.

ä½¿ç”¨ FPC è®¡æ•°å™¨è€Œä¸æ˜¯å®Œæ•´è®¡æ•°å™¨é™åˆ¶äº†æ‰§è¡Œåº¦ä¼°è®¡çš„å¼€é”€ï¼Œå¹¶ä¸”è¿˜æä¾›äº†åœ¨è¿è¡Œæ—¶è°ƒæ•´æ¦‚ç‡çš„æœºä¼šï¼Œå¦‚æ ¹æ®é‡è¦æŒ‡ä»¤ä¸ªæ€§åŒ–æ¦‚ç‡ã€‚

### The Value TAgged GEometric Predictor

é¢˜ç›®çš„å«ä¹‰ä¸ºï¼šå€¼æ ‡è®°çš„å‡ ä½•é¢„æµ‹å™¨ã€‚

ç¬¬ä¸€æ®µé¦–å…ˆåˆ—ä¸¾å‡ºæ¥äº† VTAGE æ¥æºäºåˆ†æ”¯é¢„æµ‹çš„ ITTAGE, ITTAGE æ¥æºäº TAGE.

> As it uses branch history to predict, we expect VTAGE to perform much better than other predictors when instruction results are indeed depending on the control flow. 
>
> Nonetheless, VTAGE is also able to capture control-flow independent patterns as long as they are short enough with regard to the maximum history length used by the predictor. 
>
> In particular, it can still capture short strided patterns, although space efficiency is not optimal since each value of the pattern will reside in an entry (contrarily to the Stride predictor where one pattern can be represented by a single entry).

è¿™ä¸€æ®µçš„ç»†èŠ‚æˆ‘ä»¬æš‚æ—¶ä¸è¿›è¡Œè€ƒç©¶ã€‚

> Fig. 2 describes a (1+N)-component VTAGE predictor. The main idea of the VTAGE scheme (exactly like the ITTAGE scheme) is to use several tables â€“ components â€“ storing predictions. Each table is indexed by a different number of bits of the global branch history, hashed with the PC of the instruction. The different lengths form a geometric series (i.e. VT1 is accessed with two bits of the history, VT2 with four, VT3 with eight and so on). 
>
> These tables are backed up by a base predictor â€“ a tagless LVP predictor â€“ which is accessed using the instruction address only. 
>
> In VTAGE, an entry of a tagged component consists of a partial tag, a 1-bit usefulness counter u used by the replacement policy, a full 64-bit value val, and a confidence/hysteresis counter c. An entry of the base predictor simply consists of the prediction and the confidence counter.

ä¸Šè¿°æ–‡å­—åœ¨é™ˆè¿° VTAGE é¢„æµ‹å™¨æ˜¯å¦‚ä½•å®ç°çš„ï¼Œè¿™æ®µæ¯”è¾ƒé‡è¦ã€‚

VTAGE ä¸»è¦æ˜¯ä½¿ç”¨äº†å¾ˆå¤š table, VT1, VT2, â€¦, VTn, åˆ†åˆ«ä»£è¡¨çš„å«ä¹‰æ˜¯ï¼šVT1 å…³è”äº† 2-bit çš„ global branch history, VT2 ä¸º 4-bit, VT3 ä¸º 8-bit, ä»¥æ­¤ç±»æ¨ï¼Œè¿™å°±æ˜¯ç­‰æ¯”çº§æ•°æˆ–è€…å‡ ä½•çº§æ•°ã€‚

è¿™äº›è¡¨ç”±æ— æ ‡è®° LVP é¢„æµ‹å™¨å¤‡ä»½ï¼Œè¯¥é¢„æµ‹å™¨ä»…ä»…ä½¿ç”¨æŒ‡ä»¤åœ°å€è®¿é—®ã€‚

ç¬¬ä¸‰æ®µè®²è¿°äº†é¢„æµ‹å™¨å…·ä½“çš„å®ç°ç»†èŠ‚ã€‚

> At prediction time, all components are searched in parallel to check for a tag match. The matching component accessed with the longest history is called the provider component as it will provide the prediction to the pipeline.

åœ¨é¢„æµ‹çš„æ—¶å€™ï¼Œå¹¶è¡ŒæŸ¥æ‰¾ä¸ tag åŒ¹é…çš„æ¡ç›®ï¼Œmatch çš„ç»„ä»¶å¹¶ä¸”ä¸ longest history è”ç³»çš„ç§°ä½œ provider component, åœ¨æµæ°´çº¿ä¸­æä¾›é¢„æµ‹ã€‚

> At update time, only the provider is updated. 
>
> On either a correct or an incorrect prediction, $c^2$ and $u^3$ are updated. On a misprediction, $val$ is replaced if $c$ is equal to 0, and a new entry is allocated in a component using a longer history than the provider: All â€œupperâ€ components are accessed to see if one of them has an entry that is not useful ($u$ is 0). 
>
> If none is found, the u counter of all matching entries in the upper components are reset, but no entry is allocated. Otherwise, a new entry is allocated in one of the components whose corresponding entry is not useful. The component is chosen randomly.

åœ¨æ›´æ–°çš„æ—¶å€™ï¼Œåªæ›´æ–° provider.

æ— è®ºé¢„æµ‹æ˜¯æ­£ç¡®æˆ–è€…ä¸æ­£ç¡®ï¼Œ$c^2$ å’Œ $u^3$ ä¼šè¢«æ›´æ–°ã€‚âŒâŒ

å¦‚æœæ˜¯ misprediction, $val$ ä¼šè¢«æ›¿æ¢æ‰ï¼Œå¦‚æœ c æ˜¯ 0 çš„è¯ï¼Œå¹¶ä¸”æ–°çš„æ¡ç›®ä¼šè¢«åˆ†é…ï¼Œä½¿ç”¨æ›´é•¿çš„ history.æ‰€æœ‰æ›´ä¸Šå±‚çš„ç»„ä»¶éƒ½è¢«è®¿é—®ï¼Œå»åˆ¤æ–­æ˜¯å¦å…¶ä¸­æœ‰ä¸€ä¸ª entry æ˜¯æ— ç”¨çš„ï¼Œåœ¨è¿™é‡Œ $u == 0$ï¼ˆäºŒè¿›åˆ¶ï¼‰æ˜¯æ— ç”¨çš„ï¼Œ$u$ æ˜¯ä¸€ä¸ª useful bit, å…¶è¢« replacement policy ä½¿ç”¨ã€‚

å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•ä¸€ä¸ªï¼Œä¸Šå±‚ç»„ä»¶çš„ $u$ è®¡æ•°å™¨éƒ½è¢«é‡ç½®ï¼Œæ„å‘³ç€æ²¡æœ‰ entry è¢«åˆ†é…ã€‚å¦‚æœæ‰¾åˆ°äº†çš„è¯ï¼Œä¸€ä¸ªæ–°çš„ entry å°±è¢«åˆ†é…äº†ï¼Œè¢«åˆ†é…çš„ç­–ç•¥æ˜¯ï¼šéšæœºç­–ç•¥ï¼Œé€‰æ‹©ä¸€ä¸ªç»„ä»¶çš„ entry ä¸æ˜¯ useful çš„ã€‚

> The main difference between VTAGE and ITTAGE is essentially the usage: The predicted value is used only if its confidence counter is saturated. We refer the reader to for a detailed description of ITTAGE.

VTAGE å’Œ ITTAGE ä¸åŒçš„ç‚¹åœ¨äºï¼Œé¥±å’Œè®¡æ•°å™¨é¥±å’Œçš„æ—¶å€™æ‰ä½¿ç”¨é¢„æµ‹çš„å€¼ã€‚

> Lastly, as a prediction does not depend on previous values but only on previous control-flow, VTAGE can seamlessly predict instructions in tight loops and behaves like LVP in Fig. 1. However, due to index hash and multiplexing from multiple components, it is possible that its prediction latency will be higher, although this is unlikely to be an issue since prediction can span several cycles.

æœ€åï¼Œç”±äºé¢„æµ‹ä¸ä¾èµ–äºå…ˆå‰çš„å€¼ï¼Œè€Œåªä¾èµ–äºå…ˆå‰çš„æ§åˆ¶æµï¼ŒVTAGE å¯ä»¥å®Œç¾é¢„æµ‹ tight loop.

ç„¶è€Œï¼Œç”±äºå¤šä¸ªç»„ä»¶çš„ç´¢å¼•å“ˆå¸Œå’Œå¤ç”¨ï¼Œå…¶é¢„æµ‹å»¶è¿Ÿå¯èƒ½ä¼šæ›´é«˜ï¼Œå°½ç®¡è¿™å¯èƒ½ä¸æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œå› ä¸ºé¢„æµ‹æ˜¯å¯ä»¥è·¨å‘¨æœŸçš„ã€‚

## Evaluation Methodology

### Value Predictors

#### Single Scheme Predictors

> We study the behavior of several distinct value predictors in addition to VTAGE.
>
> Namely, LVP, the 2-delta Stride predictor (2D-Stride) as a representative of the stride-based predictor family4 and a generic order-4 FCM predictor (o4-FCM)

é™¤äº† VTAGE, æˆ‘ä»¬è¿˜éœ€è¦å¯¹æ¯”ä¸€äº› value predictors. åŒ…æ‹¬ LVP, 2D-Stride å’Œ o4-FCM.

> All predictors use 3-bit saturating counters as confidence counters. The prediction is used only if the confidence counter is saturated. 
>
> Baseline counters are incremented by one on a correct prediction and reset on a misprediction. The predictors were simulated with and without FPC (See Section 5). As the potential of VP has been covered extensively in previous work, we **limit ourselves to reasonably sized predictors** to gain more concrete insights. 
>
> We start from a 128KB LVP (8K-entry) and derive the other predictors, each of them having 8K entries as we wish to gauge the prediction generation method, not space efficiency. Predictor parameters are illustrated in Table 1.

å…ˆé˜è¿°è¿™äº›é¢„æµ‹å™¨éƒ½ä½¿ç”¨äº† 3-bit çš„é¥±å’Œè®¡æ•°å™¨ä½œä¸ºç½®ä¿¡åº¦çš„è¡¡é‡æ ‡å‡†ï¼Œå¹¶ä¸”åªæœ‰åœ¨é¥±å’Œè®¡æ•°å™¨é¥±å’Œçš„æ—¶å€™å¯¹åº”çš„é¢„æµ‹æ‰è¢«ä½¿ç”¨ã€‚

å¦‚æœé¢„æµ‹æˆåŠŸçš„è¯ï¼ŒåŸºçº¿çš„é¢„æµ‹å™¨ +1ï¼Œmisprediction çš„è¯å°±é‡ç½®ã€‚

é¢„æµ‹å™¨åœ¨æœ‰ FPC å’Œæ²¡æœ‰ FPC çš„æƒ…å†µä¸‹æ¨¡æ‹Ÿã€‚å¹¶ä¸”é™åˆ¶äº†é¢„æµ‹å™¨çš„å¤§å°ã€‚

âŒâŒ æˆ‘ä»¬ä» 128K çš„ LVP å¼€å§‹ï¼Œæ¨å¯¼å…¶ä»–é¢„æµ‹å™¨ï¼Œæ¯ä¸ªé¢„æµ‹å™¨éƒ½æœ‰ 8K ä¸ª entries, å› ä¸ºæˆ‘ä»¬å¸Œæœ›è¡¡é‡é¢„æµ‹ç”Ÿæˆæ–¹æ³•ï¼Œè€Œä¸æ˜¯ç©ºé—´æ•ˆç‡ã€‚

> For VTAGE, we consider a predictor featuring 6 tables in addition to a base component. The base component is a tagless LVP predictor. We use a single useful bit per entry in the tagged components and a 3-bit hysteresis/confidence counter c per entry in every component. The tag of tagged components is *12+rank-bit* long with *rank* varying between 1 and 6. The minimum and maximum history lengths are respectively 2 and 64 as we found that these values provided a good tradeoff in our experiments.

å¯¹äº VTAGE, æˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªé¢„æµ‹å™¨ï¼Œé™¤äº†ä¸€ä¸ªåŸºç¡€ç»„ä»¶å¤–ï¼Œè¿˜åŒ…æ‹¬ 6 ä¸ªè¡¨ã€‚åŸºç¡€ç»„ä»¶æ˜¯ tagless çš„ LVP é¢„æµ‹å™¨ã€‚æˆ‘ä»¬åœ¨æ¯ä¸ª tagged çš„ç»„ä»¶ä¸­ä½¿ç”¨ä¸€ä¸ª useful æ ‡å¿—ä½å’Œä¸€ä¸ª 3-bit çš„ç½®ä¿¡åº¦/è¿Ÿæ»è®¡æ•°å™¨ã€‚tag å­—æ®µçš„å¤§å°æ˜¯ $12 + rank$ bit, $rank$ çš„å–å€¼åœ¨ 1~6 ä¹‹é—´ï¼Œç”±æ­¤è®¡ç®—ï¼Œæœ€å°å’Œæœ€å¤§çš„ history length çš„èŒƒå›´åœ¨ 2~64 ä¹‹é—´ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ trade-off.

> For o4-FCM, we use a hash function similar to thoseâ€¦..

è¯´äº†ä¸€ä¸‹ o4-FCM çš„ç»†èŠ‚ï¼Œæˆ‘ä»¬æš‚æ—¶ä¸å¯¹å…¶è¿›è¡Œç ”ç©¶ã€‚

> We consider that all predictors are able to predict instantaneously. **As a consequence, they can seamlessly deliver their prediction before Dispatch.** 
>
> This also implies that o4- CM is â€“ unrealistically â€“ able to deliver predictions for two occurrences of the same instruction fetched in two consecutive cycles. Hence, its performance is most likely to be overestimated.

æˆ‘ä»¬è®¤ä¸ºæ‰€æœ‰çš„é¢„æµ‹å™¨éƒ½å¯ä»¥ç¬é—´é¢„æµ‹ï¼Œå› æ­¤ï¼Œå®ƒä»¬å¯ä»¥åœ¨ dispatch ä¹‹å‰å®Œç¾åœ°ä¼ é€’é¢„æµ‹ã€‚

#### Hybrid Predictors

ä½œè€…é˜è¿°äº†ä¸€ä¸‹ï¼Œè¡¨æ˜æ··åˆé¢„æµ‹æ˜¯å¯è¡Œçš„ï¼ˆæ··åˆé¢„æµ‹æˆ‘ä»¬åœ¨ HPCA 19 ä¸­è¿›è¡Œé‡ç‚¹ç ”ç©¶ï¼‰ã€‚

### Simulator

>  In our experiments, we use the gem5 cycle-accurate simulator (x86 ISA).

å®éªŒä½¿ç”¨äº† gem5 ä»¿çœŸã€‚

> We model a fairly aggressive pipeline: 4GHz, 8-wide superscalar, out-of-order processor with a latency of 19 cycles. 
>
> We chose a slow front-end (15 cycles) coupled to a swift back-end (3 cycles) to obtain a realistic misprediction penalty. 

ä½œè€…æ¨¡æ‹Ÿäº†ç›¸å½“æ¿€è¿›çš„ pipline.

:::tips

ğŸ§¡ğŸ§¡ğŸ§¡

è¿™è¾¹éœ€è¦ä¸“é¢˜ç†è§£ï¼Œsuprescalar, latency çš„å…·ä½“å«ä¹‰ã€‚

ğŸ§¡ğŸ§¡ğŸ§¡

:::

ä½œè€…é€‰æ‹©äº†ä¸€ä¸ªæ…¢çš„å‰ç«¯è€¦åˆåˆ°å¿«é€Ÿçš„åç«¯ä¸­ï¼Œå¯ä»¥è§‚å¯Ÿé€¼çœŸçš„ misprediction æƒ©ç½šã€‚

#### Misprediction Recovery

> We illustrate two possible recovery scenarios, squashing at commit time and a very idealistic selective reissue.
>
> In both scenarios, recovery is unnecessary if the prediction of instruction I was wrong but no dependent instruction has been issued before the execution of I, since the prediction is replaced by the effective result at execution time. This removes useless squashes and is part of our implementation.

misprediction æ—¶å€™çš„æ¢å¤æœ‰ä¸¤ç§æ–¹å¼ï¼š

1. squashing at commit time
2. ååˆ†ç†æƒ³ä¸»ä¹‰çš„ selective reissue(ç†æƒ³ä¸»ä¹‰æ˜¯ä½œè€…å¯¹å…¶çš„è¯„ä»·ï¼Œä¸ä»£è¡¨æˆ‘æœ¬äººè§‚ç‚¹)

åœ¨ä¸Šè¿°ä¸¤ç§æƒ…å†µä¸‹ï¼Œå¦‚æœæŒ‡ä»¤çš„é¢„æµ‹é”™è¯¯ä½†æ˜¯å…¶åœ¨æ‰§è¡Œä¹‹å‰æ²¡æœ‰ issue ä¾èµ–æŒ‡ä»¤ï¼Œåˆ™ä¸éœ€è¦ recovery, å› ä¸ºé¢„æµ‹ä¼šè¢«æ‰§è¡Œæ—¶çš„æœ‰æ•ˆç»“æœå–ä»£ã€‚

