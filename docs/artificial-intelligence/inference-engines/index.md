# Inference Engines

AI æ¨ç†å¼•æ“å’Œä¼˜åŒ–æŠ€æœ¯ï¼Œä¸“æ³¨äºæ¨¡å‹éƒ¨ç½²å’Œæ¨ç†åŠ é€Ÿã€‚

## ğŸ“š æ¨ç†å¼•æ“

### NVIDIA Ecosystem
- [TensorRT](./tensorrt.md) - NVIDIA æ¨ç†ä¼˜åŒ–åº“
- [Triton Inference Server](./triton.md) - æ¨ç†æœåŠ¡å™¨
- [TensorRT-LLM](./tensorrt-llm.md) - å¤§è¯­è¨€æ¨¡å‹æ¨ç†

### Intel Ecosystem  
- [OpenVINO](../AMX/openvino.md) - Intel æ¨ç†å·¥å…·åŒ…
- [Intel Extension for PyTorch](./intel-extension.md) - PyTorch Intel æ‰©å±•

### Cross-Platform
- [ONNX Runtime](./onnx-runtime.md) - è·¨å¹³å°æ¨ç†å¼•æ“
- [Apache TVM](./tvm.md) - æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨
- [OpenAI Triton](./triton-compiler.md) - GPU å†…æ ¸ç¼–è¯‘å™¨

### Mobile & Edge
- [TensorFlow Lite](./tflite.md) - ç§»åŠ¨ç«¯æ¨ç†
- [Core ML](./coreml.md) - Apple ç”Ÿæ€æ¨ç†
- [NCNN](./ncnn.md) - ç§»åŠ¨ç«¯æ¨ç†æ¡†æ¶

## ğŸ¯ ä¼˜åŒ–æŠ€æœ¯

- [Model Quantization](../model-optimization/quantization.md) - æ¨¡å‹é‡åŒ–
- [Graph Optimization](./graph-optimization.md) - è®¡ç®—å›¾ä¼˜åŒ–
- [Kernel Fusion](./kernel-fusion.md) - ç®—å­èåˆ