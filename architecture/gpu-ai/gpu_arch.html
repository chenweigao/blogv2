<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.22" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.85" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"GPU Architecture","image":[""],"datePublished":"2025-03-06T00:00:00.000Z","dateModified":"2025-05-12T08:59:22.000Z","author":[{"@type":"Person","name":"Someone","url":"https://www.weigao.cc"}]}</script><meta property="og:url" content="https://vueblog.weigao.cc/architecture/gpu-ai/gpu_arch.html"><meta property="og:site_name" content="weigao"><meta property="og:title" content="GPU Architecture"><meta property="og:description" content="1. 量化研究方法 2. 4.4 图形处理器 CPU 程序员的挑战不只是在 GPU 上获得出色的性能，还有协调系统处理器与 GPU 上的计算调度，以及系统存储器与 GPU 存储器之间的数据传输。 GPU 中的并行：多线程、MIMD、SIMD 和指令级并行。 NVIDIA 将 CUDA 编程定义为 SIMT -- 单指令多线程。 并行执行和线程管理由 G..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-05-12T08:59:22.000Z"><meta property="article:tag" content="AI"><meta property="article:tag" content="GPU"><meta property="article:published_time" content="2025-03-06T00:00:00.000Z"><meta property="article:modified_time" content="2025-05-12T08:59:22.000Z"><link rel="stylesheet" href="//at.alicdn.com/t/font_2410206_mfj6e1vbwo.css"><link rel="icon" href="modx-icon.svg"><title>GPU Architecture | weigao</title><meta name="description" content="1. 量化研究方法 2. 4.4 图形处理器 CPU 程序员的挑战不只是在 GPU 上获得出色的性能，还有协调系统处理器与 GPU 上的计算调度，以及系统存储器与 GPU 存储器之间的数据传输。 GPU 中的并行：多线程、MIMD、SIMD 和指令级并行。 NVIDIA 将 CUDA 编程定义为 SIMT -- 单指令多线程。 并行执行和线程管理由 G...">
    <link rel="preload" href="/assets/style-DTwT6W5F.css" as="style"><link rel="stylesheet" href="/assets/style-DTwT6W5F.css">
    <link rel="modulepreload" href="/assets/app-11Vuyqh7.js"><link rel="modulepreload" href="/assets/gpu_arch.html-WvJWZ39h.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-zxK26moD.js" as="script"><link rel="prefetch" href="/assets/home.html-BOnf4GSZ.js" as="script"><link rel="prefetch" href="/assets/intro.html-KS-cxLYt.js" as="script"><link rel="prefetch" href="/assets/Drawing 2025-05-11 16.01.37 - GPU Arch.excalidraw.html-D86SW3G_.js" as="script"><link rel="prefetch" href="/assets/index.html-9EJ8q5CX.js" as="script"><link rel="prefetch" href="/assets/backtrack.html-83ZdyZ5D.js" as="script"><link rel="prefetch" href="/assets/binary_search.html-DpY6Hoxi.js" as="script"><link rel="prefetch" href="/assets/binary_tree.html-D67RRWdZ.js" as="script"><link rel="prefetch" href="/assets/dfs_bfs.html-BsfdmS2n.js" as="script"><link rel="prefetch" href="/assets/dp.html-oH8dA_N7.js" as="script"><link rel="prefetch" href="/assets/lcs.html-BjogI-T-.js" as="script"><link rel="prefetch" href="/assets/package.html-DFFA-SQW.js" as="script"><link rel="prefetch" href="/assets/presum.html-CuPnfyr6.js" as="script"><link rel="prefetch" href="/assets/slide_window.html-D2_tiEom.js" as="script"><link rel="prefetch" href="/assets/snappet.html-yBWaHH5N.js" as="script"><link rel="prefetch" href="/assets/sort.html-C_BgcWBM.js" as="script"><link rel="prefetch" href="/assets/MMU.html-CWbjpvX2.js" as="script"><link rel="prefetch" href="/assets/index.html-CVlNLbCw.js" as="script"><link rel="prefetch" href="/assets/cache.html-CqGv_8n7.js" as="script"><link rel="prefetch" href="/assets/ibs.html-DTyyhLLw.js" as="script"><link rel="prefetch" href="/assets/memory_va_page.html-5P5LJy5i.js" as="script"><link rel="prefetch" href="/assets/numa_socket.html-CYJ0cZIb.js" as="script"><link rel="prefetch" href="/assets/pipline.html-DCmp_e2x.js" as="script"><link rel="prefetch" href="/assets/x86_inst.html-D6ZWLxHA.js" as="script"><link rel="prefetch" href="/assets/index.html-BX-AnLMZ.js" as="script"><link rel="prefetch" href="/assets/index.html-CVbDMppB.js" as="script"><link rel="prefetch" href="/assets/apt.html-qA4mcNMO.js" as="script"><link rel="prefetch" href="/assets/index.html-CDUQEHd-.js" as="script"><link rel="prefetch" href="/assets/coroutines.html-CrGtibvH.js" as="script"><link rel="prefetch" href="/assets/crontab.html-Cd60F1z2.js" as="script"><link rel="prefetch" href="/assets/effective-python.html-BtB3Tmhk.js" as="script"><link rel="prefetch" href="/assets/hash.html-BoUIu4An.js" as="script"><link rel="prefetch" href="/assets/io.html-6jQ1WNw8.js" as="script"><link rel="prefetch" href="/assets/itertools.html-BMJNoro8.js" as="script"><link rel="prefetch" href="/assets/log.html-xUzl6582.js" as="script"><link rel="prefetch" href="/assets/pandas.html-C1dM82Yf.js" as="script"><link rel="prefetch" href="/assets/pip.html-Dypw9pNA.js" as="script"><link rel="prefetch" href="/assets/py-data-struct.html-kooI_52N.js" as="script"><link rel="prefetch" href="/assets/py-file.html-FIIZ-YbS.js" as="script"><link rel="prefetch" href="/assets/py-tools.html-D5bcsaO-.js" as="script"><link rel="prefetch" href="/assets/pytest.html-OgGE0eTo.js" as="script"><link rel="prefetch" href="/assets/python-function.html-CYOGmL4g.js" as="script"><link rel="prefetch" href="/assets/python-oo.html-CmZSSSvl.js" as="script"><link rel="prefetch" href="/assets/python_c.html-BvFWfxpn.js" as="script"><link rel="prefetch" href="/assets/virtualenv.html-DiNpud0U.js" as="script"><link rel="prefetch" href="/assets/hashmap.html-Dz2CKlaD.js" as="script"><link rel="prefetch" href="/assets/linkedlist.html-C7OAeKS9.js" as="script"><link rel="prefetch" href="/assets/index.html-BOnZ5GuX.js" as="script"><link rel="prefetch" href="/assets/stack.html-DjhAUPSF.js" as="script"><link rel="prefetch" href="/assets/string.html-Bz3FwYEy.js" as="script"><link rel="prefetch" href="/assets/tree.html-Br-a9aoF.js" as="script"><link rel="prefetch" href="/assets/index.html-Ba4rXWD0.js" as="script"><link rel="prefetch" href="/assets/arm_inline_assembly.html-B0KAke9u.js" as="script"><link rel="prefetch" href="/assets/arm_ins.html-D9h5RQ0O.js" as="script"><link rel="prefetch" href="/assets/index.html-BFYYmxE-.js" as="script"><link rel="prefetch" href="/assets/SAC - ISCA 23.html-09AA0ObK.js" as="script"><link rel="prefetch" href="/assets/gpu_communication.html-DXzHPo0o.js" as="script"><link rel="prefetch" href="/assets/index.html-C1Zp2-vr.js" as="script"><link rel="prefetch" href="/assets/vp_hpca14.html-CJYCI2Qm.js" as="script"><link rel="prefetch" href="/assets/vp_value_prediction.html-rqjKqjzS.js" as="script"><link rel="prefetch" href="/assets/Docker.html-MudQ_TKE.js" as="script"><link rel="prefetch" href="/assets/design-pattern.html-CiYAVGBb.js" as="script"><link rel="prefetch" href="/assets/gc.html-DwDdbuPt.js" as="script"><link rel="prefetch" href="/assets/huawei_cloud.html-CCZ0gW2z.js" as="script"><link rel="prefetch" href="/assets/jvm.html-Uyi34U3e.js" as="script"><link rel="prefetch" href="/assets/jvm_art.html-ITo72_c2.js" as="script"><link rel="prefetch" href="/assets/kernel.html-CK6PRiLb.js" as="script"><link rel="prefetch" href="/assets/kvm.html-CBLf4nNV.js" as="script"><link rel="prefetch" href="/assets/linux_os.html-CnVgO5VK.js" as="script"><link rel="prefetch" href="/assets/nginx.html-Cq_uSALv.js" as="script"><link rel="prefetch" href="/assets/openresty.html-BVsqn9s8.js" as="script"><link rel="prefetch" href="/assets/snap.html-CnWdZnr8.js" as="script"><link rel="prefetch" href="/assets/mongodb.html-DJN7sRQP.js" as="script"><link rel="prefetch" href="/assets/mysql.html-B3bc5n7F.js" as="script"><link rel="prefetch" href="/assets/peewee.html-p9gb8JFw.js" as="script"><link rel="prefetch" href="/assets/redis.html-ACAEk0k1.js" as="script"><link rel="prefetch" href="/assets/celery.html-cDD9IPkc.js" as="script"><link rel="prefetch" href="/assets/flask.html-BVjFlLLQ.js" as="script"><link rel="prefetch" href="/assets/spring.html-D5s6F21i.js" as="script"><link rel="prefetch" href="/assets/chartsjs.html-_Hi8cUhq.js" as="script"><link rel="prefetch" href="/assets/css.html-DOgGeuCI.js" as="script"><link rel="prefetch" href="/assets/jsnote.html-D_jaGu96.js" as="script"><link rel="prefetch" href="/assets/node_install.html-CmtBQ1rX.js" as="script"><link rel="prefetch" href="/assets/vue.html-Dqt1Gblp.js" as="script"><link rel="prefetch" href="/assets/epoll.html-Bcw8HLHg.js" as="script"><link rel="prefetch" href="/assets/http.html-hQEs5kwH.js" as="script"><link rel="prefetch" href="/assets/networks.html-CN9xVKX7.js" as="script"><link rel="prefetch" href="/assets/code_life.html-CDQGU-NF.js" as="script"><link rel="prefetch" href="/assets/new.html-D7TkZNlV.js" as="script"><link rel="prefetch" href="/assets/paper_report.html-BWxBZGu5.js" as="script"><link rel="prefetch" href="/assets/soft_skills.html-CoR5flex.js" as="script"><link rel="prefetch" href="/assets/thoughts-2018.html-Cl_wNRe8.js" as="script"><link rel="prefetch" href="/assets/worklog.html-CbEAWpO4.js" as="script"><link rel="prefetch" href="/assets/zen_of_python.html-DjjNB24O.js" as="script"><link rel="prefetch" href="/assets/blog_plan.html-BUH5W6bZ.js" as="script"><link rel="prefetch" href="/assets/jekyll.html-Dl6vWkhw.js" as="script"><link rel="prefetch" href="/assets/kilo.html-DRtf-EN5.js" as="script"><link rel="prefetch" href="/assets/qqbot.html-CHBL4Maf.js" as="script"><link rel="prefetch" href="/assets/vueblog.html-BO53P7n5.js" as="script"><link rel="prefetch" href="/assets/ArrayTrack.html-yho5LwA0.js" as="script"><link rel="prefetch" href="/assets/RF-Pose.html-D6K6uIBj.js" as="script"><link rel="prefetch" href="/assets/cnn.html-BIebAlXT.js" as="script"><link rel="prefetch" href="/assets/csitool.html-E-MBdb_8.js" as="script"><link rel="prefetch" href="/assets/cvpr.html-BJfAtlTw.js" as="script"><link rel="prefetch" href="/assets/face_recognition.html-DoB8VJ3H.js" as="script"><link rel="prefetch" href="/assets/information_theory.html-DtmkkHAs.js" as="script"><link rel="prefetch" href="/assets/latex.html-BQsiUShC.js" as="script"><link rel="prefetch" href="/assets/mnist.html-COmKsga0.js" as="script"><link rel="prefetch" href="/assets/opencv.html-CEtNG21b.js" as="script"><link rel="prefetch" href="/assets/splicer.html-lIbOq7tr.js" as="script"><link rel="prefetch" href="/assets/tensorflow.html-CyTbLA2F.js" as="script"><link rel="prefetch" href="/assets/tensorflowio.html-BGFIhNlc.js" as="script"><link rel="prefetch" href="/assets/bat_win.html-Bk9ILE1R.js" as="script"><link rel="prefetch" href="/assets/git.html-k3Fl1prN.js" as="script"><link rel="prefetch" href="/assets/vim.html-CXoTbNJo.js" as="script"><link rel="prefetch" href="/assets/vps.html-BrH7irnU.js" as="script"><link rel="prefetch" href="/assets/adb.html-Dmc5qPtT.js" as="script"><link rel="prefetch" href="/assets/binder.html-C-Y6MnwP.js" as="script"><link rel="prefetch" href="/assets/binder_01.html-CLjTtG51.js" as="script"><link rel="prefetch" href="/assets/binder_02.html-CM-GPvY7.js" as="script"><link rel="prefetch" href="/assets/ipc.html-DefEdPpM.js" as="script"><link rel="prefetch" href="/assets/parcel.html-DpaAgCw2.js" as="script"><link rel="prefetch" href="/assets/art_create.html-D9EGoxVV.js" as="script"><link rel="prefetch" href="/assets/art_dex2oat.html-DYkXljq2.js" as="script"><link rel="prefetch" href="/assets/art_jni.html-C12CGD_h.js" as="script"><link rel="prefetch" href="/assets/gc_art_01.html-DZc-fvJ4.js" as="script"><link rel="prefetch" href="/assets/01_jvm_memory.html-DfNV7Kn7.js" as="script"><link rel="prefetch" href="/assets/gc_g1.html-DKO2CbK6.js" as="script"><link rel="prefetch" href="/assets/jvm_inst.html-rS5qNZ14.js" as="script"><link rel="prefetch" href="/assets/reflection.html-DcakEpls.js" as="script"><link rel="prefetch" href="/assets/index.html-CgR7FO1Z.js" as="script"><link rel="prefetch" href="/assets/c-pointer.html-DfESFfVY.js" as="script"><link rel="prefetch" href="/assets/cmake.html-CoiUro2O.js" as="script"><link rel="prefetch" href="/assets/cmake_makefile.html-B7fwZ60E.js" as="script"><link rel="prefetch" href="/assets/command.html-CxyvSJNj.js" as="script"><link rel="prefetch" href="/assets/linkers_loaders.html-BYhVf0Nx.js" as="script"><link rel="prefetch" href="/assets/size_t.html-P_VhBC4I.js" as="script"><link rel="prefetch" href="/assets/BL31.html-BVGIdJE1.js" as="script"><link rel="prefetch" href="/assets/index.html-Cw7hBeaV.js" as="script"><link rel="prefetch" href="/assets/THP.html-BgszrdN2.js" as="script"><link rel="prefetch" href="/assets/i2c.html-Cdv6sklB.js" as="script"><link rel="prefetch" href="/assets/idle.html-ChJzhS5K.js" as="script"><link rel="prefetch" href="/assets/idle_tick.html-B2YB7IRM.js" as="script"><link rel="prefetch" href="/assets/notifier.html-amrxXrsW.js" as="script"><link rel="prefetch" href="/assets/pthread.html-BT7_v0kx.js" as="script"><link rel="prefetch" href="/assets/rcu.html-FfJx3phg.js" as="script"><link rel="prefetch" href="/assets/thermal.html-VVfuHC0a.js" as="script"><link rel="prefetch" href="/assets/thermal_init.html-BRrhQCR8.js" as="script"><link rel="prefetch" href="/assets/thermal_init_h.html-BlLhRbva.js" as="script"><link rel="prefetch" href="/assets/xv6.html-C2L34VUt.js" as="script"><link rel="prefetch" href="/assets/Marketing.html-uf-E19-U.js" as="script"><link rel="prefetch" href="/assets/code_simple.html-BShYgCfA.js" as="script"><link rel="prefetch" href="/assets/index.html-Puvv2PvI.js" as="script"><link rel="prefetch" href="/assets/review.html-C5fwjz46.js" as="script"><link rel="prefetch" href="/assets/bpytop.html-Co8G0OAa.js" as="script"><link rel="prefetch" href="/assets/gem.html-Du88YrMP.js" as="script"><link rel="prefetch" href="/assets/on-my-zsh.html-Dak2rqxa.js" as="script"><link rel="prefetch" href="/assets/others.html-BrVHU_kI.js" as="script"><link rel="prefetch" href="/assets/index.html-CFa_f4_8.js" as="script"><link rel="prefetch" href="/assets/tools.html-JgwufGBY.js" as="script"><link rel="prefetch" href="/assets/vps.html-VWZX_1v1.js" as="script"><link rel="prefetch" href="/assets/yarn.html-Dpf1xqOG.js" as="script"><link rel="prefetch" href="/assets/404.html-DGwkcVIS.js" as="script"><link rel="prefetch" href="/assets/index.html-L-6zRB91.js" as="script"><link rel="prefetch" href="/assets/index.html-CYNsqs1h.js" as="script"><link rel="prefetch" href="/assets/index.html-DYe54yC2.js" as="script"><link rel="prefetch" href="/assets/index.html-BhUeJixe.js" as="script"><link rel="prefetch" href="/assets/index.html-lnwOVy3X.js" as="script"><link rel="prefetch" href="/assets/index.html-0Kzu24fa.js" as="script"><link rel="prefetch" href="/assets/index.html-DIEXX-3a.js" as="script"><link rel="prefetch" href="/assets/index.html-Bwb7X5To.js" as="script"><link rel="prefetch" href="/assets/index.html-Bpy2tFs7.js" as="script"><link rel="prefetch" href="/assets/index.html-A9YGej71.js" as="script"><link rel="prefetch" href="/assets/index.html-DpQxhiFJ.js" as="script"><link rel="prefetch" href="/assets/index.html-CMelKNBC.js" as="script"><link rel="prefetch" href="/assets/index.html-CQzOsDLT.js" as="script"><link rel="prefetch" href="/assets/index.html-a_I1I-PL.js" as="script"><link rel="prefetch" href="/assets/index.html-JwjjRDi4.js" as="script"><link rel="prefetch" href="/assets/index.html-C-bqHIny.js" as="script"><link rel="prefetch" href="/assets/index.html-trE1Ziu_.js" as="script"><link rel="prefetch" href="/assets/index.html-C05kIRim.js" as="script"><link rel="prefetch" href="/assets/index.html-hdvtbUSo.js" as="script"><link rel="prefetch" href="/assets/index.html-C8cWcl0p.js" as="script"><link rel="prefetch" href="/assets/index.html-u3pkU2-U.js" as="script"><link rel="prefetch" href="/assets/index.html-Dp_ja6pe.js" as="script"><link rel="prefetch" href="/assets/index.html-DL7RerrT.js" as="script"><link rel="prefetch" href="/assets/index.html-nZWaW2sa.js" as="script"><link rel="prefetch" href="/assets/index.html-BLueIjZK.js" as="script"><link rel="prefetch" href="/assets/index.html-QbIv_0P9.js" as="script"><link rel="prefetch" href="/assets/index.html-khWvmriZ.js" as="script"><link rel="prefetch" href="/assets/index.html-DTTh2g2g.js" as="script"><link rel="prefetch" href="/assets/index.html-B7I8Ik06.js" as="script"><link rel="prefetch" href="/assets/index.html-DFhkPmmQ.js" as="script"><link rel="prefetch" href="/assets/index.html-BNsBrDLd.js" as="script"><link rel="prefetch" href="/assets/index.html-DG40OQm-.js" as="script"><link rel="prefetch" href="/assets/index.html-DG1wzJml.js" as="script"><link rel="prefetch" href="/assets/index.html-BGcwbbEd.js" as="script"><link rel="prefetch" href="/assets/index.html-D_9h0pHQ.js" as="script"><link rel="prefetch" href="/assets/index.html-DL7RerrT.js" as="script"><link rel="prefetch" href="/assets/index.html-DfysevBq.js" as="script"><link rel="prefetch" href="/assets/index.html-DBzZyRhs.js" as="script"><link rel="prefetch" href="/assets/index.html-N-vwOs3N.js" as="script"><link rel="prefetch" href="/assets/index.html-D2SnN9re.js" as="script"><link rel="prefetch" href="/assets/index.html-CP-oJQZk.js" as="script"><link rel="prefetch" href="/assets/index.html-DmkT3Q_4.js" as="script"><link rel="prefetch" href="/assets/index.html-oSxiMd2n.js" as="script"><link rel="prefetch" href="/assets/index.html-BO--K8hH.js" as="script"><link rel="prefetch" href="/assets/index.html-DRlow2_v.js" as="script"><link rel="prefetch" href="/assets/index.html-CIvTE1R-.js" as="script"><link rel="prefetch" href="/assets/index.html-ECAz77Os.js" as="script"><link rel="prefetch" href="/assets/index.html-BKpHmwGa.js" as="script"><link rel="prefetch" href="/assets/index.html-Kz4F9_sJ.js" as="script"><link rel="prefetch" href="/assets/index.html-BCgGyJ6n.js" as="script"><link rel="prefetch" href="/assets/index.html-DdcPewlV.js" as="script"><link rel="prefetch" href="/assets/index.html-B67UQrwL.js" as="script"><link rel="prefetch" href="/assets/index.html-B7xCWEXZ.js" as="script"><link rel="prefetch" href="/assets/index.html-DOEYPJMu.js" as="script"><link rel="prefetch" href="/assets/index.html-WNAVKcvg.js" as="script"><link rel="prefetch" href="/assets/index.html-DOEYPJMu.js" as="script"><link rel="prefetch" href="/assets/index.html-Be-5T_XY.js" as="script"><link rel="prefetch" href="/assets/index.html-BrB2oU8y.js" as="script"><link rel="prefetch" href="/assets/index.html-CTGzFNDH.js" as="script"><link rel="prefetch" href="/assets/index.html-PnmPKqdn.js" as="script"><link rel="prefetch" href="/assets/index.html-Z0Dd8uwb.js" as="script"><link rel="prefetch" href="/assets/index.html-W4MI9YUO.js" as="script"><link rel="prefetch" href="/assets/index.html-BrB2oU8y.js" as="script"><link rel="prefetch" href="/assets/index.html-aKzoM5Np.js" as="script"><link rel="prefetch" href="/assets/index.html-DuoWM8kk.js" as="script"><link rel="prefetch" href="/assets/index.html-C5tYZ9WE.js" as="script"><link rel="prefetch" href="/assets/index.html-1A31cbow.js" as="script"><link rel="prefetch" href="/assets/index.html-SI3Co-Gr.js" as="script"><link rel="prefetch" href="/assets/index.html-Uy5m97KV.js" as="script"><link rel="prefetch" href="/assets/index.html--r4aQEjh.js" as="script"><link rel="prefetch" href="/assets/index.html-Clsdwxzd.js" as="script"><link rel="prefetch" href="/assets/index.html-D-UwJTvB.js" as="script"><link rel="prefetch" href="/assets/index.html-8zTIKicp.js" as="script"><link rel="prefetch" href="/assets/index.html-8eqwGHJO.js" as="script"><link rel="prefetch" href="/assets/index.html-DrRuMq6U.js" as="script"><link rel="prefetch" href="/assets/index.html-BrXWuUm5.js" as="script"><link rel="prefetch" href="/assets/index.html-zSZk-Y8F.js" as="script"><link rel="prefetch" href="/assets/index.html-BPzdk3Uv.js" as="script"><link rel="prefetch" href="/assets/index.html-Bs5eld_8.js" as="script"><link rel="prefetch" href="/assets/index.html-CBPpfPLC.js" as="script"><link rel="prefetch" href="/assets/index.html-DtD-VJQg.js" as="script"><link rel="prefetch" href="/assets/index.html-B3-AZZLB.js" as="script"><link rel="prefetch" href="/assets/index.html-BUvx7RyV.js" as="script"><link rel="prefetch" href="/assets/index.html-DeCPz8wv.js" as="script"><link rel="prefetch" href="/assets/index.html-BoF-ao4T.js" as="script"><link rel="prefetch" href="/assets/index.html-BrIT_EuW.js" as="script"><link rel="prefetch" href="/assets/index.html-oGmch48D.js" as="script"><link rel="prefetch" href="/assets/index.html-CSlK9Gdr.js" as="script"><link rel="prefetch" href="/assets/index.html-OXZaufv4.js" as="script"><link rel="prefetch" href="/assets/index.html-BYvVkuV1.js" as="script"><link rel="prefetch" href="/assets/index.html-ClJfYtOd.js" as="script"><link rel="prefetch" href="/assets/index.html-CFFrJF7J.js" as="script"><link rel="prefetch" href="/assets/index.html-LX6b_Ctd.js" as="script"><link rel="prefetch" href="/assets/index.html-Dy7gLI01.js" as="script"><link rel="prefetch" href="/assets/index.html-BVmOSuLb.js" as="script"><link rel="prefetch" href="/assets/index.html-Do59p0gD.js" as="script"><link rel="prefetch" href="/assets/index.html-XfcX9Qfg.js" as="script"><link rel="prefetch" href="/assets/index.html-CzCxSuG7.js" as="script"><link rel="prefetch" href="/assets/index.html-CyL6-bq0.js" as="script"><link rel="prefetch" href="/assets/index.html-PnmPKqdn.js" as="script"><link rel="prefetch" href="/assets/index.html-DkS71JnZ.js" as="script"><link rel="prefetch" href="/assets/index.html-M_VMkmfA.js" as="script"><link rel="prefetch" href="/assets/index.html-Cn2hMPQ7.js" as="script"><link rel="prefetch" href="/assets/auto-C3mEb9gQ.js" as="script"><link rel="prefetch" href="/assets/mermaid.esm.min-BeePAOX2.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-DXWKOczD.js" as="script"><link rel="prefetch" href="/assets/giscus-1zs_z9NH.js" as="script"><link rel="prefetch" href="/assets/SearchResult-CuoDb2Js.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container external-link-icon pure has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="带我回家"><img class="vp-nav-logo" src="/excellence.png" alt><!----><span class="vp-site-name hide-in-pad">weigao</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="博客主页"><!--[--><iconify-icon class="vp-icon" icon="material-symbols:book-2" height="1em" sizing="height"></iconify-icon><!--]-->博客主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/home.html" aria-label="项目主页"><!--[--><iconify-icon class="vp-icon" icon="material-symbols:home-and-garden" height="1em" sizing="height"></iconify-icon><!--]-->项目主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/category/" aria-label="Blog"><!--[--><iconify-icon class="vp-icon" icon="material-symbols:book-ribbon" height="1em" sizing="height"></iconify-icon><!--]-->Blog<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/algorithm/" aria-label="Algorithm"><!--[--><iconify-icon class="vp-icon" icon="fluent-emoji-high-contrast:thinking-face" height="1em" sizing="height"></iconify-icon><!--]-->Algorithm<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/python/" aria-label="Python"><!--[--><iconify-icon class="vp-icon" icon="akar-icons:python-fill" height="1em" sizing="height"></iconify-icon><!--]-->Python<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/linux/" aria-label="Linux"><!--[--><iconify-icon class="vp-icon" icon="fluent-mdl2:linux-logo-32" height="1em" sizing="height"></iconify-icon><!--]-->Linux<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/architecture/" aria-label="Arch"><!--[--><iconify-icon class="vp-icon" icon="oui:compute" height="1em" sizing="height"></iconify-icon><!--]-->Arch<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/java/" aria-label="Java"><!--[--><iconify-icon class="vp-icon" icon="ri:java-line" height="1em" sizing="height"></iconify-icon><!--]-->Java<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/timeline/" aria-label="TimeLine"><!--[--><iconify-icon class="vp-icon" icon="icon-park-outline:timeline" height="1em" sizing="height"></iconify-icon><!--]-->TimeLine<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Others"><!--[--><iconify-icon class="vp-icon" icon="basil:other-1-outline" height="1em" sizing="height"></iconify-icon>Others<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/others/tools/" aria-label="Tools"><!--[--><iconify-icon class="vp-icon" icon="mdi:tools" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->Tools<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/others/tmp/" aria-label="Temp"><!--[--><iconify-icon class="vp-icon" icon="carbon:prompt-template" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->Temp<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="auto-link external-link" href="https://theme-hope.vuejs.press/zh/" aria-label="主题文档" rel="noopener noreferrer" target="_blank"><!--[--><iconify-icon class="vp-icon" icon="material-symbols:zoom-out-map" height="1em" sizing="height"></iconify-icon><!--]-->主题文档<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/chenweigao" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--[--><button type="button" class="slimsearch-button" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="slimsearch-placeholder">搜索</div><div class="slimsearch-key-hints"><kbd class="slimsearch-key">Ctrl</kbd><kbd class="slimsearch-key">K</kbd></div></button><!--]--><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/architecture/" aria-label="Architecture"><!---->Architecture<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Arm</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Papers</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">GPU &amp; AI</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/architecture/gpu-ai/" aria-label="Abstract"><!---->Abstract<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/architecture/gpu-ai/gpu_arch.html" aria-label="GPU Architecture"><!---->GPU Architecture<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/architecture/gpu-ai/gpu_communication.html" aria-label="GPU Communication"><!---->GPU Communication<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/architecture/gpu-ai/SAC%20-%20ISCA%2023.html" aria-label="SAC - ISCA 23"><!---->SAC - ISCA 23<!----></a></li></ul></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/architecture/pipline.html" aria-label="Pipeline"><!---->Pipeline<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/architecture/memory_va_page.html" aria-label="Virtual Memory and Page"><!---->Virtual Memory and Page<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/architecture/numa_socket.html" aria-label="Numa and Socket"><!---->Numa and Socket<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/architecture/cache.html" aria-label="Cache"><!---->Cache<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/architecture/x86_inst.html" aria-label="Instructions of x86"><!---->Instructions of x86<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/architecture/MMU.html" aria-label="MMU"><!---->MMU<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/architecture/ibs.html" aria-label="AMD IBS"><!---->AMD IBS<!----></a></li></ul><!----></aside><!--[--><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->GPU Architecture</h1><div class="page-info"><span class="page-author-info" aria-label="作者"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://www.weigao.cc" target="_blank" rel="noopener noreferrer">Someone</a></span><span property="author" content="Someone"></span></span><!----><span class="page-date-info" aria-label="写作日期"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025/3/6</span><meta property="datePublished" content="2025-03-06T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 33 分钟</span><meta property="timeRequired" content="PT33M"></span><!----><span class="page-tag-info" aria-label="标签"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item clickable" role="navigation">GPU</span><span class="page-tag-item clickable" role="navigation">AI</span><!--]--><meta property="keywords" content="GPU,AI"></span></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><h2 id="_1-量化研究方法" tabindex="-1"><a class="header-anchor" href="#_1-量化研究方法"><span>1. 量化研究方法</span></a></h2><h2 id="_2-4-4-图形处理器" tabindex="-1"><a class="header-anchor" href="#_2-4-4-图形处理器"><span>2. 4.4 图形处理器</span></a></h2><p>CPU 程序员的挑战不只是在 GPU 上获得出色的性能，还有<mark>协调系统处理器与 GPU 上的计算调度，以及系统存储器与 GPU 存储器之间的数据传输</mark>。</p><p>GPU 中的并行：多线程、MIMD、SIMD 和指令级并行。</p><p>NVIDIA 将 CUDA 编程定义为 <strong>SIMT</strong> -- <mark>单指令多线程</mark>。</p><p>并行执行和线程管理由 GPU 硬件负责，而不是由应用程序或者操作系统完成。<a href="#3-q1-%E5%85%B7%E4%BD%93%E8%A7%A3%E9%87%8A">详解见 Q1</a></p><blockquote><p>The hardware Thread Block Scheduler assigns Thread Blocks to multithreaded SIMD Processors, and the hardware Thread Scheduler picks which thread of SIMD instructions to run each clock cycle within a SIMD Processor.</p></blockquote><p>硬件线程块调度器（Thread Block Scheduler）将线程块（Thread Blocks）分配给多线程 SIMD 处理器（multithreaded SIMD Processors），而硬件线程调度器（Thread Scheduler）在每个时钟周期内选择要在 SIMD 处理器中运行的 SIMD 指令线程（thread of SIMD instructions）。详细解释见 <a href="#q2">Q2</a></p><h2 id="_3-stream-kernel-device" tabindex="-1"><a class="header-anchor" href="#_3-stream-kernel-device"><span>3. Stream, kernel, device</span></a></h2><h3 id="_3-1-关系图" tabindex="-1"><a class="header-anchor" href="#_3-1-关系图"><span>3.1. 关系图</span></a></h3><p>这几个概念在 GPU 编程中很常见，其关系可以简单由下图表示：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#24292e;--shiki-dark:#d8dee9ff;--shiki-light-bg:#fff;--shiki-dark-bg:#2e3440ff;"><pre class="shiki shiki-themes github-light nord vp-code"><code><span class="line"><span>+------------------+              +----------------+</span></span>
<span class="line"><span>|     Host (CPU)   |              |   Device (GPU) |</span></span>
<span class="line"><span>|                  |              |                |</span></span>
<span class="line"><span>|  Launch Kernel   | -----------&gt; |  Kernel Grid   |</span></span>
<span class="line"><span>|                  |              |  Thread Blocks |</span></span>
<span class="line"><span>|                  |              |  Threads       |</span></span>
<span class="line"><span>+------------------+              +----------------+</span></span>
<span class="line"><span>         |                                 ▲</span></span>
<span class="line"><span>         |      控制流/数据拷贝              |</span></span>
<span class="line"><span>         |                                 |</span></span>
<span class="line"><span>         v                                 |</span></span>
<span class="line"><span>   +----------------+             +------------------+</span></span>
<span class="line"><span>   |    Stream 0    | ----------&gt; |  Kernel A        |</span></span>
<span class="line"><span>   +----------------+             +------------------+</span></span>
<span class="line"><span>   |    Stream 1    | ----------&gt; |  Kernel B        |</span></span>
<span class="line"><span>   +----------------+             +------------------+</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_3-2-device" tabindex="-1"><a class="header-anchor" href="#_3-2-device"><span>3.2. Device</span></a></h3><p><strong>Device</strong> 是指 <strong>GPU 本身</strong>，相对于运行主程序的 <strong>host（通常是 CPU）</strong>。</p><ul><li><p>在多 GPU 系统中，每个 GPU 都是一个 device。</p></li><li><p>可以用 API 来查询和选择当前使用的 device（例如 cudaSetDevice () 或 hipSetDevice ()）。</p></li><li><p>GPU 的内存（device memory）和 CPU 的内存是分开的，通常需要显式拷贝数据。</p></li></ul><p>一个 GPU（device）内部通常包含多个 <strong>SM（Streaming Multiprocessors）</strong>，每个 SM 可以并发执行多个 <strong>warp</strong>（每个 warp 是 32 个线程的调度单元）。</p><h3 id="_3-3-kernel" tabindex="-1"><a class="header-anchor" href="#_3-3-kernel"><span>3.3. Kernel</span></a></h3><p><strong>Kernel</strong> 是运行在 GPU 上的 <strong>函数</strong>，由 host 发起调用。</p><ul><li><p>Kernel 是大规模并行执行的最小执行单元，多个线程并发运行同一个 kernel。</p></li><li><p>在 CUDA/ROCm 中，通过语法类似 <code>kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;(...)</code> 来发起执行。</p><ul><li><p>Grid: 指的是 thread blocks 的网格布局</p></li><li><p>Block: 指的是 block 中线程的个数和布局</p></li></ul></li><li><p>Kernel 执行时的数据并行性由开发者设计。</p></li></ul><p>一个 kernel 实际上被分割为多个 block，每个 block 被绑定到一个 SM，直到所有 block 执行完成为止。</p><h3 id="_3-4-stream" tabindex="-1"><a class="header-anchor" href="#_3-4-stream"><span>3.4. Stream</span></a></h3><p><strong>Stream</strong> 是 GPU 上执行指令的 <strong>执行队列</strong>。</p><ul><li><p>每个 stream 中的操作是 <strong>顺序执行</strong> 的，但不同 stream 可以并行执行。</p></li><li><p>可以利用多个 stream 来实现 kernel 执行和数据拷贝的并发（比如 copy + compute overlap）。</p></li><li><p>默认的 stream 是 0，叫 <strong>default stream</strong> 或 <strong>legacy stream</strong>。</p></li><li><p>非默认 stream 被称为 <strong>explicit streams</strong>，允许更细粒度的并发控制。</p></li></ul><p>实际的硬件交互映射关系如下图所示：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#24292e;--shiki-dark:#d8dee9ff;--shiki-light-bg:#fff;--shiki-dark-bg:#2e3440ff;"><pre class="shiki shiki-themes github-light nord vp-code"><code><span class="line"><span>+--------------------+            +---------------------------+</span></span>
<span class="line"><span>|   CPU (Host)       |            |         GPU               |</span></span>
<span class="line"><span>|--------------------|            |---------------------------|</span></span>
<span class="line"><span>| API: cudaMemcpy    |  ======&gt;   | DMA Engine                |</span></span>
<span class="line"><span>| API: kernel launch |  ======&gt;   | Command Processor (GPC)   |</span></span>
<span class="line"><span>|                    |            |  └── dispatch to SMs      |</span></span>
<span class="line"><span>+--------------------+            |     └── Warp Schedulers   |</span></span>
<span class="line"><span>                                  |         └── Threads       |</span></span>
<span class="line"><span>                                  +---------------------------+</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>再参考 GPU 的存储结构设计以加深印象：</p><figure><img src="/assets/gpu_1-1744183885388-Bdm7BTnJ.png" alt="gpu_1-1744183885388" tabindex="0" width="444" height="445" loading="lazy"><figcaption>gpu_1-1744183885388|444x445</figcaption></figure><h2 id="_4-warp" tabindex="-1"><a class="header-anchor" href="#_4-warp"><span>4. Warp</span></a></h2><h3 id="_4-1-todo" tabindex="-1"><a class="header-anchor" href="#_4-1-todo"><span>4.1. Todo</span></a></h3><h2 id="_5-q1" tabindex="-1"><a class="header-anchor" href="#_5-q1"><span>5. Q1</span></a></h2><blockquote><p>并行执行和线程管理由 GPU 硬件负责，而不是由应用程序或者操作系统完成。</p></blockquote><p>这句话的含义是：在 GPU 中，并行任务的执行和线程调度完全由硬件架构直接管理，而非依赖应用程序或操作系统的软件层面控制。这种设计使得 GPU 能够高效实现大规模并行计算，同时降低编程复杂度。</p><h3 id="_5-1-具体解释" tabindex="-1"><a class="header-anchor" href="#_5-1-具体解释"><span>5.1. 具体解释</span></a></h3><p>以下是具体解释：</p><p><strong>硬件直接管理并行执行</strong>：GPU 通过 <strong>SIMT（单指令多线程）</strong> 架构实现并行性。其核心思想是：单条指令同时控制多个线程，这些线程<strong>共享指令流但处理不同的数据</strong>。例如，一个线程束（Warp）包含 32 或 64 个线程，由硬件调度器自动分配到流多处理器（SM）的计算单元上执行。同一 Warp 内的线程必须执行相同指令，但每个线程的数据路径独立，因此可以灵活处理分支逻辑（如条件判断）。 相比之下，CPU 的并行执行依赖操作系统的线程调度（如多核任务分配），而 GPU 的线程调度完全由硬件实现，无需软件介入。</p><p><strong>线程模型的硬件抽象</strong>：GPU 的编程模型（如 CUDA）提供了线程网格（Grid）、线程块（Block）和线程（Thread）的逻辑划分，但实际的线程分配与执行由硬件完成：</p><ul><li>线程网格（Grid）：由多个线程块组成，表示整个计算任务的规模。</li><li>线程块（Block）：一组线程的集合，绑定到一个流多处理器（SM）上执行。同一块内的线程可通过共享内存协作。</li><li>线程（Thread）：最小执行单元，由硬件直接调度。 程序员只需定义线程结构（如 <code>&gt;&gt;</code>），硬件自动将线程块分配到 SM，并通过线程调度器管理 Warp 的执行顺序，隐藏内存延迟。</li></ul><p><strong>硬件资源的自动分配</strong>：GPU 的硬件设计专门优化了线程管理：</p><ul><li><mark>流多处理器（SM）</mark>：每个 SM 包含多个计算核心（CUDA Core）、共享内存、寄存器文件等资源。SM 可同时运行多个线程块，通过上下文切换（Context Switch）高效利用硬件资源。</li><li>线程调度器：SM 中的调度器（如 Warp Scheduler）根据线程状态（如是否等待数据）动态选择可执行的 Warp，最大化硬件利用率。</li><li>内存层次：全局内存、共享内存等的访问由硬件自动优化，减少程序员对内存延迟的显式处理。</li></ul><h2 id="_6-sm" tabindex="-1"><a class="header-anchor" href="#_6-sm"><span>6. SM</span></a></h2><h3 id="_6-1-sm-的发展" tabindex="-1"><a class="header-anchor" href="#_6-1-sm-的发展"><span>6.1. SM 的发展</span></a></h3><p>流多处理器（SM）架构随着 GPU 技术的发展不断演进，从最初注重并行处理基本功能，到如今在计算能力、存储管理、指令处理和能效优化等多方面全面提升，以适应日益复杂的计算需求。</p><ol><li><strong>早期架构与并行处理基础构建（2000 年代初 - 2006 年左右）</strong>：在 GPU 发展早期，SM 架构开始崭露头角。以英伟达早期产品为例，其主要聚焦于图形处理任务，架构设计围绕并行处理图形数据展开。此时的 SM 包含多个处理核心，能并行处理顶点和像素数据，不过<mark>处理核心数量相对较少</mark>，缓存和共享内存的规模有限，指令集也主要针对图形渲染优化，比如处理图形的几何变换、光照计算等。</li><li><strong>计算能力扩展与通用计算支持（2006 - 2012 年）</strong>：随着通用计算需求的增长，SM 架构迎来变革。<mark><em>英伟达推出 CUDA 架构后，SM 开始支持通用计算</em></mark>。处理核心数量大幅增加，提高了并行计算能力，可处理复杂的矩阵运算、数值模拟等任务。共享内存容量显著提升，方便线程间数据共享，还引入了更灵活的线程调度机制，能够同时管理和执行大量线程，提高计算效率。</li><li><strong>架构优化与性能提升（2012 - 2018 年）</strong>：这一时期，SM 架构持续优化。处理核心性能增强，在单位时间内可完成更多计算操作。缓存层次结构更加完善，增加了缓存容量，优化了缓存算法，提升数据访问速度。<mark><em>指令集进一步丰富，支持更多复杂的计算指令</em></mark>。此外，引入了更高效的内存管理机制，减少内存访问延迟，提高整体性能。</li><li><strong>面向深度学习的变革（2018 年至今）</strong>：深度学习兴起，SM 架构再次升级。英伟达的安培架构中，SM 集成了专门的 Tensor Core，针对深度学习中的矩阵运算进行加速，大幅提升计算速度。引入稀疏计算支持，提高对稀疏数据的处理效率。在能效方面也进行了优化，降低功耗的同时提高计算性能，以满足大规模深度学习模型训练和推理的需求。</li></ol><h3 id="_6-2-sm-基本信息" tabindex="-1"><a class="header-anchor" href="#_6-2-sm-基本信息"><span>6.2. SM 基本信息</span></a></h3><p>SM 是 GPU 中最基本的并行计算单元，相当于一个 “微型处理器集群”，负责调度和执行线程块（Thread Block）内的所有计算任务。</p><ul><li><strong>核心功能</strong>： <ul><li>管理数百个线程的并行执行（通过硬件线程调度器）；</li><li>集成多种计算单元（CUDA Core、Tensor Core）、缓存、寄存器等，实现高效计算。</li></ul></li><li><strong>架构演进</strong>：不同代次架构（如 Volta、Ampere、Hopper、Ada Lovelace）的 SM 设计不同，核心变化在于 Tensor Core 的引入与升级，以及 CUDA Core 的优化。</li></ul><p><img src="/assets/gpu_arch-1746957490426-BRdHHJH0.png" alt="" width="379" height="399" loading="lazy"> (<em>早期 GPU 微架构，具体可参考项目中的 Excalidraw</em>)</p><p>SM 架构对比，以 Hopper vs Ada Lovelace 为例：</p><table><thead><tr><th><strong>架构</strong></th><th><strong>SM 核心组件</strong></th><th><strong>Tensor Core 特性</strong></th><th><strong>CUDA Core 数量 / SM</strong></th></tr></thead><tbody><tr><td><strong>Hopper (H100)</strong></td><td>包含 CUDA Core、第四代 Tensor Core、共享内存、寄存器文件、线程调度器等</td><td>支持 FP8/INT4 / 稀疏化，FP16 矩阵运算吞吐量提升</td><td>128</td></tr><tr><td><strong>Ada Lovelace (L40S)</strong></td><td>类似 Hopper，但优化了图形相关单元（如 RT Core），Tensor Core 支持 INT4 稀疏化</td><td>强化 INT4/FP8 推理加速，兼容图形与计算任务</td><td>128</td></tr></tbody></table><h3 id="_6-3-tensor-core" tabindex="-1"><a class="header-anchor" href="#_6-3-tensor-core"><span>6.3. Tensor Core</span></a></h3><p>SM（Streaming Multiprocessor，流多处理器）和 Tensor Core（张量核心，<strong>矩阵核心，专用加速单元</strong>）都是 NVIDIA GPU 中的关键组件，它们相互协作，共同提升 GPU 在不同计算任务中的性能。</p><p><strong>Tensor Core 是 SM 的组成部分</strong>：在 NVIDIA 的 GPU 架构中，如 Volta、Turing 和 Ampere 等，Tensor Core 是集成在 SM 内部的专用处理单元。以 Volta 架构为例，一个 SM 由 4 个 Sub Core 组成，每个 Sub Core 内含有两个 4x4x4 Tensor Core 。Turing 架构的 SM 中，则包含 8 个 Turing Tensor Core。这表明 Tensor Core 是 SM 架构的一部分，依托 SM 的整体架构发挥作用。</p><p><strong>功能上相互配合</strong>：SM 负责管理和执行大量线程，具备强大的并行数据处理能力，其中的 CUDA 核心能执行通用的并行计算任务，处理各种类型的计算指令。而 Tensor Core 是专门为加速深度学习中的矩阵乘法和累加操作设计的，在深度学习训练和推理任务中，当遇到矩阵运算时，Warp Scheduler（负责调度计算单元工作）会向 Tensor Core 发送矩阵乘法 GEMM 运算指令，Tensor Core 接收来自寄存器文件的输入矩阵，执行矩阵乘法操作，并将结果写回寄存器文件。这体现了 SM 的线程管理和通用计算能力，与 Tensor Core 的深度学习矩阵运算加速能力相互配合。</p><p><strong>共同提升计算性能</strong>：SM 的架构设计为 Tensor Core 提供了运行环境和数据交互支持，如 SM 中的 L1 指令缓存、L1 数据缓存和共享内存等组件，保障了 Tensor Core 所需数据的读取和计算结果的存储。Tensor Core 的高效矩阵运算能力又提升了 SM 在深度学习任务上的处理速度，两者协同工作，使得 GPU 在通用计算和深度学习等多领域都能有出色的性能表现。</p><h4 id="_6-3-1-定位" tabindex="-1"><a class="header-anchor" href="#_6-3-1-定位"><span>6.3.1. 定位</span></a></h4><p>Tensor Cores 是<strong>专为矩阵运算优化的专用硬件单元</strong>，首次出现在 2017 年的 Volta 架构（如 V100），后续在 Ampere、Hopper、Ada Lovelace 等架构中持续升级（当前为第四代）。</p><ul><li><p><strong>功能</strong>：<strong>加速矩阵乘法与累加（GEMM, General Matrix Multiply）</strong>，即计算 C=A×B+C，其中 A、B、C 为矩阵。</p></li><li><p><strong>应用场景</strong>：</p><ul><li><strong>深度学习核心场景</strong>：神经网络中的线性层（全连接层、Transformer 的 Attention）、卷积层（可转换为矩阵运算），是训练和推理的关键加速单元。</li><li><strong>科学计算优化</strong>：如矩阵求逆、奇异值分解（SVD）等，需配合特定库（如 cuBLAS）使用。</li></ul></li></ul><h4 id="_6-3-2-技术特点" tabindex="-1"><a class="header-anchor" href="#_6-3-2-技术特点"><span>6.3.2. 技术特点</span></a></h4><ul><li><p><strong>专用性</strong>：仅支持<strong>特定精度的矩阵运算</strong>，包括 FP16、BF16、TF32、INT8、INT4、FP8 等（不同架构支持的精度不同，如 H200 NVL 支持 FP8，L40S 支持 INT4），<strong>不处理标量运算</strong>。</p></li><li><p><strong>计算模式</strong>：每次处理一个 4×4×4 的矩阵块（输入为两个 4x4 矩阵，输出为 4x4 矩阵并累加），单周期内完成 64 次乘加运算，效率远超 CUDA Cores 的标量累加。</p></li><li><p><strong>性能优势</strong>：</p><ul><li>以 FP16 为例，Tensor Core 的运算速度通常是 CUDA Core 的<strong>8-16 倍</strong>（如 H100 的 FP16 Tensor Core 性能为 204.9 TFLOPS，而 FP32 CUDA Core 性能为 51.2 TFLOPS，前者是后者的 4 倍，因 Tensor Core 同时利用低精度和矩阵并行）。</li><li>支持<strong>稀疏化（Sparsity）</strong>：当矩阵中零值占比达到 50% 时，性能可再提升 1 倍（如表格中 “with Sparsity” 的数值通常是非稀疏模式的 2 倍）。</li></ul></li><li><p><strong>第四代 Tensor Core</strong>（Hopper/Ada Lovelace 架构）：支持更多精度（如 FP8、INT4）和稀疏化技术，矩阵运算吞吐量进一步提升（如 H200 NVL 的 FP8 Tensor Core 稀疏性能达 3341 TFLOPS）。</p></li><li><p><strong>数量对比</strong>：Tensor Core 数量远少于 CUDA Cores（如 H200 NVL：528 个 Tensor Core vs 16896 个 CUDA Core），但每个 Tensor Core 的矩阵运算效率极高。</p></li></ul><figure><img src="/assets/gpu_arch-1746957249811-BuxfIgRC.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>图片来源：https://g.masse.me/gpu-specs/</p><h4 id="_6-3-3-sm-内的-tensor-core-布局" tabindex="-1"><a class="header-anchor" href="#_6-3-3-sm-内的-tensor-core-布局"><span>6.3.3. SM 内的 Tensor Core 布局</span></a></h4><ul><li><strong>引入与位置</strong>：Tensor Core 自 <strong>Volta 架构（2017 年）</strong> 开始集成到 SM 中，位于 SM 的专用计算模块内，与 CUDA Core 并列。</li><li><strong>数量</strong>：每个 SM 包含的 Tensor Core 数量随代次升级： <ul><li><strong>Volta（V100）</strong>：每个 SM 有 8 个 Tensor Core（支持 FP16/INT8 矩阵运算）；</li><li><strong>Ampere（A100）</strong>：每个 SM 有 8 个 Tensor Core（支持 TF32/FP16/BF16/INT8，性能提升）；</li><li><strong>Hopper（H100/H200 NVL）</strong>：每个 SM 有 8 个<strong>第四代 Tensor Core</strong>（支持 FP8/INT4 等更低精度，新增稀疏化加速）；</li><li><strong>Ada Lovelace（L40S）</strong>：每个 SM 有 8 个 Tensor Core（与 Hopper 类似，但优化了 FP8/INT4 支持）。</li></ul></li><li><strong>功能定位</strong>： <ul><li>Tensor Core 是 SM 的 “矩阵运算加速器”，专门处理 4×4 矩阵块的乘加运算（GEMM），单周期内完成 64 次乘加操作（即计算 4×4+4×4=4×4）。</li><li>仅当计算精度和操作类型（矩阵乘法）匹配时，SM 才会调用 Tensor Core，否则使用 CUDA Core。</li></ul></li></ul><h4 id="_6-3-4-与-sm-的协作" tabindex="-1"><a class="header-anchor" href="#_6-3-4-与-sm-的协作"><span>6.3.4. 与 SM 的协作</span></a></h4><ul><li><strong>数据通路</strong>：Tensor Core 的输入输出数据通过 SM 内的专用寄存器文件（Register File）与 CUDA Core 共享，无需经过显存，减少延迟。</li><li><strong>调度逻辑</strong>：当框架（如 PyTorch）调用矩阵运算时，<mark>SM 的指令调度器自动判断</mark>是否使用 Tensor Core： <ul><li>若为 FP16/BF16/TF32/INT8 等支持的精度且是矩阵运算，则分配给 Tensor Core；</li><li>否则分配给 CUDA Core（如 FP32 标量运算、INT32 整数操作）。</li></ul></li></ul><h3 id="_6-4-cuda-core" tabindex="-1"><a class="header-anchor" href="#_6-4-cuda-core"><span>6.4. Cuda Core</span></a></h3><h4 id="_6-4-1-对比" tabindex="-1"><a class="header-anchor" href="#_6-4-1-对比"><span>6.4.1. 对比</span></a></h4><p><strong>CUDA Cores</strong> 和 <strong>Tensor Cores</strong> 均为 <strong>SM 内部的计算单元</strong>，二者在 SM 中以特定结构集成。</p><table><thead><tr><th><strong>特性</strong></th><th><strong>CUDA Cores</strong></th><th><strong>Tensor Cores</strong></th></tr></thead><tbody><tr><td><strong>定位</strong></td><td>通用计算单元，处理标量运算</td><td>专用单元，加速矩阵乘法与累加</td></tr><tr><td><strong>支持精度</strong></td><td>FP64/FP32/INT32 等通用精度</td><td>FP16/BF16/TF32/INT8/FP8 等特定低精度</td></tr><tr><td><strong>计算模式</strong></td><td>标量运算，单数据点并行</td><td>矩阵块运算（4x4x4），块级并行</td></tr><tr><td><strong>典型应用</strong></td><td>图形渲染、科学计算、非矩阵优化任务</td><td>深度学习矩阵运算（训练 / 推理）、矩阵分解</td></tr><tr><td><strong>性能优势</strong></td><td>大规模线程并行，通用性强</td><td>单核心超高矩阵运算效率（比 CUDA Core 快数倍）</td></tr><tr><td><strong>首次出现架构</strong></td><td>所有 CUDA 架构（2006 年至今）</td><td>Volta 架构（2017 年），当前为第四代</td></tr><tr><td>在深度学习中，两者通常协同工作：</td><td></td><td></td></tr></tbody></table><ol><li><strong>Tensor Cores</strong>：处理神经网络中的矩阵运算（如前向传播、反向传播的梯度计算），由框架（PyTorch/TensorFlow）或库（cuDNN）自动调用，大幅减少计算时间。</li><li><strong>CUDA Cores</strong>：处理辅助任务，如数据预处理、激活函数（ReLU/Sigmoid）、非矩阵化的张量操作（如索引、切片），以及不支持 Tensor Core 的精度（如 FP64 训练）。</li></ol><p>例如，在训练一个 Transformer 模型时：</p><ul><li>矩阵乘法（Q/K/V 投影、FFN 层）由 Tensor Cores 加速；</li><li>层归一化、Softmax 等标量运算由 CUDA Cores 处理。</li></ul><h4 id="_6-4-2-sm-内的-cuda-core-布局" tabindex="-1"><a class="header-anchor" href="#_6-4-2-sm-内的-cuda-core-布局"><span>6.4.2. SM 内的 CUDA Core 布局</span></a></h4><ul><li><p><strong>数量</strong>：每个 SM 包含多个 CUDA Core，具体数量随架构变化：</p><ul><li><strong>Volta 架构（V100）</strong>：每个 SM 有 64 个 CUDA Core；</li><li><strong>Ampere 架构（A100）</strong>：每个 SM 有 128 个 CUDA Core；</li><li><strong>Hopper 架构（H100/H200 NVL）</strong>：每个 SM 有 128 个 CUDA Core；</li><li><strong>Ada Lovelace 架构（L40S）</strong>：每个 SM 有 128 个 CUDA Core（与 Ampere 类似，但优化了指令调度）。</li></ul></li><li><p><strong>功能定位</strong>：</p><ul><li>CUDA Core 是 SM 的 “通用计算基石”，负责处理标量运算（如 FP32/FP64 浮点、INT32 整数运算），以及不适合 Tensor Core 的任务（如激活函数、数据预处理）。</li><li>每个 CUDA Core 独立执行一条线程的标量指令，SM 通过同时调度数千个线程（分布在多个 CUDA Core 上）实现大规模并行计算。</li></ul></li></ul><h4 id="_6-4-3-与-sm-的协作" tabindex="-1"><a class="header-anchor" href="#_6-4-3-与-sm-的协作"><span>6.4.3. 与 SM 的协作</span></a></h4><p>SM 通过线程束（Warp，32 个线程为一组） 调度 CUDA Core：</p><ul><li>每个 Warp 的 32 个线程分配到 32 个 CUDA Core 上并行执行（如 Hopper 的 SM 有 128 个 CUDA Core，可同时处理 4 个 Warp）；</li><li>当 CUDA Core 执行浮点或整数指令时，SM 的控制单元（如指令调度器）负责分发任务并同步结果。</li></ul><h3 id="_6-5-举例-grid-block-thread" tabindex="-1"><a class="header-anchor" href="#_6-5-举例-grid-block-thread"><span>6.5. 举例：Grid/Block/Thread</span></a></h3><p>关系的示意图如下所示：(图中表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mi>B</mi><mo>∗</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">A = B * C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>, 两个向量相乘，每个向量的长度为 8192 个元素)。</p><ol><li>每个 SIMD 线程指令计算 32 个元素；</li><li>每个线程块包含 16 个 SIMD 线程；</li><li>网格包含 16 个线程块。</li></ol><figure><img src="/assets/Pasted%20image%2020250310191138-CbtG_62F.png" alt="grid" tabindex="0" width="472" height="598" loading="lazy"><figcaption>grid|472x598</figcaption></figure><h3 id="_6-6-与-cpu-的对比" tabindex="-1"><a class="header-anchor" href="#_6-6-与-cpu-的对比"><span>6.6. 与 CPU 的对比</span></a></h3><p>CPU：依赖操作系统管理线程调度（如多核任务分配），线程切换和资源分配由软件控制，适合复杂逻辑和低延迟任务。</p><p>GPU：硬件直接管理线程，通过 SIMT 架构和大量线程掩盖内存延迟，适合数据并行任务（如矩阵运算、图像处理）。</p><p>总结：GPU 的硬件设计使得并行执行和线程管理成为“黑箱”，程序员只需关注任务的并行划分（如线程块大小），而具体的线程调度、资源分配和延迟隐藏均由硬件自动完成。这种设计大幅提升了并行计算效率，同时降低了编程复杂度。</p><p><strong>GPU 的硬件设计如何隐藏线程管理细节并提升并行计算效率</strong>:</p><p>GPU（图形处理器）的架构与传统 CPU 有着根本性的不同，它专为大规模并行计算优化，能够同时运行成千上万个线程。GPU 之所以能够高效执行并行计算，关键在于其硬件设计隐藏了线程调度、资源分配以及延迟隐藏的复杂性，使得开发者只需要关注任务的并行划分，而无需直接管理底层的并行执行细节。</p><hr><h4 id="_6-6-1-gpu-线程管理的-黑箱-特性" tabindex="-1"><a class="header-anchor" href="#_6-6-1-gpu-线程管理的-黑箱-特性"><span>6.6.1. GPU 线程管理的“黑箱”特性</span></a></h4><p>在 GPU 上，程序员通常通过 CUDA（NVIDIA）或 HIP（AMD）等并行计算框架，定义计算任务的并行性。开发者需要做的主要工作是：</p><p>• 确定数据并行模式：任务如何划分为多个线程进行处理。</p><p>• 选择线程块大小（Thread Block Size）：GPU 计算通常基于“线程块（Thread Block）”的概念，程序员需要决定每个块中的线程数。</p><p>• 确定网格（Grid）结构：将线程块映射到更大范围的计算任务。</p><p>然而，一旦任务被划分好，线程的具体执行顺序、分派到哪个计算单元、如何进行调度、如何隐藏延迟等，完全由 GPU 硬件自动管理，这与<strong>传统 CPU 上需要开发者手动优化线程调度</strong>和同步的做法形成鲜明对比。</p><hr><h4 id="_6-6-2-gpu-自动完成的线程管理机制" tabindex="-1"><a class="header-anchor" href="#_6-6-2-gpu-自动完成的线程管理机制"><span>6.6.2. GPU 自动完成的线程管理机制</span></a></h4><p>GPU 硬件通过多个机制隐藏线程管理细节，从而优化计算效率：</p><p><strong>(1) 线程调度（Warp Scheduling）</strong>：</p><p>GPU 的基本执行单元是“Warp”或“Wavefront”（如 NVIDIA 的 Warp 由 32 个线程组成，AMD 的 Wavefront 通常为 64 个线程）。GPU 的硬件调度器负责：</p><ul><li>自动分配 Warp 到计算单元（Streaming Multiprocessors, SM）</li><li>在不同 Warp 之间交错执行，以最大化硬件利用率</li><li>屏蔽不同线程的执行细节，开发者不需要关心线程具体如何被调度</li></ul><p>例如，在 CPU 上，如果多个线程争夺相同的核心，可能会导致复杂的上下文切换（context switch），而 GPU 通过“零开销线程切换”机制，在一个 Warp 执行遇到内存访问延迟时，硬件可以快速切换到另一个 Warp，隐藏延迟，从而提高计算效率。</p><p><strong>(2) 资源分配（Register &amp; Shared Memory Management）</strong>：</p><p>GPU 采用分层存储架构，包括：</p><p>• 寄存器（Register File）</p><p>• 共享内存（Shared Memory）</p><p>• 全局内存（Global Memory）</p><p>• 纹理/常量内存（Texture/Constant Memory）</p><p>不同线程块的资源分配由硬件自动管理：</p><ul><li>GPU 会根据线程块的大小，自动划分可用的寄存器和共享内存，<strong>确保线程间不会发生资源冲突</strong></li><li>程序员无需手动管理内存访问模式，硬件会自动进行 <strong>数据合并（Memory Coalescing）</strong> 以优化内存访问</li></ul><p>在 CPU 上，开发者需要手动进行缓存优化，而在 GPU 上，很多缓存优化（如 L2 Cache、共享内存）由硬件完成，大大减少了程序优化的复杂度。</p><p><strong>(3) 延迟隐藏（Latency Hiding）</strong>：</p><p>CPU 主要依靠深度流水线（Deep Pipeline）和分支预测（Branch Prediction） 来减少指令执行的延迟，而 GPU 采用了<strong>大规模线程切换（Thread-Level Parallelism, TLP）</strong> 来隐藏延迟：</p><ul><li>当某个 Warp 等待内存访问时，GPU 硬件会自动调度另一个 Warp 执行，避免计算单元空闲</li><li>这种策略能够充分利用 GPU 的超大存储带宽（如 HBM 高带宽存储），在数百至数千个线程间动态调度计算任务</li></ul><p>这种延迟隐藏机制使得程序员不需要像在 CPU 上那样进行复杂的流水线优化、寄存器重命名等，而是交给 GPU 硬件自动优化。</p><hr><h4 id="_6-6-3-gpu-这种硬件设计的优势" tabindex="-1"><a class="header-anchor" href="#_6-6-3-gpu-这种硬件设计的优势"><span>6.6.3. GPU 这种硬件设计的优势</span></a></h4><p><strong>(1) 降低编程复杂度</strong></p><p>由于线程管理和调度均由硬件完成，开发者只需要关注：</p><p>• 如何划分计算任务</p><p>• 如何选择合理的线程块大小</p><p>• 如何优化数据访问模式（如避免共享内存冲突）</p><p>相较于 CPU 上需要手动管理线程、同步、缓存等，GPU 的这种设计大大降低了并行编程的门槛，使得更多开发者能够利用 GPU 进行加速计算。</p><p><strong>(2) 提升并行计算效率</strong></p><p>• 由于 GPU 能够同时管理数万个线程，并通过自动调度 Warp 来优化资源利用率，使得 GPU 在数据并行任务上展现出极高的吞吐率</p><p>• 通过零开销线程切换，GPU 在面对高延迟操作（如全局内存访问）时依然能够保持高效执行，而 CPU 可能会因为缓存未命中导致停滞</p><p>• 通过自动资源分配和寄存器优化，避免了 CPU 上需要手动进行的复杂优化</p><p><strong>(3) 适用于大规模计算任务</strong></p><p>GPU 的这种设计特别适合：</p><ul><li><p>深度学习和 AI 训练（如 TensorFlow、PyTorch）：因为矩阵计算可以高度并行化</p></li><li><p>科学计算和 HPC（如气候模拟、基因计算）：涉及大量浮点运算的任务</p></li><li><p>大规模图形渲染（如游戏和视觉计算）：GPU 本就是为并行渲染设计的</p></li><li><p>数据库加速（如 GPU 加速 SQL 查询）：高吞吐率可以显著提升查询性能</p></li></ul><hr><h4 id="_6-6-4-结论" tabindex="-1"><a class="header-anchor" href="#_6-6-4-结论"><span>6.6.4. 结论</span></a></h4><p>GPU 通过将<strong>线程调度、资源分配、延迟隐藏等低层细节封装在硬件中</strong>，使得开发者能够更专注于任务的并行划分，而无需关心具体的线程管理。这种“黑箱”设计使得 GPU 能够高效执行大规模并行计算任务，同时大幅降低了并行编程的复杂度，从而推动了 AI、HPC、图形渲染等领域的快速发展。</p><p>这种架构的核心理念是<strong>让硬件管理并行性，让开发者专注于计算逻辑</strong>，从而最大化计算资源的利用率，实现高效的并行计算。</p><h2 id="_7-q2" tabindex="-1"><a class="header-anchor" href="#_7-q2"><span>7. Q2</span></a></h2><blockquote><p>硬件线程块调度器（Thread Block Scheduler）将线程块（Thread Blocks）分配给多线程 SIMD 处理器（multithreaded SIMD Processors），而硬件线程调度器（Thread Scheduler）在每个时钟周期内选择要在 SIMD 处理器中运行的 SIMD 指令线程（thread of SIMD instructions）。</p></blockquote><p>这句话描述了 GPU 内部的线程块调度（Thread Block Scheduling） 和线程调度（Thread Scheduling） 两个层次的机制，并且强调了线程调度是逐个时钟周期进行的，也就是在每个 SIMD 处理器内部的指令选择是动态的。</p><h3 id="_7-1-硬件线程块调度器-thread-block-scheduler" tabindex="-1"><a class="header-anchor" href="#_7-1-硬件线程块调度器-thread-block-scheduler"><span>7.1. 硬件线程块调度器 （Thread Block Scheduler）</span></a></h3><ol><li>负责将线程块（Thread Blocks） 分配给多线程 SIMD 处理器（Multithreaded SIMD Processors）。</li><li>在 GPU 计算模型（如 CUDA、HIP、OpenCL）中，一个计算任务通常会被划分成多个线程块，每个线程块内部包含多个线程（Threads）。</li><li>由于 GPU 由多个 SIMD 处理单元（如 Streaming Multiprocessors（SM） 或 Compute Units（CU））组成，因此需要线程块调度器负责把任务均匀分配到这些处理单元上。</li></ol><p>如果一个 GPU 有 8 个 SIMD 处理单元，而计算任务包含 64 个线程块，线程块调度器可能会将每个 SIMD 处理单元分配 8 个线程块，确保所有计算单元都参与计算，从而最大化吞吐量。</p><hr><h3 id="_7-2-硬件线程调度器-thread-scheduler" tabindex="-1"><a class="header-anchor" href="#_7-2-硬件线程调度器-thread-scheduler"><span>7.2. 硬件线程调度器 （Thread Scheduler）</span></a></h3><ul><li><p>负责在每个 SIMD 处理器内部，每个时钟周期（clock cycle） 选择一个要执行的 SIMD 指令线程（thread of SIMD instructions）。</p></li><li><p>由于 GPU 采用 SIMT（Single Instruction, Multiple Threads） 计算模式，每个 SIMD 处理单元可以同时执行多个 Warp（NVIDIA）/Wavefront（AMD），但由于计算资源有限，必须在多个候选线程中选择合适的线程执行。</p></li></ul><p><strong>关键点：</strong></p><ol><li><p>多个 Warp/Wavefront 竞争执行权：在一个 SIMD 处理单元内部，可能有几十到上百个 Warp/Wavefront 处于就绪（ready） 状态，但一次只能执行一个 Warp/Wavefront 的 SIMD 指令。</p></li><li><p>调度发生在每个时钟周期：线程调度器在每个时钟周期（clock cycle） 都会选择一个 Warp/Wavefront，执行它的下一条 SIMD 指令。</p></li><li><p>影响调度决策的因素：</p></li></ol><ul><li>指令依赖性（Instruction Dependencies）： 如果某个 Warp/Wavefront 需要的数据还没准备好，调度器可能会跳过它，选择另一个 Warp/Wavefront。</li><li>寄存器压力（Register Pressure）： 如果某个 Warp/Wavefront 占用了太多寄存器，可能会降低调度器的灵活性。</li><li>内存访问延迟（Memory Latency）： 如果某个 Warp/Wavefront 需要访问 DRAM，调度器可能会选择另一个不受内存访问限制的 Warp/Wavefront 先执行。</li></ul><h3 id="_7-3-示例" tabindex="-1"><a class="header-anchor" href="#_7-3-示例"><span>7.3. 示例</span></a></h3><p>假设一个 SIMD 处理器可以并行执行 32 个线程（即 1 个 Warp/Wavefront），但它可能维护了 64 个 Warp/Wavefront 在等待执行。</p><p>线程调度器会在每个时钟周期选择一个就绪（ready） 的 Warp/Wavefront，执行其中的 SIMD 指令。</p><p>如果某个 Warp/Wavefront 的内存访问未完成，线程调度器可能会选择另一个已经准备好执行的 Warp/Wavefront，以隐藏延迟（latency hiding）。</p><hr><h3 id="_7-4-总结" tabindex="-1"><a class="header-anchor" href="#_7-4-总结"><span>7.4. 总结</span></a></h3><p><strong>Thread Block Scheduler（线程块调度器）</strong>：</p><ul><li>作用： 负责在多个 SIMD 处理单元（如 SM/CU） 之间分配线程块（Thread Blocks）。</li><li>目标： 确保所有 SIMD 处理单元都参与计算，提高吞吐量。</li></ul><p><strong>Thread Scheduler（线程调度器）：</strong></p><ul><li>作用： 负责在每个 SIMD 处理单元内部，每个时钟周期（clock cycle） 选择一个 Warp/Wavefront，执行其中的 SIMD 指令。</li><li>目标： 通过动态调度 Warp/Wavefront，最大化计算资源的利用率，同时隐藏内存访问延迟。</li></ul><hr><h3 id="_7-5-直观比喻" tabindex="-1"><a class="header-anchor" href="#_7-5-直观比喻"><span>7.5. 直观比喻</span></a></h3><p>可以把整个 GPU 计算过程比作工厂流水线：</p><ol><li>Thread Block Scheduler 类似于车间经理，负责把不同的任务分配给多个生产线（SIMD 处理单元）。</li><li>Thread Scheduler 类似于生产线上的调度员，每秒钟（每个时钟周期）都要决定当前哪条生产线上的工作站（Warp/Wavefront）应该执行下一步任务。</li></ol><p>这样，GPU 通过多层次调度，在硬件层面实现高吞吐量并行计算，有效地利用计算资源。</p><h2 id="_8-explicit-predicate-registers-显式谓词寄存器" tabindex="-1"><a class="header-anchor" href="#_8-explicit-predicate-registers-显式谓词寄存器"><span>8. Explicit Predicate Registers（显式谓词寄存器）</span></a></h2><p>Explicit Predicate Registers（显式谓词寄存器）通常出现在支持 VLIW（超长指令字） 或 SIMD（单指令多数据） 体系结构的 CPU 和 GPU 设计中，用于实现指令级并行（ILP） 和数据级并行（DLP）。它们的主要作用是存储和控制指令或数据的执行条件。</p><h3 id="_8-1-什么是-explicit-predicate-registers" tabindex="-1"><a class="header-anchor" href="#_8-1-什么是-explicit-predicate-registers"><span>8.1. 什么是 Explicit Predicate Registers？</span></a></h3><p>在计算机体系结构中，<strong>predicate（谓词）</strong> 是一个布尔值（0/1），用于指示某条指令是否应该执行。Predicate 允许在不需要分支指令（如 if-else 或 branch）的情况下，实现<strong>条件执行</strong>（conditional execution）。这在<strong>减少流水线分支预测失败、提高指令并行度</strong>方面非常重要。</p><p><strong>Predicate Registers（谓词寄存器）</strong> 存储这些布尔值，每个谓词寄存器通常存储一个或多个谓词位。例如，在向量化执行时，每个 SIMD 线程可以有一个对应的谓词寄存器位，控制它是否执行当前指令。</p><p><strong>显式谓词寄存器（Explicit Predicate Registers）</strong> “显式”指的是架构直接提供<strong>专门的</strong>谓词寄存器，而不是依赖通用寄存器或状态标志位。例如：</p><ul><li><p>Intel AVX-512: 提供 16 个 mask registers（k0-k15），用于 SIMD 向量化中的条件掩码。</p></li><li><p>AMD CDNA / RDNA: GPU 采用谓词寄存器来管理 SIMT（单指令多线程）执行，控制哪些线程在 warp/wavefront 中生效。</p></li><li><p>Itanium（IA-64）: 采用了大量的谓词寄存器（64 个），用于 VLIW 指令并行调度。</p></li><li><p>ARM SVE（Scalable Vector Extension）: 提供了显式谓词寄存器 p0-p7，用于向量掩码操作。</p></li></ul><h3 id="_8-2-显式谓词寄存器的作用" tabindex="-1"><a class="header-anchor" href="#_8-2-显式谓词寄存器的作用"><span>8.2. 显式谓词寄存器的作用</span></a></h3><p><strong>避免分支预测失败</strong>：传统 if-else 代码会引入分支预测，而谓词寄存器允许<strong>无分支执行</strong>，减少分支预测开销。例如：</p><div class="language-asm line-numbers-mode" data-highlighter="shiki" data-ext="asm" style="--shiki-light:#24292e;--shiki-dark:#d8dee9ff;--shiki-light-bg:#fff;--shiki-dark-bg:#2e3440ff;"><pre class="shiki shiki-themes github-light nord vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#616E88;">; x86 AVX-512</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#81A1C1;">VPADDQ</span><span style="--shiki-light:#005CC5;--shiki-dark:#81A1C1;"> ZMM1</span><span style="--shiki-light:#24292E;--shiki-dark:#D8DEE9FF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#81A1C1;">ZMM2</span><span style="--shiki-light:#24292E;--shiki-dark:#D8DEE9FF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#81A1C1;">ZMM3</span><span style="--shiki-light:#24292E;--shiki-dark:#D8DEE9FF;"> {</span><span style="--shiki-light:#D73A49;--shiki-dark:#81A1C1;">k1</span><span style="--shiki-light:#24292E;--shiki-dark:#D8DEE9FF;">}  </span><span style="--shiki-light:#6A737D;--shiki-dark:#616E88;">; 仅在 k1 掩码为 1 的位置执行加法</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>提高指令并行度（ILP）</strong>：现代 CPU 会同时调度多个指令，使用谓词寄存器可以让不同指令并行执行，不必等待分支决策完成。</p><p><strong>向量化计算（SIMD/SIMT）</strong>：GPU 和向量指令集利用谓词寄存器进行<strong>掩码计算</strong>，控制哪些元素参与计算，例如：</p><div class="language-asm line-numbers-mode" data-highlighter="shiki" data-ext="asm" style="--shiki-light:#24292e;--shiki-dark:#d8dee9ff;--shiki-light-bg:#fff;--shiki-dark-bg:#2e3440ff;"><pre class="shiki shiki-themes github-light nord vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#616E88;">; ARM SVE</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#81A1C1;">ADD</span><span style="--shiki-light:#24292E;--shiki-dark:#D8DEE9FF;"> Z0.S, P0/M, Z1.S, Z2.S  </span><span style="--shiki-light:#6A737D;--shiki-dark:#616E88;">; 仅对 P0 掩码为 1 的元素执行加法</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>减少控制依赖（Control Dependency）</strong>：传统流水线 CPU 需要预测分支，而谓词寄存器让<strong>所有指令都进入流水线</strong>，只是在执行阶段选择是否生效，降低分支误预测的开销。</p><h3 id="_8-3-典型应用" tabindex="-1"><a class="header-anchor" href="#_8-3-典型应用"><span>8.3. 典型应用</span></a></h3><p><strong>AI 和 HPC</strong>: 深度学习推理（如 Transformer 模型）和数值计算中，经常使用 AVX-512、SVE、CDNA/RDNA 的 SIMD/矩阵运算，显式谓词寄存器用于掩码计算。</p><p><strong>编译器优化</strong>: LLVM、GCC 在自动向量化过程中，会利用谓词寄存器生成<strong>无分支代码</strong>，提升 SIMD 效率。</p><p><strong>GPU Wavefront 处理</strong>: AMD RDNA/CDNA GPU 使用显式谓词寄存器管理<strong>Wavefront 屏蔽（Wave Masking）</strong>，让 SIMD 线程更高效地执行 warp/wave 级分支。</p><div class="hint-container tip"><p class="hint-container-title">总结</p><p><strong>显式谓词寄存器</strong>是一种专门用于<strong>条件执行</strong>的寄存器，广泛应用于 <strong>VLIW、SIMD、SIMT</strong> 体系结构。它们的优势包括<strong>减少分支预测失败、提高指令并行度、提升向量化计算效率</strong>，在现代 CPU/GPU 体系结构中扮演关键角色。</p></div><h2 id="_9-nvida-gpu-指令集体系结构" tabindex="-1"><a class="header-anchor" href="#_9-nvida-gpu-指令集体系结构"><span>9. NVIDA GPU 指令集体系结构</span></a></h2><p>列举部分指令：</p><figure><img src="/assets/20250322205534-Bd0_5x-u.jpg" alt="isa_gpu" tabindex="0" loading="lazy"><figcaption>isa_gpu</figcaption></figure><h2 id="_10-nv-gpu-存储结构" tabindex="-1"><a class="header-anchor" href="#_10-nv-gpu-存储结构"><span>10. NV GPU 存储结构</span></a></h2><h3 id="_10-1-streaming-caches" tabindex="-1"><a class="header-anchor" href="#_10-1-streaming-caches"><span>10.1. Streaming Caches</span></a></h3><blockquote><p>Rather than rely on large caches to contain the whole working sets of an application, GPUs traditionally <mark>use smaller streaming caches</mark> and, because their working sets can be hundreds of megabytes, rely on extensive multithreading of threads of SIMD instructions to <strong>hide the long latency to DRAM.</strong></p></blockquote><p>这句话的意思是：</p><p>与其依靠大容量的缓存来容纳应用程序的整个工作集，GPU 传统上采用更小的流式缓存。由于 GPU 的工作集可能达到数百兆字节，为了掩盖访问 DRAM（动态随机存取存储器）时的长延迟，GPU 依靠大量的线程并行执行 SIMD（单指令多数据）指令来隐藏这些延迟。</p><ol><li><strong>大缓存 vs. 小流式缓存</strong></li></ol><ul><li><strong>CPU</strong> 通常使用较大的缓存（如 L2/L3 缓存）来存储经常访问的数据，从而减少对主存（DRAM）的访问次数。</li><li><strong>GPU</strong> 则采用<strong>小型流式缓存</strong>（Streaming Cache）。它主要用于临时存储数据，通过高速缓存访问来减少访存延迟，但不会试图容纳整个应用的工作集。</li></ul><ol start="2"><li><p><strong>Workload 大小</strong>：GPU 的应用场景（如图像处理、深度学习等）通常需要处理海量数据，其 Workload 可能达到数百兆字节，远超缓存的容量。</p></li><li><p><strong>隐藏内存延迟</strong></p></li></ol><ul><li>由于 DRAM 访问的延迟较长，GPU 不像 CPU 那样依靠复杂的缓存层级来降低延迟。</li><li>GPU 采用<strong>大量的线程</strong>（通过 SIMT/SIMD 方式）执行，<mark>确保在某个线程等待数据返回时，其他线程可以继续执行其他任务</mark>。这种方法有效地<strong>隐藏内存访问延迟</strong>。</li></ul><ol start="4"><li><strong>SIMD 指令</strong>：GPU 通过 SIMD 指令（Single Instruction, Multiple Data）执行一条指令，同时操作多个数据项。再结合超线程调度，多线程并行执行进一步提高了吞吐量。</li></ol><p>GPU 的架构设计强调<strong>吞吐量</strong>而非<strong>低延迟</strong>。通过依靠<strong>小型流式缓存</strong>和<strong>多线程掩盖内存延迟</strong>，GPU 能高效处理大规模数据并执行并行计算。</p><div class="hint-container note"><p class="hint-container-title">注</p><p>此处命名为 <code>数据</code>，但这里并没有提供具体数据集，而是提供了处理获取大规模数据的方法</p></div><h2 id="_11-device-and-stream" tabindex="-1"><a class="header-anchor" href="#_11-device-and-stream"><span>11. Device and Stream</span></a></h2><p>在 CUDA 编程里，<code>device</code>（设备）和 <code>stream</code>（流）是两个关键概念，它们存在着密切的联系，下面将为你详细介绍它们之间的关系。</p><h3 id="_11-1-基本概念" tabindex="-1"><a class="header-anchor" href="#_11-1-基本概念"><span>11.1. 基本概念</span></a></h3><ul><li><strong>Device</strong>：在 CUDA 语境中，<code>device</code> 通常指的是 GPU。CUDA 程序可以在多个 GPU 设备上并行运行，每个 GPU 设备都有其独立的内存和计算资源。</li><li><strong>Stream</strong>：<code>stream</code> 是一系列按顺序执行的 CUDA 操作队列。同一流内的操作会按照顺序依次执行，不同流内的操作则可以并行执行，这样就能提高 GPU 资源的利用率。</li></ul><h3 id="_11-2-二者关系" tabindex="-1"><a class="header-anchor" href="#_11-2-二者关系"><span>11.2. 二者关系</span></a></h3><ul><li><strong>设备包含多个流</strong>：一个 <code>device</code>（GPU）能够同时管理多个 <code>stream</code>。借助多个流，你可以让不同的 CUDA 操作在同一个 GPU 上并行执行，以此提升整体性能。例如，在一个 GPU 上可以同时开启数据传输流和内核执行流，使数据传输和内核计算并行进行。</li><li><strong>流在设备上执行</strong>：所有的 <code>stream</code> 都必须依附于某个 <code>device</code>。当你创建一个 <code>stream</code> 时，实际上是在特定的 GPU 设备上创建了一个操作队列。不同设备上的流是相互独立的，不能跨设备共享。</li><li><strong>通过流管理设备资源</strong>：合理运用 <code>stream</code> 能够更好地管理 <code>device</code>（GPU）的资源。例如，你可以把不同类型的任务分配到不同的流中，像将数据传输任务和内核计算任务分别放到不同的流里，从而实现数据传输和内核计算的重叠，充分利用 GPU 的带宽和计算能力。</li></ul><h3 id="_11-3-示例代码" tabindex="-1"><a class="header-anchor" href="#_11-3-示例代码"><span>11.3. 示例代码</span></a></h3><p>下面是一个简单的 CUDA C++代码示例，展示了如何在一个 GPU 设备上创建和使用多个流：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#24292e;--shiki-dark:#d8dee9ff;--shiki-light-bg:#fff;--shiki-dark-bg:#2e3440ff;"><pre class="shiki shiki-themes github-light nord vp-code"><code><span class="line"><span>#include &lt;cuda_runtime.h&gt;</span></span>
<span class="line"><span>#include &lt;iostream&gt;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>__global__ void kernel(float* d_a, float* d_b, float* d_c, int n) {</span></span>
<span class="line"><span>    int idx = threadIdx.x + blockIdx.x * blockDim.x;</span></span>
<span class="line"><span>    if (idx &lt; n) {</span></span>
<span class="line"><span>        d_c[idx] = d_a[idx] + d_b[idx];</span></span>
<span class="line"><span>    }</span></span>
<span class="line"><span>}</span></span>
<span class="line"><span></span></span>
<span class="line"><span>int main() {</span></span>
<span class="line"><span>    const int n = 1024;</span></span>
<span class="line"><span>    const int blockSize = 256;</span></span>
<span class="line"><span>    const int gridSize = (n + blockSize - 1) / blockSize;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    float *h_a, *h_b, *h_c;</span></span>
<span class="line"><span>    float *d_a, *d_b, *d_c;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    // 分配主机内存</span></span>
<span class="line"><span>    h_a = (float*)malloc(n * sizeof(float));</span></span>
<span class="line"><span>    h_b = (float*)malloc(n * sizeof(float));</span></span>
<span class="line"><span>    h_c = (float*)malloc(n * sizeof(float));</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    // 初始化主机数据</span></span>
<span class="line"><span>    for (int i = 0; i &lt; n; i++) {</span></span>
<span class="line"><span>        h_a[i] = static_cast&lt;float&gt;(i);</span></span>
<span class="line"><span>        h_b[i] = static_cast&lt;float&gt;(i * 2);</span></span>
<span class="line"><span>    }</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    // 分配设备内存</span></span>
<span class="line"><span>    cudaMalloc((void**)&amp;d_a, n * sizeof(float));</span></span>
<span class="line"><span>    cudaMalloc((void**)&amp;d_b, n * sizeof(float));</span></span>
<span class="line"><span>    cudaMalloc((void**)&amp;d_c, n * sizeof(float));</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    // 创建两个流</span></span>
<span class="line"><span>    cudaStream_t stream1, stream2;</span></span>
<span class="line"><span>    cudaStreamCreate(&amp;stream1);</span></span>
<span class="line"><span>    cudaStreamCreate(&amp;stream2);</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    // 在流1中执行数据传输和内核计算</span></span>
<span class="line"><span>    cudaMemcpyAsync(d_a, h_a, n * sizeof(float), cudaMemcpyHostToDevice, stream1);</span></span>
<span class="line"><span>    cudaMemcpyAsync(d_b, h_b, n * sizeof(float), cudaMemcpyHostToDevice, stream1);</span></span>
<span class="line"><span>    kernel&lt;&lt;&lt;gridSize, blockSize, 0, stream1&gt;&gt;&gt;(d_a, d_b, d_c, n);</span></span>
<span class="line"><span>    cudaMemcpyAsync(h_c, d_c, n * sizeof(float), cudaMemcpyDeviceToHost, stream1);</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    // 在流2中执行另一个任务（这里简单示例为同步操作）</span></span>
<span class="line"><span>    cudaStreamSynchronize(stream2);</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    // 销毁流</span></span>
<span class="line"><span>    cudaStreamDestroy(stream1);</span></span>
<span class="line"><span>    cudaStreamDestroy(stream2);</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    // 释放设备内存</span></span>
<span class="line"><span>    cudaFree(d_a);</span></span>
<span class="line"><span>    cudaFree(d_b);</span></span>
<span class="line"><span>    cudaFree(d_c);</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    // 释放主机内存</span></span>
<span class="line"><span>    free(h_a);</span></span>
<span class="line"><span>    free(h_b);</span></span>
<span class="line"><span>    free(h_c);</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    return 0;</span></span>
<span class="line"><span>}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在这个示例里，我们在同一个 GPU 设备上创建了两个流 <code>stream1</code> 和 <code>stream2</code>，并在 <code>stream1</code> 中执行了数据传输和内核计算任务。这样，通过使用流，我们能够更好地管理 GPU 设备的资源，提高程序的性能。</p><h3 id="_11-4-stream-的进一步细分理解" tabindex="-1"><a class="header-anchor" href="#_11-4-stream-的进一步细分理解"><span>11.4. Stream 的进一步细分理解</span></a></h3><p>从功能和操作类型角度，<code>Stream</code>内的操作可以更细致地划分：</p><ul><li><p><strong>内存操作流</strong>：</p><ul><li><strong>主机到设备的内存传输</strong>：借助 <code>cudaMemcpyAsync</code> 函数，能把数据从主机（CPU）内存异步传输到设备（GPU）内存。比如在深度学习训练里，需把输入数据和标签从主机内存传至 GPU 内存，以开展后续计算。</li><li><strong>设备到主机的内存传输</strong>：同样使用 <code>cudaMemcpyAsync</code> 函数，可将数据从设备内存异步传输回主机内存。例如在推理结束后，要把计算结果从 GPU 内存传回 CPU 内存进行后续处理。</li><li><strong>设备内的内存操作</strong>：像 <code>cudaMemsetAsync</code> 可用于异步地将设备内存的某个区域设置为特定值，<code>cudaMemcpyPeerAsync</code> 能在不同 GPU 设备间异步传输数据。</li></ul></li><li><p><strong>内核执行流</strong>：用于调度和执行 CUDA 内核函数。CUDA 内核是在 GPU 上并行执行的函数，可同时处理大量数据。例如，在矩阵乘法运算中，可编写一个 CUDA 内核函数，让大量线程并行计算矩阵元素的乘积和累加结果。</p></li><li><p><strong>事件同步流</strong>：CUDA 事件可用于记录流中特定操作的完成时间，并且能实现不同流之间的同步。例如，你可以在一个流中记录一个事件，在另一个流中等待该事件完成后再继续执行后续操作，以此确保不同流中的操作按特定顺序执行。</p></li></ul><h2 id="_12-cuda-内核" tabindex="-1"><a class="header-anchor" href="#_12-cuda-内核"><span>12. Cuda 内核</span></a></h2><p>CUDA 内核是在 GPU 上并行执行的函数。它由大量线程组成，这些线程会被组织成线程块和网格。每个线程负责处理数据的一部分，众多线程同时运行，从而实现并行计算。以下是一个简单的 CUDA 内核示例，用于实现向量加法：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#24292e;--shiki-dark:#d8dee9ff;--shiki-light-bg:#fff;--shiki-dark-bg:#2e3440ff;"><pre class="shiki shiki-themes github-light nord vp-code"><code><span class="line"><span>__global__ void vectorAdd(float* a, float* b, float* c, int n) {</span></span>
<span class="line"><span>    int idx = threadIdx.x + blockIdx.x * blockDim.x;</span></span>
<span class="line"><span>    if (idx &lt; n) {</span></span>
<span class="line"><span>        c[idx] = a[idx] + b[idx];</span></span>
<span class="line"><span>    }</span></span>
<span class="line"><span>}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在这个示例中，<code>__global__</code> 关键字表明这是一个 CUDA 内核函数。<code>threadIdx.x</code> 表示线程在块内的索引，<code>blockIdx.x</code> 表示块在网格内的索引，<code>blockDim.x</code> 表示块的大小。通过这些索引，每个线程可以确定自己要处理的数据位置。</p><h2 id="_13-reference" tabindex="-1"><a class="header-anchor" href="#_13-reference"><span>13. Reference</span></a></h2></div><!----><!----><!----></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/chenweigao/edit/main/architecture/gpu-ai/gpu_arch.md" aria-label="编辑此页" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->编辑此页<!----></a></div><div class="vp-meta-item git-info"><!----><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: weigao.cwg">weigao</span>,<!--]--><!--[--><span class="vp-meta-info" title="email: weigao.cwg">xiaocheng</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link route-link-active auto-link prev" href="/architecture/gpu-ai/" aria-label="Abstract"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><!---->Abstract</div></a><a class="route-link auto-link next" href="/architecture/gpu-ai/gpu_communication.html" aria-label="GPU Communication"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">GPU Communication<!----></div></a></nav><div id="comment" class="giscus-wrapper input-top vp-comment" vp-comment style="display:block;"><div style="display: flex;align-items: center;justify-content: center;height: 96px"><span style="--loading-icon: url(&quot;data:image/svg+xml;utf8,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; preserveAspectRatio=&#39;xMidYMid&#39; viewBox=&#39;25 25 50 50&#39;%3E%3CanimateTransform attributeName=&#39;transform&#39; type=&#39;rotate&#39; dur=&#39;2s&#39; keyTimes=&#39;0;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;360&#39;%3E%3C/animateTransform%3E%3Ccircle cx=&#39;50&#39; cy=&#39;50&#39; r=&#39;20&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39; stroke-width=&#39;4&#39; stroke-linecap=&#39;round&#39;%3E%3Canimate attributeName=&#39;stroke-dasharray&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;1,200;90,200;1,200&#39;%3E%3C/animate%3E%3Canimate attributeName=&#39;stroke-dashoffset&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;-35px;-125px&#39;%3E%3C/animate%3E%3C/circle%3E%3C/svg%3E&quot;);--icon-size: 48px;display: inline-block;width: var(--icon-size);height: var(--icon-size);background-color: currentcolor;-webkit-mask-image: var(--loading-icon);mask-image: var(--loading-icon)"></span></div></div><!----><!--]--></main><!--]--><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">2017-2023</div><div class="vp-copyright">Copyright © 2025 Someone </div></footer></div><!--]--><!--]--><!--[--><!----><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-11Vuyqh7.js" defer></script>
  </body>
</html>
