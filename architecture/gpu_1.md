---
title: GPU 体系结构
date: 2025-03-06
---
## 量化研究方法

## 4.4 图形处理器

CPU 程序员的挑战不只是在 GPU 上获得出色的性能，还有==协调系统处理器与 GPU 上的计算调度，以及系统存储器与 GPU 存储器之间的数据传输==。

GPU 中的并行：多线程、MIMD、SIMD 和指令级并行。

NVIDIA 将 CUDA 编程定义为 **SIMT** -- ==单指令多线程==。

并行执行和线程管理由 GPU 硬件负责，而不是由应用程序或者操作系统完成。



## 阅读理解

### Q1

>  并行执行和线程管理由 GPU 硬件负责，而不是由应用程序或者操作系统完成。

这句话的含义是：在 GPU 中，并行任务的执行和线程调度完全由硬件架构直接管理，而非依赖应用程序或操作系统的软件层面控制。这种设计使得 GPU 能够高效实现大规模并行计算，同时降低编程复杂度。

以下是具体解释：

<font color="#f79646">硬件直接管理并行执行</font>：GPU 通过 SIMT（单指令多线程）架构实现并行性。其核心思想是：单条指令同时控制多个线程，这些线程共享指令流但处理不同的数据。例如，一个线程束（Warp）包含 32 或 64 个线程，由硬件调度器自动分配到流多处理器（SM）的计算单元上执行。同一 Warp 内的线程必须执行相同指令，但每个线程的数据路径独立，因此可以灵活处理分支逻辑（如条件判断）。
相比之下，CPU 的并行执行依赖操作系统的线程调度（如多核任务分配），而 GPU 的线程调度完全由硬件实现，无需软件介入。

<font color="#f79646">线程模型的硬件抽象</font>：GPU 的编程模型（如 CUDA）提供了线程网格（Grid）、线程块（Block）和线程（Thread）的逻辑划分，但实际的线程分配与执行由硬件完成：
- 线程网格（Grid）：由多个线程块组成，表示整个计算任务的规模。
- 线程块（Block）：一组线程的集合，绑定到一个流多处理器（SM）上执行。同一块内的线程可通过共享内存协作。
- 线程（Thread）：最小执行单元，由硬件直接调度。
程序员只需定义线程结构（如 `>>`），硬件自动将线程块分配到 SM，并通过线程调度器管理 Warp 的执行顺序，隐藏内存延迟。

<font color="#f79646">硬件资源的自动分配</font>：GPU 的硬件设计专门优化了线程管理：
- 流多处理器（SM）：每个 SM 包含多个计算核心（CUDA Core）、共享内存、寄存器文件等资源。SM 可同时运行多个线程块，通过上下文切换（Context Switch）高效利用硬件资源。
- 线程调度器：SM 中的调度器（如 Warp Scheduler）根据线程状态（如是否等待数据）动态选择可执行的 Warp，最大化硬件利用率。
- 内存层次：全局内存、共享内存等的访问由硬件自动优化，减少程序员对内存延迟的显式处理。
---
 **与 CPU 的对比**
- CPU：依赖操作系统管理线程调度（如多核任务分配），线程切换和资源分配由软件控制，适合复杂逻辑和低延迟任务。
- GPU：硬件直接管理线程，通过 SIMT 架构和大量线程掩盖内存延迟，适合数据并行任务（如矩阵运算、图像处理）。
---
 总结：GPU 的硬件设计使得并行执行和线程管理成为“黑箱”，程序员只需关注任务的并行划分（如线程块大小），而具体的线程调度、资源分配和延迟隐藏均由硬件自动完成。这种设计大幅提升了并行计算效率，同时降低了编程复杂度。
