---
title: Pipeline
date: 2022-08-24
category:
 -  Arm
---

## 1. Abstract

æœ¬æ–‡ä¸»è¦ç ”ç©¶æµæ°´çº¿æŠ€æœ¯åœ¨è®¡ç®—æœºä½“ç³»ç»“æ„ä¸­çš„åº”ç”¨ã€‚æµæ°´çº¿æŠ€æœ¯åˆ†ä¸ºä¸¤ä¸ªå¤§çš„éƒ¨åˆ†ï¼Œæœ¬éƒ¨åˆ†ç»Ÿä¸€ç ”ç©¶æµæ°´çº¿çš„åŸºç¡€çŸ¥è¯†éƒ¨åˆ†ï¼Œæ€»ä½“è€Œè¨€å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼š

1. data path implications, hazards and examining the performance of pipelines.
2. interaction between pipelining and various aspects of instruction set design
3. etc..

### 1.1. What is pipeline?

> Pipelining is an implementation technique whereby multiple instructions are overlapped
> in execution;

æµæ°´çº¿çš„æ¦‚å¿µç†è§£è¾ƒä¸ºç®€å•ã€‚

> In a computer pipeline, each *step* in the pipeline completes a part of an instruction. 
> 
> Like the assembly line, different steps are completing different parts of different instructions
> in parallel. Each of these steps is called a *pipe stage* or a *pipe segment*.
> The stages are connected one to the next to form a pipeâ€”instructions enter at one end, progress through the stages, and exit at the other end, just as cars would in an assembly line.

åœ¨è®¡ç®—æœº pipeline ä¸­çš„æ¯ä¸€ä¸ª step éƒ½å®ŒæˆæŒ‡ä»¤çš„ä¸€éƒ¨åˆ†ï¼Œè¿™ä¸ª step åœ¨æµæ°´çº¿ä¸­ç§°ä½œ pipe stage.

> The time required between moving an instruction one step down the pipeline is a *processor cycle.*

ä¸Šè¿°æ–‡å­—ä¸¥æ ¼å®šä¹‰äº† cycle çš„æ¦‚å¿µï¼Œå³æŒ‡ä»¤å‘ä¸‹ç§»åŠ¨ä¸€æ­¥æ‰€éœ€è¦çš„æ—¶é—´ã€‚

> Because all stages proceed at the same time, the length of a processor cycle is determined by the time required for the slowest pipe stage.

ç”±äºæ‰€æœ‰çš„ stage éƒ½åŒæ—¶è¿è¡Œï¼Œæ‰€ä»¥å¤„ç†å™¨ cycle çš„é•¿åº¦å–å†³äº**æœ€æ…¢**çš„ stage æ‰€éœ€çš„æ—¶é—´ã€‚

> In a computer, this processor cycle is almost always 1 clock cycle.

é˜è¿°äº†ä¸€ä¸ªå…¬å¼ï¼š
$$
process\ cycle =  1\ clock \ cycle
$$

> Pipelining yields a reduction in the average execution time per instruction. If the starting point is a processor that takes multiple clock cycles per instruction, then pipelining reduces the CPI.

æµæ°´çº¿çš„ä¸»è¦ä½œç”¨è¿˜æ˜¯é™ä½æŒ‡ä»¤çš„å¹³å‡æ‰§è¡Œæ—¶é—´ã€‚å¦ä¸€æ–¹é¢ï¼Œå¦‚æœæ¯ä¸ªæŒ‡ä»¤éœ€è¦å¤šä¸ªå¤„ç†å™¨æ—¶é’Ÿå‘¨æœŸï¼Œé‚£ä¹ˆæµæ°´çº¿æŠ€æœ¯å¯ä»¥é™ä½ CPI.

## 2. RISC V Instruction Set

:::warning ğŸŸ¢ğŸŸ¢ RISC V å’Œ ARM çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ

éƒ½æ˜¯ RISC æŒ‡ä»¤é›†ï¼Œå¯ä»¥ç†è§£ä¸ºç«äº‰å¯¹æ‰‹ã€‚RISC V æ˜¯å¼€æºçš„ï¼Œæˆæƒè´¹è¾ƒä½ï¼Œä½†æ˜¯ ARM ç”Ÿæ€ç¹è£ï¼Œç›®å‰å›½å†…å¤–ä¹Ÿæœ‰åœ¨åš RISC V çš„ä¼ä¸šã€‚

:::

è™½ç„¶é˜…è¯»çš„è¿™æœ¬ä¹¦ä½¿ç”¨çš„æ˜¯ RISC V æŒ‡ä»¤é›†ï¼Œä½†æ˜¯å…¶ä»–çš„ RISC ä¹Ÿæ˜¯ç±»ä¼¼çš„ã€‚

> All RISC architectures are characterized by a few key properties:
> 
> - All operations on data apply to data in registers and typically change the entire register (32 or 64 bits per register).
> - The only operations that affect memory are load and store operations that move data from memory to a register or to memory from a register, respectively. Load and store operations that load or store less than a full register (e.g., a byte, 16 bits, or 32 bits) are often available.
> - The instruction formats are few in number, with all instructions typically being one size. In RISC V, the register specifiers: `rs1`, `rs2`, and `rd` are always in the same place simplifying the control.
> 
> These simple properties lead to dramatic simplifications in the implementation of pipelining, which is why these instruction sets were designed this way.

æ‰€æœ‰çš„ RISC ä½“ç³»ç»“æ„éƒ½å…·æœ‰ä»¥ä¸‹çš„å…³é”®å±æ€§ï¼š

- å¯¹æ•°æ®çš„æ‰€æœ‰æ“ä½œéƒ½é€‚ç”¨äºå¯„å­˜å™¨ä¸­çš„æ•°æ®ï¼Œå¹¶ä¸”é€šå¸¸ä¼šæ›´æ”¹æ•´ä¸ªå¯„å­˜å™¨ã€‚

- å½±å“å­˜å‚¨çš„å”¯ä¸€æ“ä½œæ˜¯ load å’Œ store. load æ˜¯å°†æ•°æ®ä»å†…å­˜ç§»åŠ¨åˆ°å¯„å­˜å™¨ï¼Œstore æ˜¯å°†æ•°æ®ä»å¯„å­˜å™¨ç§»åŠ¨åˆ°å†…å­˜ã€‚load æˆ–è€… store å°äºå®Œæ•´å¯„å­˜å™¨ä¹Ÿæ˜¯å¯ä»¥çš„ã€‚
  
  âŒâŒâŒ ç¬¬ä¸€æ¡å’Œç¬¬äºŒæ¡ä¼¼ä¹æœ‰ç‚¹çŸ›ç›¾ï¼Ÿ

- æŒ‡ä»¤æ ¼å¼çš„æ•°é‡å¾ˆå°‘ï¼Œæ‰€æœ‰æŒ‡ä»¤é€šå¸¸éƒ½æ˜¯ä¸€ä¸ªå°ºå¯¸ã€‚

ä»¥ä¸Šç®€å•çš„ç†Ÿæ‚‰å¯¼è‡´äº†æµæ°´çº¿å®ç°çš„æ˜¾è‘—ç®€åŒ–ã€‚

### 2.1. The Classic Five-Stage Pipeline for a RISC Processor

ä¸‹å›¾ç®€å•ç»™å‡ºäº† RISC V äº”ä¸ª stage çš„å…·ä½“ç»†èŠ‚ï¼š

```mermaid
flowchart LR
    IF --> ID
    ID --> EX
    EX --> MEM
    MEM --> WB
```

- IF: instruction fetch
- ID: instruction decode
- EX: execution
- MEM: memory access
- WB: write-back

> To start with, we have to determine what happens on every clock cycle of the processor and make sure we donâ€™t try to perform two different operations with the same data path resource on the same clock cycle.

é˜²æ­¢åœ¨åŒä¸€ä¸ª clock cycle, åŒä¸€ä¸ª data path resource ä¸Šæ‰§è¡Œä¸¤ä¸ªä¸åŒçš„æ“ä½œã€‚

> For example, a single ALU cannot be asked to compute an effective address and perform a subtract operation at the same time. Thus, we must ensure that the overlap of instructions in the pipeline cannot cause such a conflict.

æ¯”å¦‚è¯´æˆ‘ä»¬ä¸èƒ½è¦æ±‚å•ä¸ª ALU å»è®¡ç®—æœ‰æ•ˆåœ°å€çš„åŒæ—¶æ‰§è¡Œå‡æ³•æ“ä½œã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¿…é¡»ç¡®ä¿ç®¡é“ä¸­çš„æŒ‡ä»¤çš„é‡å ä¸ä¼šäº§ç”Ÿè¿™ç§å†²çªã€‚

â­â­ @todo C-7 çš„å›¾ç‰‡å¯ä»¥æœ‰æ•ˆè¯´æ˜è¿™ä¸ªé—®é¢˜ï¼Œå°†æ¥å¯ä»¥æ·»åŠ è¿›æ¥

> First, we use separate instruction and data memories, which we would typically implement with separate instruction and data caches.

ä½¿ç”¨å•ç‹¬çš„æŒ‡ä»¤å’Œæ•°æ®ç¼“å­˜ã€‚

> The use of separate caches eliminates a conflict for a single memory that would arise between instruction fetch and data memory access. 
> 
> Notice that if our pipelined processor has a clock cycle that is equal to that of the unpipelined version, the memory system must deliver five times the bandwidth. This increased demand is one cost of higher performance.

ä½¿ç”¨å•ç‹¬çš„ç¼“å­˜æ¶ˆé™¤äº†æŒ‡ä»¤è·å–æ•°æ®è®¿é—®ä¹‹é—´å¯èƒ½å­˜åœ¨çš„å•ä¸ªå†…å­˜å†²çªã€‚

ä½†æ˜¯éœ€è¦æ³¨æ„ï¼Œå…¶ä»£ä»·æ˜¯å†…å­˜ç³»ç»Ÿå¿…é¡»æä¾›äº”å€çš„å¸¦å®½ï¼ˆ5 clock cycle çš„æƒ…å†µä¸‹ï¼‰ã€‚

> Second, the register file is used in the two stages: one for reading in ID and one for writing in WB. These uses are distinct, so we simply show the register file in two places. *Hence, we need to perform two reads and one write every clock cycle.*
> 
> To handle reads and a write to the same register (and for another reason, which will become obvious shortly), we perform the register write in the first half of the clock cycle and the read in the second half.

register file è¢«ä¸¤ä¸ª stages ç”¨äº†ï¼šåœ¨ ID ä¸­è¯»å–ï¼Œåœ¨ WB ä¸­å†™å…¥ï¼Œè¿™ä¸¤ç§ç”¨æ³•æ˜¯ä¸åŒçš„ã€‚

âŒâŒ æ–œä½“çš„æ²¡æœ‰ç†è§£ã€‚

ä¸ºäº†å¤„ç†å¯¹åŒä¸€ä¸ªå¯„å­˜å™¨çš„è¯»å’Œå†™ï¼Œæˆ‘ä»¬åœ¨æ—¶é’Ÿå‘¨æœŸçš„å‰åŠéƒ¨åˆ†æ‰§è¡Œå¯„å­˜å™¨å†™å…¥ï¼ŒååŠéƒ¨åˆ†æ‰§è¡Œè¯»å–ã€‚

> Third, Figure C.2 does not deal with the PC. To start a new instruction every clock, we must increment and store the PC every clock, and this must be done during the IF stage in preparation for the next instruction. Furthermore, we must also have an adder to compute the potential branch target address during ID. One further problem is that we need the ALU in the ALU stage to evaluate the branch condition. Actually, we donâ€™t really need a full ALU to evaluate the comparison between two registers, but we need enough of the function that it has to occur in this pipestage.

ä¸Šè¿°æè¿°æš‚æ—¶ä¸æ˜¯å¾ˆå…³é”®ã€‚æ€»çš„æ¥è¯´è¿˜æ˜¯ç¡®ä¿ç¡¬ä»¶èµ„æºå¦‚ PC, ALU ç­‰ä¸è¢«åŒæ—¶ä½¿ç”¨ã€‚

> Although it is critical to ensure that instructions in the pipeline do not attempt to use the hardware resources at the same time, we must also ensure that instructions in different stages of the pipeline do not interfere with one another. 
> 
> This separation is done by introducing pipeline registers between successive stages of the pipeline, so that at the end of a clock cycle all the results from a given stage are stored into a register that is used as the input to the next stage on the next clock cycle. Figure C.3 shows the pipeline drawn with these pipeline registers.

è™½ç„¶ç¡®ä¿ pipeline ä¸­çš„æŒ‡ä»¤ä¸ä¼šåŒæ—¶å°è¯•ä½¿ç”¨ç¡¬ä»¶èµ„æºè‡³å…³é‡è¦ï¼Œä½†æ˜¯æˆ‘ä»¬è¿˜å¿…é¡»ç¡®ä¿ pipeline ä¸åŒé˜¶æ®µçš„æŒ‡ä»¤ä¸ä¼šäº’ç›¸å¹²æ‰°ã€‚

è¿™ç§åˆ†ç¦»æ˜¯é€šè¿‡åœ¨æµæ°´çº¿çš„è¿ç»­ stage ä¹‹é—´å¼•å…¥æµæ°´çº¿å¯„å­˜å™¨æ¥å®ç°çš„ï¼Œä»¥ä¾¿äºåœ¨æ—¶é’Ÿå‘¨æœŸç»“æŸæ—¶ï¼Œç»™å®š stage çš„ç»“æœéƒ½å­˜å‚¨åˆ°ä¸€ä¸ªå¯„å­˜å™¨ä¸­ï¼Œè¯¥å¯„å­˜å™¨ç”¨ä½œä¸‹ä¸€ä¸ª clock cycle çš„è¾“å…¥ã€‚

> Although many figures will omit such registers for simplicity, they are required to make the pipeline operate properly and must be present.  Of course, similar registers would be needed even in a multicycle data path that had no pipelining (because only values in registers are preserved across clock boundaries). 
> 
> In the case of a pipelined processor, the pipeline registers also play the key role of carrying intermediate results from one stage to another where the source and destination may not be directly adjacent. For example, the register value to be stored during a store instruction is read during ID, but not actually used until MEM; it is passed through two pipeline registers to reach the data memory during the MEM stage. Likewise, the result of an ALU instruction is computed during EX, but not actually stored until WB; it arrives there by passing through two pipeline registers. It is sometimes useful to name the pipeline registers, and we follow the convention of naming them by the pipeline stages they connect, so the registers are called IF/ID, ID/EX, EX/MEM, and MEM/WB.

å…ˆè¯´æ˜äº†æµæ°´çº¿å¯„å­˜å™¨è™½ç„¶åœ¨å¾ˆå¤šçš„å›¾é‡Œé¢æ²¡æœ‰è¢«ç”»å‡ºæ¥ï¼Œä½†æ˜¯å…¶å¿…ä¸å¯å°‘ã€‚

å†è¯´æ˜äº†ï¼Œå¯„å­˜å™¨ä¸­çš„æ•°æ®å¯èƒ½ä¸ä»…ä»…è¢«ä¸¥æ ¼ç›¸é‚»çš„ä¸¤ä¸ªæŒ‡ä»¤ä½¿ç”¨ã€‚å¹¶ä¸”è¿›è¡Œäº†ä¸¾ä¾‹ã€‚

## 3. The Major Hurdle of Pipeliningâ€”Pipeline Hazards

> There are situations, called hazards, that prevent the next instruction in the instruction stream from executing during its designated clock cycle. Hazards reduce the performance from the ideal speedup gained by pipelining. There are three classes of hazards:
> 
> 1. **Structural hazards** arise from resource conflicts when the hardware cannot support all possible combinations of instructions simultaneously in overlapped execution. In modern processors, structural hazards occur primarily in special purpose functional units that are less frequently used (such as floating point divide or other complex long running instructions). They are not a major performance factor, assuming programmers and compiler writers are aware of the lower throughput of these instructions. Instead of spending more time on this infrequent case, we focus on the two other hazards that are much more frequent.
> 2. **Data hazards** arise when an instruction depends on the results of a previous instruction in a way that is exposed by the overlapping of instructions in the pipeline.
> 3. **Control hazards** arise from the pipelining of branches and other instructions that change the PC.

è®²è¿°äº†ä¸‰ç§å†’é™©æ–¹å¼ã€‚

> Hazards in pipelines can make it necessary to stall the pipeline. Avoiding a hazard
> often requires that some instructions in the pipeline be allowed to proceed while others are delayed. For the pipelines we discuss in this appendix, when an instruction is stalled, all instructions issued later than the stalled instructionâ€”and hence not as far along in the pipelineâ€”are also stalled. Instructions issued earlier than the stalled instructionâ€”and hence farther along in the pipelineâ€”must continue, because otherwise the hazard will never clear. As a result, no new instructions are fetched during the stall.Wewill see several examples of howpipeline stalls operate in this sectionâ€” donâ€™t worry, they arenâ€™t as complex as they might sound!

è¯´äº†å‡ ä¸ªé¿å…å†’é™©çš„æ–¹å¼ã€‚

### 3.1. Performance of Pipelines With Stalls

ä¸»è¦æ˜¯è®²è¿°æ€§èƒ½ä¼˜åŒ–ï¼Œæš‚ä¸ç ”ç©¶ã€‚

### 3.2. Data Hazards

@todo

### 3.3. Branch Hazards

@todo

### 3.4. Reducing the Cost of Branches Through Prediction

> As pipelines get deeper and the potential penalty of branches increases, using delayed branches and similar schemes becomes insufficient. 
> 
> Instead, we need to turn to more aggressive means for predicting branches. Such schemes fall into two classes: low-cost static schemes that rely on information available at compile time and strategies that predict branches dynamically based on program behavior. We discuss both approaches here.

éšç€æµæ°´çº¿çš„åŠ æ·±ï¼Œå…¶æ½œåœ¨çš„æƒ©ç½šå¢åŠ ï¼Œä½¿ç”¨ä¸€äº›å¼±é¸¡çš„æ–¹æ³•å·²ç»ä¸å†é‚£ä¹ˆé«˜æ•ˆäº†ã€‚

ğŸ”´ğŸ”´ğŸ”´ @todo åˆ†æ”¯é¢„æµ‹çš„æ„ä¹‰è¿˜éœ€è¦å†ç»§ç»­ç ”ç©¶

æ‰€ä»¥è¯´æˆ‘ä»¬éœ€è¦è½¬å‘æ›´ç§¯æçš„æ–¹æ³•æ¥é¢„æµ‹åˆ†æ”¯ï¼Œæ­¤ç±»æ–¹æ¡ˆåˆ†ä¸ºä¸¤ç±»ï¼š

1. ä¾èµ–ç¼–è¯‘æ—¶å¯ç”¨ä¿¡æ¯çš„ä½æˆæœ¬é™æ€æ–¹æ¡ˆ
2. åŸºäºç¨‹åºè¡Œä¸ºçš„åŠ¨æ€åˆ†æ”¯é¢„æµ‹

#### 3.4.1. Static Branch Prediction

@todo

#### 3.4.2. Dynamic Branch Prediction and Branch-Prediction Buffers

> The simplest dynamic branch-prediction scheme is a branch-prediction buffer or branch history table. A branch-prediction buffer is a small memory indexed by the lower portion of the address of the branch instruction. The memory contains a bit that says whether the branch was recently taken or not. This scheme is the simplest sort of buffer; it has no tags and is useful only to reduce the branch delay when it is longer than the time to compute the possible target PCs.

æœ€ç®€å•çš„åŠ¨æ€åˆ†æ”¯é¢„æµ‹æ˜¯åˆ†æ”¯é¢„æµ‹ buffer æˆ–è€…åˆ†æ”¯é¢„æµ‹ table. å…·ä½“çš„ç»†èŠ‚è¾ƒä¸ºç®€å•ï¼Œä¸å¤šèµ˜è¿°ã€‚

> With such a buffer, we donâ€™t know, in fact, if the prediction is correctâ€”it may have been put there by another branch that has the same low-order address bits. But this doesnâ€™t matter. The prediction is a hint that is assumed to be correct, and fetching begins in the predicted direction. If the hint turns out to be wrong, the prediction bit is inverted and stored back.

å³ä½¿æœ‰è¿™ä¸ª buffer, æˆ‘ä»¬ä¹Ÿæ— ä»å¾—çŸ¥ï¼Œé¢„æµ‹æ˜¯å¦æ­£ç¡®ã€‚ä½†æ˜¯è¿™æ²¡å…³ç³»ï¼Œå› ä¸ºé¢„æµ‹æ˜¯è¢«å‡å®šä¸ºä¸€ä¸ªæ­£ç¡®çš„æç¤ºï¼Œfetch ä»é¢„æµ‹çš„æ–¹å‘å¼€å§‹ï¼Œå¦‚æœè¿™ä¸ªæç¤ºæœ€ç»ˆè¢«è¯æ˜æ˜¯é”™è¯¯çš„ï¼Œé‚£ä¹ˆé¢„æµ‹ä½çš„é‚£ä¸ª bit å°±è¢«åè½¬è¿‡æ¥ã€‚

âŒâŒâŒ æ­¤æ—¶æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œåˆ†æ”¯é¢„æµ‹é”™è¯¯ä¹‹åï¼Œæµæ°´çº¿è¢«åè½¬äº†ä¹ˆï¼Ÿ

> This buffer is effectively a cache where every access is a hit, and, as we will see, the performance of the buffer depends on both how often the prediction is for the branch of interest and how accurate the prediction is when it matches. Before we analyze the performance, it is useful to make a small, but important, improvement in the accuracy of the branch-prediction scheme.

buffer çš„æ€§èƒ½å–å†³äºé¢„æµ‹å…´è¶£åˆ†æ”¯çš„é¢‘ç‡å’Œé¢„æµ‹åŒ¹é…æ—¶çš„å‡†ç¡®æ€§ã€‚

## 4. How Is Pipelining Implemented?

> Before we proceed to basic pipelining, we need to review a simple implementation of an unpipelined version of RISC V.

å…ˆç ”ç©¶ä¸€ä¸ªæ²¡æœ‰æµæ°´çº¿ç‰ˆæœ¬çš„ RISC V.

### 4.1. A Simple Implementation of RISC V

> In this subsection, we focus on a pipeline for an integer subset of RISC V that consists of l*oad-store word, branch equal, and integer ALU* operations. 
> 
> Later in this appendix we will incorporate the basic floating-point operations. Although we discuss only a subset of RISC V, the basic principles can be extended to handle all the instructions; for example, adding store involves some additional computing of the immediate field. We initially used a less aggressive implementation of a branch instruction. We show how to implement the more aggressive version at the end of this section.

æˆ‘ä»¬è®¨è®º RISC V çš„ä¸€ä¸ªå­é›†ã€‚

> Every RISC V instruction can be implemented in, at most, 5 clock cycles. The 5
> clock cycles are as follows:

æ¥ä¸‹æ¥è¯´æ˜ 5 ä¸ª clock cycle çš„åˆ†åˆ«æ„æˆï¼š

1. Instruction fetch cycle(IF)
   
   ```
   IR <- Mem[PC];
   NPC <- PC + 4;
   ```
   
   > Operationâ€”Send out the PC and fetch the instruction from memory into the instruction register (IR); increment the PC by 4 to address the next sequential instruction. The IR is used to hold the instruction that will be needed on subsequent clock cycles; likewise, the register NPC is used to hold the next sequential PC.

å…¶æ“ä½œæ˜¯å‘é€å‡ºå» PC å¹¶å°†æŒ‡ä»¤ä»å†…å­˜ä¸­è¯»å–å‡ºæ¥åˆ°**æŒ‡ä»¤å¯„å­˜å™¨ IR**ï¼›å°† PC é€’å¢ 4 ä»¥å¯»å€ä¸‹ä¸€ä¸ªé¡ºåºæŒ‡ä»¤ã€‚IR ç”¨äºä¿å­˜åç»­æ—¶é’Ÿå‘¨æœŸæ‰€éœ€çš„æŒ‡ä»¤ï¼ŒåŒæ ·ï¼Œå¯„å­˜å™¨ *NPC ç”¨äºä¿å­˜ä¸‹ä¸€ä¸ªé¡ºåº PC*.

2. Instruction decode/register fetch cycle (ID)
   
   ```
   A <- Regs[rs1];
   B <- Regs[rs2];
   Imm <- sign-extended immediate field of IR;
   ```
   
   > Operationâ€”Decode the instruction and access the register file to read the registers (`rs1` and `rs2` are the register specifiers). The outputs of the general-purpose registers are read into two temporary registers (A and B) for use in later clock cycles. The lower 16 bits of the IR are also sign extended and stored into the temporary register `Imm`, for use in the next cycle. 
   > 
   > Decoding is done in parallel with reading registers, which is possible because these fields are at a fixed location in the RISC V instruction format. Because the immediate portion of a load and an ALU immediate is located in an identical place in every RISC V instruction, the sign-extended immediate is also calculated during this cycle in case it is needed in the next cycle. For stores, a separate sign-extension is needed, because the immediate field is split in two pieces.

å…¶æ“ä½œæ˜¯è§£ç æŒ‡ä»¤å¹¶è®¿é—® register file ä»¥è¯»å–å¯„å­˜å™¨ï¼Œé€šç”¨å¯„å­˜å™¨çš„è¾“å‡ºè¢«è¯»å…¥ä¸¤ä¸ªä¸´æ—¶å¯„å­˜å™¨ A å’Œ B, ä»¥ä¾¿äºåœ¨åç»­çš„æ—¶é’Ÿå‘¨æœŸä¸­ä½¿ç”¨ã€‚IR çš„ä½ 16 bitä¹Ÿè¢«æ‰©å±•å¹¶å­˜å‚¨åˆ°ä¸´æ—¶å¯„å­˜å™¨ `Imm` ä¸­ï¼Œä¾›ä¸‹ä¸€ä¸ª cycle ä½¿ç”¨ã€‚

è§£ç ä¸è¯»å–å¯„å­˜å™¨å¹¶è¡Œå®Œæˆï¼Œè¿™æ˜¯å¯èƒ½çš„ï¼Œå› ä¸ºè¿™äº›å­—æ®µåœ¨ RISC V æŒ‡ä»¤æ ¼å¼ä¸­å¤„äºå›ºå®šä½ç½®ã€‚

âŒâŒ immediate filed ç›¸å…³çš„ç ”ç©¶ã€‚

3. Execution/effective address cycle (EX)

> The ALU operates on the operands prepared in the prior cycle, performing one of four functions depending on the RISC V instruction type:
> 
> - Memory reference:
>   `ALU Output <- A + Imm;`
>   Operationâ€”The ALU adds the operands to form the effective address and places the result into the register ALU Output.
> - Register-register ALU instruction:
>   `ALU Output <- A func B;`
>   Operationâ€”The ALU performs the operation specified by the function code (a combination of the func3 and func7 fields) on the value in register A and on the value in register B. The result is placed in the temporary register ALU Output.
> - Register-Immediate ALU instruction:
>   `ALUOutput <- A op Imm`;
>   Operationâ€”The ALU performs the operation specified by the opcode on the value in register A and on the value in register Imm. The result is placed in the temporary register ALU Output.
> - Branch:
>   `ALU Output <- NPC + (Imm << 2);`
>   `Cond <- (A == B)`
>   Operationâ€”The ALU adds the NPC to the sign-extended immediate value in Imm, which is shifted left by 2 bits to create a word offset, to compute the address of the branch target. Register A, which has been read in the prior cycle, is checked to determine whether the branch is taken, by comparison with Register B, because we consider only branch equal.

è®²è¿° EX æ­¥éª¤æ‰€åšçš„äº‹æƒ…ã€‚ALU å¯¹ä¸Šä¸ª cycle çš„æ“ä½œæ•°è¿›è¡Œæ“ä½œï¼Œæ ¹æ® RISC V æŒ‡ä»¤ç±»å‹æ“ä½œä¸‹åˆ—å››ä¸ªå‡½æ•°ä¸­çš„ä¸€ä¸ªï¼š

1. å†…å­˜å¼•ç”¨ï¼›å¯„å­˜å™¨çš„å€¼åŠ ä¸Šç«‹å³æ•°ï¼Œè®¡ç®—å‡ºæ¥æœ‰æ•ˆåœ°å€å¹¶ä½œä¸º ALU çš„è¾“å‡ºï¼›
2. å¯„å­˜å™¨ä¹‹é—´ï¼›ALU å¯¹å¯„å­˜å™¨ A å’Œ B ä¸­çš„å€¼æ‰§è¡ŒæŒ‡å®šåŠŸèƒ½ä»£ç ï¼Œç»“æœæ”¾åœ¨ ALU è¾“å‡ºå¯„å­˜å™¨ï¼›
3. å¯„å­˜å™¨å’Œç«‹å³æ•°ï¼›å¯„å­˜å™¨ A çš„å€¼ op ç«‹å³æ•°ï¼›
4. åˆ†æ”¯ï¼›ALU å°† NPC æ·»åŠ åˆ° Imm çš„ç¬¦å·æ‰©å±•ç«‹å³å€¼ä¸­ï¼Œè¯¥ç«‹å³å€¼åç§» 2 ä½ä»¥åˆ›å»ºå­—åç§»ï¼Œç”¨äºè®¡ç®—åˆ†æ”¯ç›®æ ‡çš„åœ°å€ã€‚é€šè¿‡ä¸å¯„å­˜å™¨ B ç›¸æ¯”ï¼Œæ£€æŸ¥åœ¨ä¸Šä¸€ä¸ªå‘¨æœŸä¸­è¯»å–çš„å¯„å­˜å™¨ A, ä»¥ç¡®å®šæ˜¯å¦é‡‡ç”¨åˆ†æ”¯ã€‚

> The load-store architecture of RISC V means that effective address and execution cycles can be combined into a single clock cycle, because no instruction needs to simultaneously calculate a data address, calculate an instruction target address, and perform an operation on the data. The other integer instructions not included herein are jumps of various forms, which are similar to branches.

4. Memory access/branch completion cycle (MEM)

> The PC is updated for all instructions: `PC <- NPC`;
> 
> - Memory reference:
>   `LMD <- Mem[ALUOutput] or Mem[ALUOutput] <- B;`
>   Operationâ€”Access memory if needed. If the instruction is a load, data return from memory and are placed in the LMD (load memory data) register; if it is a store, then the data from the B register are written into memory. In either case, the address used is the one computed during the prior cycle and stored in the register ALU Output.
> - Branch:
>   `if (cond) PC <- ALUOutput`
>   Operationâ€”If the instruction branches, the PC is replaced with the branch destination
>   address in the register ALU Output.

â€‹        

5. Write-back cycle (WB)

> - Register-register or Register-immediate ALU instruction:
>   `Regs[rd] <- ALU Output;`
> 
> - Load instruction:
>   `Regs[rd] <- LMD;`
>   Operationâ€”Write the result into the register file, whether it comes from the memory system (which is in LMD) or from the ALU (which is in ALU Output) with rd designating the register.

æˆ‘ä»¬åšä¸€ä¸ªç®€å•çš„æ€»ç»“ï¼Œé¦–å…ˆç¬¬ä¸€æ­¥ IFï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬ç»å¸¸çŸ¥é“çš„ fetch, è¿™ä¸€æ­¥æ˜¯é€å‡º PC,  å°†æŒ‡ä»¤å­˜å‚¨åœ¨ IR ä¸­ï¼ŒPC + 4 åˆ°ä¸‹ä¸€æ¡æŒ‡ä»¤çš„åœ°å€ï¼Œå¹¶ä¸”å­˜å‚¨åœ¨ NPC ä¸­ï¼ˆä¸ºäº†æ–¹ä¾¿ç†è§£ï¼Œç†è§£ç§°ä¸º Next-PCï¼‰ï¼›

æ¥ä¸‹æ¥è¿›è¡ŒæŒ‡ä»¤çš„è¯‘ç ï¼Œæ³¨æ„è¿™ä¸ªå’Œå¯„å­˜å™¨çš„è¯»å–æ˜¯å¯ä»¥åŒæ—¶å®Œæˆçš„ï¼Œåœ¨è¿™ä¸ªæ­¥éª¤ä¸­ï¼ŒIR çš„ä½ 16 ä½è¿›è¡Œäº†ç¬¦å·æ‰©å±•ï¼Œå­˜å‚¨åœ¨äº†ä¸´æ—¶å¯„å­˜å™¨ Imm ä¸­ï¼Œä¾›ä¸‹ä¸€ä¸ªå‘¨æœŸä½¿ç”¨ï¼›

æ¥ä¸‹æ¥æ˜¯æ‰§è¡Œçš„è¿‡ç¨‹ï¼Œæ ¹æ®å…·ä½“çš„æŒ‡ä»¤å†³å®šè¦æ‰§è¡Œçš„ç±»å‹ï¼Œå…¶ç»“æœå­˜å‚¨åœ¨äº†ä¸´æ—¶å¯„å­˜å™¨ ALU Output ä¸­ï¼›

æ¥ä¸‹æ¥æ˜¯è®¿å­˜æŒ‡ä»¤ï¼Œå³ memery accessã€‚éœ€è¦æ³¨æ„åˆ°åœ¨è¿™ä¸ªæ­¥éª¤ä¸­ï¼Œæ›´æ–°äº† PC å¯„å­˜å™¨ï¼›ä¸ç®¡æ˜¯å¯„å­˜å™¨å†™å…¥è¿˜æ˜¯å†™å‡ºï¼Œä½¿ç”¨çš„åœ°å€éƒ½æ˜¯ä¸Šä¸ªæ­¥éª¤ ALU Output çš„ç»“æœï¼›å¦‚æœæ˜¯è½½å…¥ load æŒ‡ä»¤ï¼Œåˆ™å°†ä» memory è¿”å›çš„æ•°æ®æ”¾å…¥ LMD(load memory data) å¯„å­˜å™¨ä¸­ï¼Œå¦‚æœæ˜¯å­˜å‚¨ store æŒ‡ä»¤ï¼Œåˆ™å°† B å¯„å­˜å™¨çš„å€¼å†™å…¥åˆ° memory ä¸­ã€‚éœ€è¦æ³¨æ„åˆ°ï¼Œè¿™ä¸€æ­¥éª¤å¯èƒ½æ˜¯åˆ†æ”¯æŒ‡ä»¤ï¼Œå¦‚æœæ˜¯åˆ†æ”¯æŒ‡ä»¤çš„è¯ï¼Œåˆ™ç”¨å¯„å­˜å™¨ ALU Output ä¸­çš„åˆ†æ”¯ç›®æ ‡åœ°å€ä»£æ›¿ PC.

æœ€åä¸€æ­¥æ˜¯å†™å›æ“ä½œï¼›ç›®æ ‡æ˜¯å†™å…¥å¯„å­˜å™¨å †ä¸­ã€‚

ğŸŸ¢ğŸŸ¢ æ³¨æ„åˆ°ä¸Šè¿°æ˜¯ä¸è€ƒè™‘æµæ°´çº¿çš„æƒ…å†µä¸‹çš„å®ç°ã€‚
